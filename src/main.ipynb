{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 競馬予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. colabの環境を整える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1. git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yuugo0724/keiba_prediction.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-2. 作業ブランチの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloneしたディレクトリに移動\n",
    "%cd ./keiba_prediction\n",
    "\n",
    "# ブランチ名がmainであること\n",
    "!git branch\n",
    "# 作業ブランチの作成\n",
    "!git branch [作業ブランチ名]\n",
    "# 作業ブランチにチェックアウト\n",
    "!git checkout [作業ブランチ名]\n",
    "# 作業ブランチにチェックアウトできていることを確認\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-2. ソースコードのディレクトリに移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-3. pythonのライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../dockerfile/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モジュールやライブラリのインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ライブラリ\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as lgb\n",
    "import lightgbm as lgb_orig\n",
    "\n",
    "\"\"\"\n",
    "モジュール(定数)\n",
    "\"\"\"\n",
    "# ローカルパス\n",
    "from modules.constants import LocalPaths\n",
    "# データフレームの列名\n",
    "#from modules.constants import ResultsCols\n",
    "# レース名のマスター\n",
    "from modules.constants import RaceInfo\n",
    "# スクレイピングのパス\n",
    "#from modules.constants import ScrapyPath\n",
    "\n",
    "\"\"\"\n",
    "モジュール(前処理)\n",
    "\"\"\"\n",
    "# 前処理\n",
    "#from modules.preprocess import shaping\n",
    "from modules.preprocess import _scrapy_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. ローカルパスの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化(path_list => pl)\n",
    "lp = LocalPaths()\n",
    "ri = RaceInfo()\n",
    "# プロジェクトのベースディレクトリ\n",
    "base_dir = lp.BASE_DIR\n",
    "# scrapyのベースディレクトリ\n",
    "scrapy_dir = lp.SCRAPY_DIR\n",
    "# scrapy keibaプロジェクトのパス\n",
    "scrapy_keiba_dir = lp.SCRAPY_KEIBA_DIR\n",
    "# dataディレクトリ\n",
    "data_dir = lp.DATA_DIR\n",
    "# レース結果スクレイピング用url格納ディレクトリ\n",
    "data_url_dir = lp.DATA_URL_DIR\n",
    "# masterデータ格納ディレクトリ\n",
    "data_master_dir = lp.DATA_MASTER_DIR\n",
    "data_tmp_dir = lp.DATA_TMP_DIR\n",
    "# gradesデータ格納ディレクトリ\n",
    "data_grades_dir = lp.DATA_GRADES_DIR\n",
    "# horse_gradesデータ格納ディレクトリ\n",
    "data_horse_grades_dir = lp.DATA_HORSE_GRADES_DIR\n",
    "# pedigreeデータ格納ディレクトリ\n",
    "data_pedigree_dir = lp.DATA_PEDIGREE_DIR\n",
    "# gradesのmaster\n",
    "data_grades_master = lp.DATA_GRADES_MASTER\n",
    "# horse_idのmaster\n",
    "data_horse_id_master = lp.DATA_HORSE_ID_MASTER\n",
    "\n",
    "# 競馬場ID\n",
    "place_dict = ri.PLACE_DICT\n",
    "# urlの正常性チェックプログラムのパス\n",
    "#sy_unc_path = base_path + 'scrapy/url_normality_check.py'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学習データ作成\n",
    "2-1. スクレイピングを実施  \n",
    "2-2. 前処理  \n",
    "2-3. 学習データを説明変数と目的変数に分割  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. スクレイピング\n",
    "- スクレイピング対象のurlを取得  \n",
    "- レース結果データを取得  \n",
    "- 馬ごとの成績データを取得  \n",
    "  ※学習データとしては、まだ利用していない  \n",
    "- 血統データを取得  \n",
    "  ※学習データとしては、まだ利用していない  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-1. 変数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース結果スクレイピング対象のurl取得\n",
    "proc_coll_url = lp.PROC_COLL_URL\n",
    "log_coll_url = lp.LOG_COLL_URL\n",
    "# レース結果スクレイピング\n",
    "proc_coll_grades = lp.PROC_COLL_GRADES\n",
    "log_coll_grades = lp.LOG_COLL_GRADES\n",
    "# 馬ごとのレース結果スクレイピング\n",
    "proc_coll_horse_grades = lp.PROC_COLL_HORSE_GRADES\n",
    "log_coll_horse_grades = lp.LOG_COLL_HORSE_GRADES\n",
    "# 馬ごとの血統データスクレイピング\n",
    "proc_coll_pedigree = lp.PROC_COLL_PEDIGREE\n",
    "log_coll_pedigree = lp.LOG_COLL_PEDIGREE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-2. スクレイピング対象のurl取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_date = pd.date_range(start=\"20120101\",end=\"20221101\", freq=\"MS\")\n",
    "df_date = df_gen_date.to_series().dt.strftime(\"%Y%m\")\n",
    "horse_id_list = df_date.values\n",
    "\n",
    "os.chdir(scrapy_keiba_dir)\n",
    "with open(log_coll_url, 'w') as f:\n",
    "  for horse_id in horse_id_list:\n",
    "    date_dir = os.path.join(data_url_dir,horse_id[0:4])\n",
    "    os.makedirs(date_dir, exist_ok=True)\n",
    "    scrapy_cmd = [\"python3\",proc_coll_url,horse_id,date_dir,data_url_dir]\n",
    "    scrapy_proc = subprocess.Popen(scrapy_cmd, stdout=f, stderr=f)\n",
    "    scrapy_proc.wait()\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-3. レース結果のパスリスト作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_file_list = []\n",
    "for current_dir, sub_dirs, files_list in os.walk(data_url_dir):\n",
    "  for file in files_list:\n",
    "    url_file_list.append(os.path.join(current_dir,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-4. レース結果の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1-4-1. 取得対象のレース期間を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_date = pd.date_range(start=\"20200101\",end=\"20210101\", freq=\"MS\")\n",
    "df_date = df_gen_date.to_series().dt.strftime(\"%Y%m\")\n",
    "horse_id_list = df_date.values\n",
    "\n",
    "target_url_file_list = []\n",
    "for date in horse_id_list:\n",
    "  date_match = '.*/' + date + '.csv'\n",
    "  target_url_files = [url_file for url_file in url_file_list if re.match(date_match,url_file)]\n",
    "  if target_url_files:\n",
    "    target_url_file_list.extend(target_url_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1-4-2. レース結果のスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(scrapy_keiba_dir)\n",
    "with open(log_coll_grades, 'w') as f:\n",
    "  for url_file in target_url_file_list:\n",
    "    file_name = url_file.split('/')[-1].split('.')[0]\n",
    "    date_y = file_name[0:4]\n",
    "    date_m = file_name[4:6]\n",
    "    race_url_list = np.ravel(pd.read_csv(url_file,header=0).values.tolist())\n",
    "    date_dir = os.path.join(data_grades_dir,date_y,date_m)\n",
    "    os.makedirs(date_dir, exist_ok=True)\n",
    "    for race_url in race_url_list:\n",
    "      race_id = re.sub(\"\\D\",\"\", race_url)\n",
    "      scrapy_cmd = [\"python3\",proc_coll_grades,race_url,race_id,date_dir,data_grades_dir]\n",
    "      scrapy_proc = subprocess.Popen(scrapy_cmd, stdout=f, stderr=f)\n",
    "      scrapy_proc.wait()\n",
    "os.chdir(base_dir)\n",
    "\n",
    "# colabで取得する場合、時間がたつと切断されてしまうため、\n",
    "# 取得後ブランチを作ってpushする\n",
    "#!git add .\n",
    "#!git commit -m \"from colab\"\n",
    "#!git push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-5. 成績マスターの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_list = []\n",
    "for current_dir, sub_dirs, files_list in os.walk(data_grades_dir):\n",
    "  for file in files_list:\n",
    "    race_list.append(os.path.join(current_dir,file))\n",
    "#print(race_list)\n",
    "_scrapy_data.create_grades_master(race_list,data_grades_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-6. 成績マスターの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master = pd.read_pickle(data_grades_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-7. 馬IDマスターの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horse_id_master = grades_master['馬ID']\n",
    "df_horse_id_master = df_horse_id_master.drop_duplicates()\n",
    "df_horse_id_master = df_horse_id_master.reset_index(drop=True)\n",
    "df_horse_id_master.to_pickle(data_horse_id_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-8. 馬のレース結果を取得\n",
    "※現状学習データに含めるつもりはないので実施不要  \n",
    "　今後、学習データに含める場合にコードを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_id_list = [\"2018104963\",\"2018105074\"]\n",
    "\n",
    "os.chdir(scrapy_keiba_dir)\n",
    "with open(log_coll_horse_grades, 'w') as f:\n",
    "  for horse_id in horse_id_list:\n",
    "    scrapy_cmd = [\"python3\",proc_coll_horse_grades,horse_id,data_horse_grades_dir]\n",
    "    scrapy_proc = subprocess.Popen(scrapy_cmd, stdout=f, stderr=f)\n",
    "    scrapy_proc.wait()\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-9. 血統データを取得\n",
    "※現状学習データに含めるつもりはないので実施不要  \n",
    "　今後、学習データに含める場合にコードを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_id_list = [\"2018104963\",\"2018105074\"]\n",
    "\n",
    "os.chdir(scrapy_keiba_dir)\n",
    "with open(log_coll_pedigree, 'w') as f:\n",
    "  for horse_id in horse_id_list:\n",
    "    scrapy_cmd = [\"python3\",proc_coll_pedigree,horse_id,data_horse_grades_dir]\n",
    "    scrapy_proc = subprocess.Popen(scrapy_cmd, stdout=f, stderr=f)\n",
    "    scrapy_proc.wait()\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-1. 欠損値の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master = grades_master.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-2. 体重増減を整数化(記号を削除)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master['馬体重増減'] = grades_master['馬体重増減'].replace(\"+\",\"\").astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-3. 性齢の分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexual_age = grades_master['性齢']\n",
    "sex = sexual_age.replace('[0-9]+',\"\", regex=True)\n",
    "age = sexual_age.replace(\"\\D\",\"\", regex=True)\n",
    "grades_master['性'] = sex\n",
    "grades_master['齢'] = age.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-4. レース名の処理※要検討"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_id_list = []\n",
    "race_id_list = grades_master['レースID']\n",
    "for place_id in race_id_list:\n",
    "  place_id_list.append(place_dict[place_id[4:6]])\n",
    "grades_master['競馬場'] = place_id_list\n",
    "#print(grades_master[['レースID','競馬場']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master['レース名'].drop_duplicates().to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 競馬場・レース名を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 競馬場指定\n",
    "grades_master = grades_master[grades_master['競馬場']=='中山']\n",
    "\n",
    "# レース名指定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-5. カテゴリ変数をダミー変数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grades_master = pd.get_dummies(grades_master,columns=['レース名'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['回り'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['天候'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['タイプ'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['馬場状態'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['馬名'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['騎手'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['調教師'])\n",
    "grades_master = pd.get_dummies(grades_master,columns=['性'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-6. 不要な列を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master = grades_master.drop('レースID', axis=1)\n",
    "grades_master = grades_master.drop('レース名', axis=1)\n",
    "grades_master = grades_master.drop('競馬場', axis=1)\n",
    "grades_master = grades_master.drop('馬番', axis=1)\n",
    "grades_master = grades_master.drop('性齢', axis=1)\n",
    "grades_master = grades_master.drop('タイム', axis=1)\n",
    "grades_master = grades_master.drop('単勝', axis=1)\n",
    "grades_master = grades_master.drop('人気', axis=1)\n",
    "grades_master = grades_master.drop('馬ID', axis=1)\n",
    "grades_master = grades_master.drop('調教師ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-7. データフレームの型をintに変換\n",
    "変換対象列  \n",
    "- 距離  \n",
    "- 枠番  \n",
    "- 斥量  \n",
    "- 馬体重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スクレイピングのバグで距離列に空白が含まれていたのでそちらを削除  \n",
    "※現時点では修正済み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master = grades_master[grades_master['距離'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master['距離'] = grades_master['距離'].astype(int)\n",
    "grades_master['枠番'] = grades_master['枠番'].astype(int)\n",
    "grades_master['斥量'] = grades_master['斥量'].astype(float)\n",
    "grades_master['馬体重'] = grades_master['馬体重'].astype(int)\n",
    "grades_master['着順'] = pd.to_numeric(grades_master['着順'],errors='coerce')\n",
    "grades_master = grades_master.dropna(how='any', axis=0)\n",
    "grades_master['着順'] = grades_master['着順'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-7. 3着以内とそれ以外でデータを2分類化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master.loc[grades_master['着順']<=3,['着順']] = 1\n",
    "grades_master.loc[grades_master['着順']>3,['着順']] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### １着、２着、３着、それ以外で多分類化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master.loc[grades_master['着順']==1,['着順']] = 3\n",
    "grades_master.loc[grades_master['着順']==2,['着順']] = 2\n",
    "grades_master.loc[grades_master['着順']==3,['着順']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "距離            int64\n",
      "着順            int64\n",
      "枠番            int64\n",
      "斥量          float64\n",
      "馬体重           int64\n",
      "             ...   \n",
      "調教師_鹿戸雄一      uint8\n",
      "調教師_黒岩陽一      uint8\n",
      "性_セ           uint8\n",
      "性_牝           uint8\n",
      "性_牡           uint8\n",
      "Length: 5163, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(grades_master.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 学習データを説明変数と目的変数に分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5918, 5162)\n",
      "(2537, 5162)\n",
      "(5918,)\n",
      "(2537,)\n"
     ]
    }
   ],
   "source": [
    "#df_tran_data = df_tran_data.drop(['馬体重(増減)'], axis=1)\n",
    "\n",
    "x = grades_master.drop(['着順'], axis=1)\n",
    "y = grades_master['着順']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-5-4. 学習データと検証データに分ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-6. 学習モデルの作成・学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-6-1. ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'objective': 'binary',\n",
    "  'metric': 'auc',\n",
    "}\n",
    "best_params, histroy ={}, []\n",
    "model = lgb.train(params,\n",
    "                  lgb_train,\n",
    "                  valid_sets=[lgb_train,lgb_eval],\n",
    "                  num_boost_round=10,\n",
    "                  early_stopping_rounds=10)\n",
    "best_params_ = model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-06 14:31:12,655]\u001b[0m A new study created in memory with name: no-name-63151c10-65ac-449c-a7c4-ccfe40285159\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/keiba/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[33m[W 2022-12-06 14:31:12,668]\u001b[0m Trial 0 failed because of the following error: LightGBMError('Cannot set reference after freed raw data, set free_raw_data=False when construct Dataset to avoid this.')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keiba/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/keiba/.local/lib/python3.9/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 248, in __call__\n",
      "    booster = lgb.train(self.lgbm_params, train_set, **kwargs)\n",
      "  File \"/home/keiba/.local/lib/python3.9/site-packages/lightgbm/engine.py\", line 224, in train\n",
      "    reduced_valid_sets.append(valid_data._update_params(params).set_reference(train_set))\n",
      "  File \"/home/keiba/.local/lib/python3.9/site-packages/lightgbm/basic.py\", line 2120, in set_reference\n",
      "    raise LightGBMError(\"Cannot set reference after freed raw data, \"\n",
      "lightgbm.basic.LightGBMError: Cannot set reference after freed raw data, set free_raw_data=False when construct Dataset to avoid this.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Cannot set reference after freed raw data, set free_raw_data=False when construct Dataset to avoid this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m,\n\u001b[1;32m      4\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmulti_logloss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m best_params, histroy \u001b[39m=\u001b[39m{}, []\n\u001b[0;32m----> 7\u001b[0m model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params,\n\u001b[1;32m      8\u001b[0m                   lgb_train,\n\u001b[1;32m      9\u001b[0m                   valid_sets\u001b[39m=\u001b[39;49m[lgb_train,lgb_eval],\n\u001b[1;32m     10\u001b[0m                   num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m                   early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m best_params_ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mparams\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/integration/_lightgbm_tuner/__init__.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m _imports\u001b[39m.\u001b[39mcheck()\n\u001b[1;32m     34\u001b[0m auto_booster \u001b[39m=\u001b[39m LightGBMTuner(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 35\u001b[0m auto_booster\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m auto_booster\u001b[39m.\u001b[39mget_best_booster()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/integration/_lightgbm_tuner/optimize.py:545\u001b[0m, in \u001b[0;36m_LightGBMBaseTuner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39m# Sampling.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_train_set()\n\u001b[0;32m--> 545\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtune_feature_fraction()\n\u001b[1;32m    546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtune_num_leaves()\n\u001b[1;32m    547\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtune_bagging()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/integration/_lightgbm_tuner/optimize.py:570\u001b[0m, in \u001b[0;36m_LightGBMBaseTuner.tune_feature_fraction\u001b[0;34m(self, n_trials)\u001b[0m\n\u001b[1;32m    567\u001b[0m param_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.4\u001b[39m, \u001b[39m1.0\u001b[39m, n_trials)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    569\u001b[0m sampler \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mGridSampler({param_name: param_values})\n\u001b[0;32m--> 570\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tune_params([param_name], \u001b[39mlen\u001b[39;49m(param_values), sampler, \u001b[39m\"\u001b[39;49m\u001b[39mfeature_fraction\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/integration/_lightgbm_tuner/optimize.py:653\u001b[0m, in \u001b[0;36m_LightGBMBaseTuner._tune_params\u001b[0;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[1;32m    651\u001b[0m     _timeout \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mif\u001b[39;00m _n_trials \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 653\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m    654\u001b[0m         objective,\n\u001b[1;32m    655\u001b[0m         n_trials\u001b[39m=\u001b[39;49m_n_trials,\n\u001b[1;32m    656\u001b[0m         timeout\u001b[39m=\u001b[39;49m_timeout,\n\u001b[1;32m    657\u001b[0m         catch\u001b[39m=\u001b[39;49m(),\n\u001b[1;32m    658\u001b[0m         callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optuna_callbacks,\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[39mif\u001b[39;00m pbar:\n\u001b[1;32m    662\u001b[0m     pbar\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/integration/_lightgbm_tuner/optimize.py:248\u001b[0m, in \u001b[0;36m_OptunaObjective.__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    246\u001b[0m kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlgbm_kwargs)\n\u001b[1;32m    247\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mvalid_sets\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_copy_valid_sets(kwargs[\u001b[39m\"\u001b[39m\u001b[39mvalid_sets\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 248\u001b[0m booster \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlgbm_params, train_set, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    250\u001b[0m val_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_booster_best_score(booster)\n\u001b[1;32m    251\u001b[0m elapsed_secs \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/engine.py:224\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(valid_data, Dataset):\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTraining only accepts Dataset object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m reduced_valid_sets\u001b[39m.\u001b[39mappend(valid_data\u001b[39m.\u001b[39;49m_update_params(params)\u001b[39m.\u001b[39;49mset_reference(train_set))\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m valid_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(valid_names) \u001b[39m>\u001b[39m i:\n\u001b[1;32m    226\u001b[0m     name_valid_sets\u001b[39m.\u001b[39mappend(valid_names[i])\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/basic.py:2120\u001b[0m, in \u001b[0;36mDataset.set_reference\u001b[0;34m(self, reference)\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_free_handle()\n\u001b[1;32m   2119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2120\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m\"\u001b[39m\u001b[39mCannot set reference after freed raw data, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2121\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mset free_raw_data=False when construct Dataset to avoid this.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Cannot set reference after freed raw data, set free_raw_data=False when construct Dataset to avoid this."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "  'objective': 'multiclass',\n",
    "  'num_class': 3,\n",
    "  'metric': 'multi_logloss',\n",
    "}\n",
    "best_params, histroy ={}, []\n",
    "model = lgb.train(params = params,\n",
    "                  lgb_train = lgb_train,\n",
    "                  valid_sets = [lgb_train,lgb_eval],\n",
    "                  num_boost_round = 100,\n",
    "                  early_stopping_rounds=5,\n",
    "                  verbose_eval = 50\n",
    "                  )\n",
    "best_params_ = model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-6-2. 学習モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keiba/.local/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Contains only one class\n",
      "[LightGBM] [Info] Number of positive: 5918, number of negative: 0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8641\n",
      "[LightGBM] [Info] Number of data points in the train set: 5918, number of used features: 4238\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=1.000000 -> initscore=34.539576\n",
      "[LightGBM] [Info] Start training from score 34.539576\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=1.000000 -> initscore=34.539576\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 1\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n"
     ]
    }
   ],
   "source": [
    "model = lgb_orig.train(best_params_,\n",
    "                        lgb_train,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        num_boost_round=100,\n",
    "                        early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = x_test.sample(n=1)\n",
    "#print(pred)\n",
    "y_pred = model.predict(pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1, 0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
