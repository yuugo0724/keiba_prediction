{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 競馬予測_スクレイピング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. colabの環境を整える"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-1. git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yuugo0724/keiba_prediction.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-2. 作業ブランチの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloneしたディレクトリに移動\n",
    "%cd ./keiba_prediction\n",
    "\n",
    "# ブランチ名がmainであること\n",
    "!git branch\n",
    "# 作業ブランチの作成\n",
    "!git branch [作業ブランチ名]\n",
    "# 作業ブランチにチェックアウト\n",
    "!git checkout [作業ブランチ名]\n",
    "# 作業ブランチにチェックアウトできていることを確認\n",
    "!git branch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-2. ソースコードのディレクトリに移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-3. pythonのライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../dockerfile/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. importと変数の定義"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keiba/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ライブラリ\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "モジュール(定数)\n",
    "\"\"\"\n",
    "# ローカルパス\n",
    "from modules.constants import LocalPaths\n",
    "# 学習データのパス\n",
    "from modules.constants import TrainDataPaths\n",
    "# データフレームの列名\n",
    "from modules.constants import DataFrameCols\n",
    "# レース名のマスター\n",
    "from modules.constants import RaceInfo\n",
    "\"\"\"\n",
    "モジュール(前処理)\n",
    "\"\"\"\n",
    "# データフレームの作成\n",
    "from modules.preprocess import create_dataframe\n",
    "# スクレイピング\n",
    "from modules.preprocess import scrapy_proc\n",
    "# データフレームの整形\n",
    "from modules.preprocess import dataframe_grades\n",
    "\"\"\"\n",
    "モジュール(モデルの学習)\n",
    "\"\"\"\n",
    "from modules.training import data_training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. インスタンスの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps = LocalPaths()\n",
    "df_cols = DataFrameCols()\n",
    "race_info = RaceInfo()\n",
    "# スクレイピング用クラスのインスタンス化\n",
    "scrapy_proc = scrapy_proc(lps)\n",
    "# マスタ作成用クラスのインスタンス化\n",
    "create_dataframe = create_dataframe(lps, df_cols)\n",
    "# 学習データのパスクラスをインスタンス化\n",
    "#   モデルのタイプ\n",
    "#     multiclass_3\n",
    "#     multiclass_5\n",
    "#     binaryclass ※上手く動かせない・・・\n",
    "#   カテゴリ変数の処理方法を決める\n",
    "#     ラベルエンコーディング　：label\n",
    "#     ダミー変数化　　　　　　：dummies ※列が多くなりすぎるため廃止\n",
    "#     カウントエンコーディング：count  ※競馬予測に向いていない\n",
    "tdp = TrainDataPaths('binaryclass','label')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. スクレイピング\n",
    "1. スクレイピング対象のurlを取得  \n",
    "2. レース結果データを取得  \n",
    "3. 馬ごとの成績データを取得  \n",
    "  ※学習データとしては、まだ利用していない  \n",
    "4. 血統データを取得  \n",
    "  ※学習データとしては、まだ利用していない  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. スクレイピング対象のurl取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urlを取得する日付のレンジを指定\n",
    "df_gen_date = pd.date_range(start=\"20221201\",end=\"20221231\", freq=\"MS\")\n",
    "# フォーマットを変えてリストに格納\n",
    "df_date = df_gen_date.to_series().dt.strftime(\"%Y%m\")\n",
    "race_date_list = df_date.values\n",
    "\n",
    "# スクレイピング対象のurlをスクレイピング\n",
    "scrapy_proc.coll_urls(race_date_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. レース結果のパスリスト作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urlファイルのパスリストを定義\n",
    "scrapy_proc.create_path_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. レース結果の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース結果を取得する日付のレンジを指定\n",
    "df_gen_date = pd.date_range(start=\"20221201\",end=\"20221231\", freq=\"MS\")\n",
    "# フォーマットを変えてリストに格納\n",
    "df_date = df_gen_date.to_series().dt.strftime(\"%Y%m\")\n",
    "race_date_list = df_date.values\n",
    "\n",
    "# レース結果対象のurlパスリスト作成\n",
    "scrapy_proc.create_race_path_list(race_date_list)\n",
    "# レース結果のスクレイピング\n",
    "scrapy_proc.coll_grades()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-4. レース結果マスターの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース結果を取得する日付のレンジを指定\n",
    "df_gen_date = pd.date_range(start=\"20140101\",end=\"20221231\", freq=\"MS\")\n",
    "# フォーマットを変えてリストに格納\n",
    "df_date = df_gen_date.to_series().dt.strftime(\"%Y%m\")\n",
    "race_date_list = df_date.values\n",
    "\n",
    "create_dataframe.create_master_grades(race_date_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-6. レース結果マスターの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_master = pd.read_pickle(lps.DATA_GRADES_MASTER, compression='zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-7. 馬IDマスターの作成\n",
    "※現状学習データに含めるつもりはないので実施不要  \n",
    "　今後、学習データに含める場合にコードを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframe.create_master_horseid(grades_master)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-8. 騎手IDマスターの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframe.create_master_jockeyid(grades_master)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-9. 調教師IDマスターの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframe.create_master_trainerid(grades_master)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【未実装】2-10. 馬ごとのレース結果を取得\n",
    "※現状学習データに含めるつもりはないので実施不要  \n",
    "　今後、学習データに含める場合にコードを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_id_list = [\"2018104963\",\"2018105074\"]\n",
    "#horse_id_list = df_horse_id_master.values\n",
    "\n",
    "scrapy_proc.coll_horse_grades(horse_id_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【未実装】2-11. 血統データを取得\n",
    "※現状学習データに含めるつもりはないので実施不要  \n",
    "　今後、学習データに含める場合にコードを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_id_list = [\"2018104963\",\"2018105074\"]\n",
    "#horse_id_list = df_horse_id_master.values\n",
    "\n",
    "scrapy_proc.coll_predigree(horse_id_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重賞一覧取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース結果を取得する日付のレンジを指定\n",
    "df_gen_date = pd.date_range(start=\"2012\",end=\"2022\", freq=\"MS\")\n",
    "# フォーマットを変えてリストに格納\n",
    "df_date = df_gen_date.to_series().dt.strftime(\"%Y\")\n",
    "df_date = df_date.drop_duplicates()\n",
    "juushou_date_list = df_date.values\n",
    "\n",
    "# レース結果のスクレイピング\n",
    "scrapy_proc.coll_juushou(juushou_date_list,lps.DATA_JUUSHOU_LIST)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 前処理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. 前処理に必要なクラスのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース結果マスタを読み込み\n",
    "grades_master = pd.read_pickle(lps.DATA_GRADES_MASTER, compression='zip')\n",
    "# データフレームの処理クラスのインスタンス化\n",
    "grades = dataframe_grades(grades_master, lps, tdp, df_cols, race_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. レース情報を分割し、下記列を追加\n",
    "- 距離\n",
    "- 回り\n",
    "- タイプ\n",
    "- 馬場状態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.train_split_raceinfo()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G1・G2・G3レース列を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.add_G_race()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-3. レース結果マスタのデータ整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 競馬場名を指定\n",
    "# 例：中山\n",
    "place_name = None\n",
    "#place_name = '中山'\n",
    "\n",
    "# 欠損値の削除\n",
    "grades.remove_missing_values()\n",
    "# 体重増減の記号(+)を削除\n",
    "grades.conversion_values()\n",
    "# 性齢を性と齢で分割\n",
    "grades.split_sexual_age()\n",
    "# 競馬場指定(デフォルト指定なし)\n",
    "grades.select_place_name(place_name)\n",
    "# レースタイプを指定(デフォルト指定なし)\n",
    "# 芝・ダート・障\n",
    "# 引数はリスト\n",
    "race_type_list = ['芝','ダート']\n",
    "grades.select_race_type(race_type_list)\n",
    "# スクレイピングの不具合で周りに「障」が含まれているため、その削除\n",
    "#grades.tmp_del_shougai()\n",
    "# 整数型に型変換\n",
    "grades.conversion_int()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-4. レース結果マスタから目的変数用に着順を変更\n",
    "モデルのタイプ  \n",
    "- multiclass_3  \n",
    "  １着　：0  \n",
    "  ２着　：1  \n",
    "  ３着　：2  \n",
    "  その他：3  \n",
    "- multiclass_5  \n",
    "  １着　：0  \n",
    "  ２着　：1  \n",
    "  ３着　：2  \n",
    "  ４着　：3  \n",
    "  ５着　：4  \n",
    "  その他：5  \n",
    "- binaryclass ※上手く動かせない・・・  \n",
    "  １着　：0  \n",
    "  その他：1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.train_data_model_type()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-5. カテゴリ変数(馬名・騎手・調教師)の処理\n",
    "共通で処理するカテゴリ変数  \n",
    "- 回り\n",
    "- タイプ\n",
    "- 性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.category_process()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-6. 学習データの前処理・保存\n",
    "【前処理】  \n",
    "1. アンダーサンプリング  \n",
    "2. ~~標準化~~  \n",
    "  ※決定木では不要なため実施しない  \n",
    "\n",
    "【保存】  \n",
    "- 説明変数  \n",
    "- 目的変数  \n",
    "- 学習データ  \n",
    "- 検証データ  \n",
    "- LightGBMのデータセット  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.data_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.output_grades_master()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. モデルの学習"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. クラスのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_training(lps, tdp, df_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2. モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-04 07:05:54,277]\u001b[0m A new study created in memory with name: no-name-c7a861b1-fcf2-45fe-b044-58acd69de6e5\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/keiba/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/keiba/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/keiba/.local/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.607498\tvalid's binary_logloss: 0.608296\n",
      "[20]\ttrain's binary_logloss: 0.595448\tvalid's binary_logloss: 0.597113\n",
      "[30]\ttrain's binary_logloss: 0.589746\tvalid's binary_logloss: 0.592176\n",
      "[40]\ttrain's binary_logloss: 0.584948\tvalid's binary_logloss: 0.588108\n",
      "[50]\ttrain's binary_logloss: 0.582079\tvalid's binary_logloss: 0.585961\n",
      "[60]\ttrain's binary_logloss: 0.580055\tvalid's binary_logloss: 0.584633\n",
      "[70]\ttrain's binary_logloss: 0.578327\tvalid's binary_logloss: 0.583684\n",
      "[80]\ttrain's binary_logloss: 0.576868\tvalid's binary_logloss: 0.582983\n",
      "[90]\ttrain's binary_logloss: 0.575203\tvalid's binary_logloss: 0.582069\n",
      "[100]\ttrain's binary_logloss: 0.57399\tvalid's binary_logloss: 0.58159\n",
      "[110]\ttrain's binary_logloss: 0.572809\tvalid's binary_logloss: 0.581198\n",
      "[120]\ttrain's binary_logloss: 0.571689\tvalid's binary_logloss: 0.580777\n",
      "[130]\ttrain's binary_logloss: 0.570729\tvalid's binary_logloss: 0.580555\n",
      "[140]\ttrain's binary_logloss: 0.569818\tvalid's binary_logloss: 0.580241\n",
      "[150]\ttrain's binary_logloss: 0.568721\tvalid's binary_logloss: 0.579908\n",
      "[160]\ttrain's binary_logloss: 0.567821\tvalid's binary_logloss: 0.579738\n",
      "[170]\ttrain's binary_logloss: 0.566743\tvalid's binary_logloss: 0.579437\n",
      "[180]\ttrain's binary_logloss: 0.566026\tvalid's binary_logloss: 0.579297\n",
      "[190]\ttrain's binary_logloss: 0.565115\tvalid's binary_logloss: 0.579103\n",
      "[200]\ttrain's binary_logloss: 0.564091\tvalid's binary_logloss: 0.578772\n",
      "[210]\ttrain's binary_logloss: 0.563301\tvalid's binary_logloss: 0.5786\n",
      "[220]\ttrain's binary_logloss: 0.562559\tvalid's binary_logloss: 0.578459\n",
      "[230]\ttrain's binary_logloss: 0.561731\tvalid's binary_logloss: 0.578279\n",
      "[240]\ttrain's binary_logloss: 0.560982\tvalid's binary_logloss: 0.578169\n",
      "[250]\ttrain's binary_logloss: 0.560277\tvalid's binary_logloss: 0.577976\n",
      "[260]\ttrain's binary_logloss: 0.559415\tvalid's binary_logloss: 0.577803\n",
      "[270]\ttrain's binary_logloss: 0.558676\tvalid's binary_logloss: 0.577648\n",
      "[280]\ttrain's binary_logloss: 0.557962\tvalid's binary_logloss: 0.577579\n",
      "[290]\ttrain's binary_logloss: 0.557154\tvalid's binary_logloss: 0.577473\n",
      "[300]\ttrain's binary_logloss: 0.556449\tvalid's binary_logloss: 0.577449\n",
      "[310]\ttrain's binary_logloss: 0.555703\tvalid's binary_logloss: 0.577361\n",
      "[320]\ttrain's binary_logloss: 0.554924\tvalid's binary_logloss: 0.577242\n",
      "[330]\ttrain's binary_logloss: 0.554145\tvalid's binary_logloss: 0.577161\n",
      "[340]\ttrain's binary_logloss: 0.553493\tvalid's binary_logloss: 0.577058\n",
      "[350]\ttrain's binary_logloss: 0.552706\tvalid's binary_logloss: 0.576934\n",
      "[360]\ttrain's binary_logloss: 0.552067\tvalid's binary_logloss: 0.576888\n",
      "[370]\ttrain's binary_logloss: 0.551325\tvalid's binary_logloss: 0.576738\n",
      "Early stopping, best iteration is:\n",
      "[368]\ttrain's binary_logloss: 0.551438\tvalid's binary_logloss: 0.576729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.576729:  14%|#4        | 1/7 [00:05<00:30,  5.05s/it]\u001b[32m[I 2023-01-04 07:05:59,334]\u001b[0m Trial 0 finished with value: 0.5767287099010565 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.5767287099010565.\u001b[0m\n",
      "feature_fraction, val_score: 0.576729:  14%|#4        | 1/7 [00:05<00:30,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.605541\tvalid's binary_logloss: 0.606485\n",
      "[20]\ttrain's binary_logloss: 0.594601\tvalid's binary_logloss: 0.596468\n",
      "[30]\ttrain's binary_logloss: 0.588851\tvalid's binary_logloss: 0.5915\n",
      "[40]\ttrain's binary_logloss: 0.584487\tvalid's binary_logloss: 0.587812\n",
      "[50]\ttrain's binary_logloss: 0.581783\tvalid's binary_logloss: 0.58585\n",
      "[60]\ttrain's binary_logloss: 0.579792\tvalid's binary_logloss: 0.584645\n",
      "[70]\ttrain's binary_logloss: 0.578192\tvalid's binary_logloss: 0.583839\n",
      "[80]\ttrain's binary_logloss: 0.576481\tvalid's binary_logloss: 0.582913\n",
      "[90]\ttrain's binary_logloss: 0.575123\tvalid's binary_logloss: 0.582352\n",
      "[100]\ttrain's binary_logloss: 0.573799\tvalid's binary_logloss: 0.581812\n",
      "[110]\ttrain's binary_logloss: 0.572639\tvalid's binary_logloss: 0.581537\n",
      "[120]\ttrain's binary_logloss: 0.571583\tvalid's binary_logloss: 0.581205\n",
      "[130]\ttrain's binary_logloss: 0.570529\tvalid's binary_logloss: 0.580973\n",
      "[140]\ttrain's binary_logloss: 0.569554\tvalid's binary_logloss: 0.580719\n",
      "[150]\ttrain's binary_logloss: 0.56861\tvalid's binary_logloss: 0.580532\n",
      "[160]\ttrain's binary_logloss: 0.56761\tvalid's binary_logloss: 0.58024\n",
      "[170]\ttrain's binary_logloss: 0.566576\tvalid's binary_logloss: 0.579916\n",
      "[180]\ttrain's binary_logloss: 0.565757\tvalid's binary_logloss: 0.579777\n",
      "[190]\ttrain's binary_logloss: 0.564727\tvalid's binary_logloss: 0.579497\n",
      "[200]\ttrain's binary_logloss: 0.564056\tvalid's binary_logloss: 0.579423\n",
      "[210]\ttrain's binary_logloss: 0.563235\tvalid's binary_logloss: 0.579262\n",
      "[220]\ttrain's binary_logloss: 0.562416\tvalid's binary_logloss: 0.579137\n",
      "[230]\ttrain's binary_logloss: 0.56148\tvalid's binary_logloss: 0.578896\n",
      "[240]\ttrain's binary_logloss: 0.560505\tvalid's binary_logloss: 0.578599\n",
      "[250]\ttrain's binary_logloss: 0.55976\tvalid's binary_logloss: 0.578444\n",
      "[260]\ttrain's binary_logloss: 0.559007\tvalid's binary_logloss: 0.578342\n",
      "[270]\ttrain's binary_logloss: 0.558263\tvalid's binary_logloss: 0.578241\n",
      "[280]\ttrain's binary_logloss: 0.557443\tvalid's binary_logloss: 0.578119\n",
      "[290]\ttrain's binary_logloss: 0.556623\tvalid's binary_logloss: 0.577927\n",
      "[300]\ttrain's binary_logloss: 0.55584\tvalid's binary_logloss: 0.577767\n",
      "[310]\ttrain's binary_logloss: 0.55502\tvalid's binary_logloss: 0.577563\n",
      "[320]\ttrain's binary_logloss: 0.554315\tvalid's binary_logloss: 0.577515\n",
      "[330]\ttrain's binary_logloss: 0.55358\tvalid's binary_logloss: 0.577466\n",
      "[340]\ttrain's binary_logloss: 0.552838\tvalid's binary_logloss: 0.577332\n",
      "[350]\ttrain's binary_logloss: 0.552104\tvalid's binary_logloss: 0.577288\n",
      "[360]\ttrain's binary_logloss: 0.551487\tvalid's binary_logloss: 0.577221\n",
      "[370]\ttrain's binary_logloss: 0.550682\tvalid's binary_logloss: 0.57709\n",
      "[380]\ttrain's binary_logloss: 0.550041\tvalid's binary_logloss: 0.576996\n",
      "[390]\ttrain's binary_logloss: 0.549271\tvalid's binary_logloss: 0.576845\n",
      "[400]\ttrain's binary_logloss: 0.548617\tvalid's binary_logloss: 0.576763\n",
      "[410]\ttrain's binary_logloss: 0.54796\tvalid's binary_logloss: 0.576662\n",
      "[420]\ttrain's binary_logloss: 0.547126\tvalid's binary_logloss: 0.576535\n",
      "[430]\ttrain's binary_logloss: 0.546442\tvalid's binary_logloss: 0.576512\n",
      "[440]\ttrain's binary_logloss: 0.545827\tvalid's binary_logloss: 0.576437\n",
      "[450]\ttrain's binary_logloss: 0.545072\tvalid's binary_logloss: 0.576343\n",
      "[460]\ttrain's binary_logloss: 0.544456\tvalid's binary_logloss: 0.576281\n",
      "[470]\ttrain's binary_logloss: 0.543694\tvalid's binary_logloss: 0.576212\n",
      "[480]\ttrain's binary_logloss: 0.543081\tvalid's binary_logloss: 0.576126\n",
      "[490]\ttrain's binary_logloss: 0.542386\tvalid's binary_logloss: 0.575991\n",
      "[500]\ttrain's binary_logloss: 0.541665\tvalid's binary_logloss: 0.57594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575815:  29%|##8       | 2/7 [00:13<00:35,  7.18s/it]\u001b[32m[I 2023-01-04 07:06:08,010]\u001b[0m Trial 1 finished with value: 0.5758150967970606 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.5758150967970606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510]\ttrain's binary_logloss: 0.540975\tvalid's binary_logloss: 0.575868\n",
      "[520]\ttrain's binary_logloss: 0.540395\tvalid's binary_logloss: 0.575819\n",
      "[530]\ttrain's binary_logloss: 0.539765\tvalid's binary_logloss: 0.575819\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttrain's binary_logloss: 0.53994\tvalid's binary_logloss: 0.575815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575815:  29%|##8       | 2/7 [00:13<00:35,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.604335\tvalid's binary_logloss: 0.605208\n",
      "[20]\ttrain's binary_logloss: 0.593591\tvalid's binary_logloss: 0.595442\n",
      "[30]\ttrain's binary_logloss: 0.587988\tvalid's binary_logloss: 0.590673\n",
      "[40]\ttrain's binary_logloss: 0.584537\tvalid's binary_logloss: 0.587974\n",
      "[50]\ttrain's binary_logloss: 0.582033\tvalid's binary_logloss: 0.586251\n",
      "[60]\ttrain's binary_logloss: 0.579985\tvalid's binary_logloss: 0.585078\n",
      "[70]\ttrain's binary_logloss: 0.578167\tvalid's binary_logloss: 0.584101\n",
      "[80]\ttrain's binary_logloss: 0.576525\tvalid's binary_logloss: 0.583156\n",
      "[90]\ttrain's binary_logloss: 0.575106\tvalid's binary_logloss: 0.582461\n",
      "[100]\ttrain's binary_logloss: 0.573774\tvalid's binary_logloss: 0.582\n",
      "[110]\ttrain's binary_logloss: 0.572597\tvalid's binary_logloss: 0.581686\n",
      "[120]\ttrain's binary_logloss: 0.571585\tvalid's binary_logloss: 0.581434\n",
      "[130]\ttrain's binary_logloss: 0.570524\tvalid's binary_logloss: 0.581183\n",
      "[140]\ttrain's binary_logloss: 0.569554\tvalid's binary_logloss: 0.580916\n",
      "[150]\ttrain's binary_logloss: 0.568619\tvalid's binary_logloss: 0.58079\n",
      "[160]\ttrain's binary_logloss: 0.567537\tvalid's binary_logloss: 0.580441\n",
      "[170]\ttrain's binary_logloss: 0.566561\tvalid's binary_logloss: 0.580308\n",
      "[180]\ttrain's binary_logloss: 0.565631\tvalid's binary_logloss: 0.580186\n",
      "[190]\ttrain's binary_logloss: 0.564706\tvalid's binary_logloss: 0.580111\n",
      "[200]\ttrain's binary_logloss: 0.563834\tvalid's binary_logloss: 0.57997\n",
      "[210]\ttrain's binary_logloss: 0.562978\tvalid's binary_logloss: 0.579721\n",
      "[220]\ttrain's binary_logloss: 0.562147\tvalid's binary_logloss: 0.579519\n",
      "[230]\ttrain's binary_logloss: 0.561259\tvalid's binary_logloss: 0.57934\n",
      "[240]\ttrain's binary_logloss: 0.560196\tvalid's binary_logloss: 0.578987\n",
      "[250]\ttrain's binary_logloss: 0.559396\tvalid's binary_logloss: 0.578848\n",
      "[260]\ttrain's binary_logloss: 0.5585\tvalid's binary_logloss: 0.578725\n",
      "[270]\ttrain's binary_logloss: 0.557761\tvalid's binary_logloss: 0.57861\n",
      "[280]\ttrain's binary_logloss: 0.556782\tvalid's binary_logloss: 0.578404\n",
      "[290]\ttrain's binary_logloss: 0.556072\tvalid's binary_logloss: 0.57834\n",
      "[300]\ttrain's binary_logloss: 0.555318\tvalid's binary_logloss: 0.578158\n",
      "[310]\ttrain's binary_logloss: 0.554484\tvalid's binary_logloss: 0.578071\n",
      "[320]\ttrain's binary_logloss: 0.553762\tvalid's binary_logloss: 0.577983\n",
      "[330]\ttrain's binary_logloss: 0.553034\tvalid's binary_logloss: 0.577946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575815:  43%|####2     | 3/7 [00:21<00:30,  7.66s/it]\u001b[32m[I 2023-01-04 07:06:16,247]\u001b[0m Trial 2 finished with value: 0.5778329482617587 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.5758150967970606.\u001b[0m\n",
      "feature_fraction, val_score: 0.575815:  43%|####2     | 3/7 [00:21<00:30,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340]\ttrain's binary_logloss: 0.55228\tvalid's binary_logloss: 0.577852\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttrain's binary_logloss: 0.552395\tvalid's binary_logloss: 0.577833\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.608409\tvalid's binary_logloss: 0.609291\n",
      "[20]\ttrain's binary_logloss: 0.596946\tvalid's binary_logloss: 0.598642\n",
      "[30]\ttrain's binary_logloss: 0.591038\tvalid's binary_logloss: 0.593505\n",
      "[40]\ttrain's binary_logloss: 0.586009\tvalid's binary_logloss: 0.58917\n",
      "[50]\ttrain's binary_logloss: 0.582404\tvalid's binary_logloss: 0.586126\n",
      "[60]\ttrain's binary_logloss: 0.580334\tvalid's binary_logloss: 0.584778\n",
      "[70]\ttrain's binary_logloss: 0.578624\tvalid's binary_logloss: 0.58385\n",
      "[80]\ttrain's binary_logloss: 0.577257\tvalid's binary_logloss: 0.583004\n",
      "[90]\ttrain's binary_logloss: 0.576014\tvalid's binary_logloss: 0.582377\n",
      "[100]\ttrain's binary_logloss: 0.574751\tvalid's binary_logloss: 0.581822\n",
      "[110]\ttrain's binary_logloss: 0.573611\tvalid's binary_logloss: 0.581417\n",
      "[120]\ttrain's binary_logloss: 0.572603\tvalid's binary_logloss: 0.581005\n",
      "[130]\ttrain's binary_logloss: 0.571594\tvalid's binary_logloss: 0.58065\n",
      "[140]\ttrain's binary_logloss: 0.570563\tvalid's binary_logloss: 0.580222\n",
      "[150]\ttrain's binary_logloss: 0.569472\tvalid's binary_logloss: 0.579858\n",
      "[160]\ttrain's binary_logloss: 0.568433\tvalid's binary_logloss: 0.579472\n",
      "[170]\ttrain's binary_logloss: 0.567499\tvalid's binary_logloss: 0.579242\n",
      "[180]\ttrain's binary_logloss: 0.566742\tvalid's binary_logloss: 0.579047\n",
      "[190]\ttrain's binary_logloss: 0.565848\tvalid's binary_logloss: 0.578818\n",
      "[200]\ttrain's binary_logloss: 0.565067\tvalid's binary_logloss: 0.578589\n",
      "[210]\ttrain's binary_logloss: 0.564167\tvalid's binary_logloss: 0.578285\n",
      "[220]\ttrain's binary_logloss: 0.563531\tvalid's binary_logloss: 0.578199\n",
      "[230]\ttrain's binary_logloss: 0.562746\tvalid's binary_logloss: 0.578049\n",
      "[240]\ttrain's binary_logloss: 0.562045\tvalid's binary_logloss: 0.577918\n",
      "[250]\ttrain's binary_logloss: 0.561338\tvalid's binary_logloss: 0.577725\n",
      "[260]\ttrain's binary_logloss: 0.560629\tvalid's binary_logloss: 0.57753\n",
      "[270]\ttrain's binary_logloss: 0.559921\tvalid's binary_logloss: 0.57736\n",
      "[280]\ttrain's binary_logloss: 0.559199\tvalid's binary_logloss: 0.577268\n",
      "[290]\ttrain's binary_logloss: 0.558408\tvalid's binary_logloss: 0.577017\n",
      "[300]\ttrain's binary_logloss: 0.557843\tvalid's binary_logloss: 0.576909\n",
      "[310]\ttrain's binary_logloss: 0.557165\tvalid's binary_logloss: 0.576738\n",
      "[320]\ttrain's binary_logloss: 0.556526\tvalid's binary_logloss: 0.576643\n",
      "[330]\ttrain's binary_logloss: 0.555803\tvalid's binary_logloss: 0.576505\n",
      "[340]\ttrain's binary_logloss: 0.555209\tvalid's binary_logloss: 0.576494\n",
      "[350]\ttrain's binary_logloss: 0.554447\tvalid's binary_logloss: 0.576426\n",
      "[360]\ttrain's binary_logloss: 0.553789\tvalid's binary_logloss: 0.576286\n",
      "[370]\ttrain's binary_logloss: 0.553151\tvalid's binary_logloss: 0.576198\n",
      "[380]\ttrain's binary_logloss: 0.552508\tvalid's binary_logloss: 0.576086\n",
      "[390]\ttrain's binary_logloss: 0.551792\tvalid's binary_logloss: 0.575931\n",
      "[400]\ttrain's binary_logloss: 0.551233\tvalid's binary_logloss: 0.575815\n",
      "[410]\ttrain's binary_logloss: 0.550601\tvalid's binary_logloss: 0.575667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575645:  57%|#####7    | 4/7 [00:30<00:23,  7.90s/it]\u001b[32m[I 2023-01-04 07:06:24,497]\u001b[0m Trial 3 finished with value: 0.5756445071901048 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.5756445071901048.\u001b[0m\n",
      "feature_fraction, val_score: 0.575645:  57%|#####7    | 4/7 [00:30<00:23,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[420]\ttrain's binary_logloss: 0.549959\tvalid's binary_logloss: 0.575673\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttrain's binary_logloss: 0.550425\tvalid's binary_logloss: 0.575645\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.603131\tvalid's binary_logloss: 0.60404\n",
      "[20]\ttrain's binary_logloss: 0.594033\tvalid's binary_logloss: 0.595927\n",
      "[30]\ttrain's binary_logloss: 0.588545\tvalid's binary_logloss: 0.591382\n",
      "[40]\ttrain's binary_logloss: 0.584985\tvalid's binary_logloss: 0.588802\n",
      "[50]\ttrain's binary_logloss: 0.582137\tvalid's binary_logloss: 0.586897\n",
      "[60]\ttrain's binary_logloss: 0.579826\tvalid's binary_logloss: 0.585451\n",
      "[70]\ttrain's binary_logloss: 0.577909\tvalid's binary_logloss: 0.584438\n",
      "[80]\ttrain's binary_logloss: 0.576423\tvalid's binary_logloss: 0.583756\n",
      "[90]\ttrain's binary_logloss: 0.575058\tvalid's binary_logloss: 0.583409\n",
      "[100]\ttrain's binary_logloss: 0.573744\tvalid's binary_logloss: 0.583126\n",
      "[110]\ttrain's binary_logloss: 0.5724\tvalid's binary_logloss: 0.582659\n",
      "[120]\ttrain's binary_logloss: 0.571144\tvalid's binary_logloss: 0.582283\n",
      "[130]\ttrain's binary_logloss: 0.569997\tvalid's binary_logloss: 0.581918\n",
      "[140]\ttrain's binary_logloss: 0.568952\tvalid's binary_logloss: 0.581695\n",
      "[150]\ttrain's binary_logloss: 0.567765\tvalid's binary_logloss: 0.581334\n",
      "[160]\ttrain's binary_logloss: 0.566776\tvalid's binary_logloss: 0.581172\n",
      "[170]\ttrain's binary_logloss: 0.565714\tvalid's binary_logloss: 0.580953\n",
      "[180]\ttrain's binary_logloss: 0.564633\tvalid's binary_logloss: 0.580712\n",
      "[190]\ttrain's binary_logloss: 0.563694\tvalid's binary_logloss: 0.580483\n",
      "[200]\ttrain's binary_logloss: 0.562799\tvalid's binary_logloss: 0.580369\n",
      "[210]\ttrain's binary_logloss: 0.561912\tvalid's binary_logloss: 0.58033\n",
      "[220]\ttrain's binary_logloss: 0.560965\tvalid's binary_logloss: 0.580175\n",
      "[230]\ttrain's binary_logloss: 0.560042\tvalid's binary_logloss: 0.579975\n",
      "[240]\ttrain's binary_logloss: 0.558998\tvalid's binary_logloss: 0.579819\n",
      "[250]\ttrain's binary_logloss: 0.558098\tvalid's binary_logloss: 0.579618\n",
      "[260]\ttrain's binary_logloss: 0.557198\tvalid's binary_logloss: 0.579396\n",
      "[270]\ttrain's binary_logloss: 0.55626\tvalid's binary_logloss: 0.579229\n",
      "[280]\ttrain's binary_logloss: 0.555372\tvalid's binary_logloss: 0.579081\n",
      "[290]\ttrain's binary_logloss: 0.554507\tvalid's binary_logloss: 0.578925\n",
      "[300]\ttrain's binary_logloss: 0.553622\tvalid's binary_logloss: 0.57874\n",
      "[310]\ttrain's binary_logloss: 0.552834\tvalid's binary_logloss: 0.578719\n",
      "[320]\ttrain's binary_logloss: 0.551939\tvalid's binary_logloss: 0.578556\n",
      "[330]\ttrain's binary_logloss: 0.551121\tvalid's binary_logloss: 0.578434\n",
      "[340]\ttrain's binary_logloss: 0.550258\tvalid's binary_logloss: 0.578381\n",
      "[350]\ttrain's binary_logloss: 0.549477\tvalid's binary_logloss: 0.578279\n",
      "[360]\ttrain's binary_logloss: 0.548598\tvalid's binary_logloss: 0.578235\n",
      "[370]\ttrain's binary_logloss: 0.547764\tvalid's binary_logloss: 0.5782\n",
      "[380]\ttrain's binary_logloss: 0.546882\tvalid's binary_logloss: 0.578144\n",
      "[390]\ttrain's binary_logloss: 0.545924\tvalid's binary_logloss: 0.577961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575645:  71%|#######1  | 5/7 [00:37<00:15,  7.60s/it]\u001b[32m[I 2023-01-04 07:06:31,579]\u001b[0m Trial 4 finished with value: 0.5779605731851726 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.5756445071901048.\u001b[0m\n",
      "feature_fraction, val_score: 0.575645:  71%|#######1  | 5/7 [00:37<00:15,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's binary_logloss: 0.545214\tvalid's binary_logloss: 0.577978\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttrain's binary_logloss: 0.545924\tvalid's binary_logloss: 0.577961\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.603465\tvalid's binary_logloss: 0.60433\n",
      "[20]\ttrain's binary_logloss: 0.593929\tvalid's binary_logloss: 0.595709\n",
      "[30]\ttrain's binary_logloss: 0.588644\tvalid's binary_logloss: 0.591459\n",
      "[40]\ttrain's binary_logloss: 0.584864\tvalid's binary_logloss: 0.588582\n",
      "[50]\ttrain's binary_logloss: 0.582088\tvalid's binary_logloss: 0.586662\n",
      "[60]\ttrain's binary_logloss: 0.579947\tvalid's binary_logloss: 0.585363\n",
      "[70]\ttrain's binary_logloss: 0.578115\tvalid's binary_logloss: 0.584346\n",
      "[80]\ttrain's binary_logloss: 0.576652\tvalid's binary_logloss: 0.583701\n",
      "[90]\ttrain's binary_logloss: 0.575184\tvalid's binary_logloss: 0.58309\n",
      "[100]\ttrain's binary_logloss: 0.573918\tvalid's binary_logloss: 0.582611\n",
      "[110]\ttrain's binary_logloss: 0.572617\tvalid's binary_logloss: 0.582124\n",
      "[120]\ttrain's binary_logloss: 0.571531\tvalid's binary_logloss: 0.581857\n",
      "[130]\ttrain's binary_logloss: 0.570414\tvalid's binary_logloss: 0.581614\n",
      "[140]\ttrain's binary_logloss: 0.569364\tvalid's binary_logloss: 0.581469\n",
      "[150]\ttrain's binary_logloss: 0.568327\tvalid's binary_logloss: 0.581291\n",
      "[160]\ttrain's binary_logloss: 0.567354\tvalid's binary_logloss: 0.581123\n",
      "[170]\ttrain's binary_logloss: 0.566133\tvalid's binary_logloss: 0.580747\n",
      "[180]\ttrain's binary_logloss: 0.565154\tvalid's binary_logloss: 0.580602\n",
      "[190]\ttrain's binary_logloss: 0.564211\tvalid's binary_logloss: 0.580352\n",
      "[200]\ttrain's binary_logloss: 0.563365\tvalid's binary_logloss: 0.580218\n",
      "[210]\ttrain's binary_logloss: 0.562419\tvalid's binary_logloss: 0.580033\n",
      "[220]\ttrain's binary_logloss: 0.561517\tvalid's binary_logloss: 0.579959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575645:  86%|########5 | 6/7 [00:59<00:12, 12.71s/it]\u001b[32m[I 2023-01-04 07:06:54,192]\u001b[0m Trial 5 finished with value: 0.579737533313619 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.5756445071901048.\u001b[0m\n",
      "feature_fraction, val_score: 0.575645:  86%|########5 | 6/7 [00:59<00:12, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230]\ttrain's binary_logloss: 0.560588\tvalid's binary_logloss: 0.579785\n",
      "[240]\ttrain's binary_logloss: 0.559823\tvalid's binary_logloss: 0.579756\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttrain's binary_logloss: 0.560311\tvalid's binary_logloss: 0.579738\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.604003\tvalid's binary_logloss: 0.604932\n",
      "[20]\ttrain's binary_logloss: 0.59384\tvalid's binary_logloss: 0.595662\n",
      "[30]\ttrain's binary_logloss: 0.588347\tvalid's binary_logloss: 0.59101\n",
      "[40]\ttrain's binary_logloss: 0.584838\tvalid's binary_logloss: 0.588464\n",
      "[50]\ttrain's binary_logloss: 0.581991\tvalid's binary_logloss: 0.586513\n",
      "[60]\ttrain's binary_logloss: 0.579914\tvalid's binary_logloss: 0.585276\n",
      "[70]\ttrain's binary_logloss: 0.577988\tvalid's binary_logloss: 0.58412\n",
      "[80]\ttrain's binary_logloss: 0.576614\tvalid's binary_logloss: 0.583563\n",
      "[90]\ttrain's binary_logloss: 0.575221\tvalid's binary_logloss: 0.582999\n",
      "[100]\ttrain's binary_logloss: 0.57406\tvalid's binary_logloss: 0.582641\n",
      "[110]\ttrain's binary_logloss: 0.572867\tvalid's binary_logloss: 0.582385\n",
      "[120]\ttrain's binary_logloss: 0.5715\tvalid's binary_logloss: 0.581881\n",
      "[130]\ttrain's binary_logloss: 0.57041\tvalid's binary_logloss: 0.581674\n",
      "[140]\ttrain's binary_logloss: 0.569331\tvalid's binary_logloss: 0.581379\n",
      "[150]\ttrain's binary_logloss: 0.568368\tvalid's binary_logloss: 0.581209\n",
      "[160]\ttrain's binary_logloss: 0.56723\tvalid's binary_logloss: 0.580764\n",
      "[170]\ttrain's binary_logloss: 0.566284\tvalid's binary_logloss: 0.580541\n",
      "[180]\ttrain's binary_logloss: 0.56547\tvalid's binary_logloss: 0.580501\n",
      "[190]\ttrain's binary_logloss: 0.564431\tvalid's binary_logloss: 0.580268\n",
      "[200]\ttrain's binary_logloss: 0.563441\tvalid's binary_logloss: 0.580102\n",
      "[210]\ttrain's binary_logloss: 0.562534\tvalid's binary_logloss: 0.579949\n",
      "[220]\ttrain's binary_logloss: 0.561629\tvalid's binary_logloss: 0.579783\n",
      "[230]\ttrain's binary_logloss: 0.560603\tvalid's binary_logloss: 0.579596\n",
      "[240]\ttrain's binary_logloss: 0.559759\tvalid's binary_logloss: 0.57949\n",
      "[250]\ttrain's binary_logloss: 0.558915\tvalid's binary_logloss: 0.579441\n",
      "[260]\ttrain's binary_logloss: 0.557995\tvalid's binary_logloss: 0.579112\n",
      "[270]\ttrain's binary_logloss: 0.557225\tvalid's binary_logloss: 0.578993\n",
      "[280]\ttrain's binary_logloss: 0.556461\tvalid's binary_logloss: 0.578878\n",
      "[290]\ttrain's binary_logloss: 0.555606\tvalid's binary_logloss: 0.578678\n",
      "[300]\ttrain's binary_logloss: 0.554752\tvalid's binary_logloss: 0.578563\n",
      "[310]\ttrain's binary_logloss: 0.553932\tvalid's binary_logloss: 0.578489\n",
      "[320]\ttrain's binary_logloss: 0.553198\tvalid's binary_logloss: 0.578331\n",
      "[330]\ttrain's binary_logloss: 0.552389\tvalid's binary_logloss: 0.578215\n",
      "[340]\ttrain's binary_logloss: 0.551475\tvalid's binary_logloss: 0.578095\n",
      "[350]\ttrain's binary_logloss: 0.550662\tvalid's binary_logloss: 0.577986\n",
      "[360]\ttrain's binary_logloss: 0.549936\tvalid's binary_logloss: 0.577896\n",
      "[370]\ttrain's binary_logloss: 0.549132\tvalid's binary_logloss: 0.577826\n",
      "[380]\ttrain's binary_logloss: 0.548393\tvalid's binary_logloss: 0.577687\n",
      "[390]\ttrain's binary_logloss: 0.547504\tvalid's binary_logloss: 0.577539\n",
      "[400]\ttrain's binary_logloss: 0.546753\tvalid's binary_logloss: 0.577482\n",
      "[410]\ttrain's binary_logloss: 0.545941\tvalid's binary_logloss: 0.57741\n",
      "[420]\ttrain's binary_logloss: 0.545158\tvalid's binary_logloss: 0.577269\n",
      "[430]\ttrain's binary_logloss: 0.544426\tvalid's binary_logloss: 0.577157\n",
      "[440]\ttrain's binary_logloss: 0.543705\tvalid's binary_logloss: 0.577094\n",
      "[450]\ttrain's binary_logloss: 0.542857\tvalid's binary_logloss: 0.576944\n",
      "[460]\ttrain's binary_logloss: 0.542119\tvalid's binary_logloss: 0.576889\n",
      "[470]\ttrain's binary_logloss: 0.541383\tvalid's binary_logloss: 0.576837\n",
      "[480]\ttrain's binary_logloss: 0.540619\tvalid's binary_logloss: 0.576683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.575645: 100%|##########| 7/7 [01:07<00:00, 10.92s/it]\u001b[32m[I 2023-01-04 07:07:01,446]\u001b[0m Trial 6 finished with value: 0.5766135920014501 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.5756445071901048.\u001b[0m\n",
      "feature_fraction, val_score: 0.575645: 100%|##########| 7/7 [01:07<00:00,  9.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[490]\ttrain's binary_logloss: 0.539939\tvalid's binary_logloss: 0.576651\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttrain's binary_logloss: 0.540148\tvalid's binary_logloss: 0.576614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.575645:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.596623\tvalid's binary_logloss: 0.601931\n",
      "[20]\ttrain's binary_logloss: 0.579828\tvalid's binary_logloss: 0.59008\n",
      "[30]\ttrain's binary_logloss: 0.56916\tvalid's binary_logloss: 0.584103\n",
      "[40]\ttrain's binary_logloss: 0.559253\tvalid's binary_logloss: 0.579368\n",
      "[50]\ttrain's binary_logloss: 0.551716\tvalid's binary_logloss: 0.577182\n",
      "[60]\ttrain's binary_logloss: 0.546111\tvalid's binary_logloss: 0.576095\n",
      "[70]\ttrain's binary_logloss: 0.54117\tvalid's binary_logloss: 0.575449\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.537202\tvalid's binary_logloss: 0.575061\n",
      "[90]\ttrain's binary_logloss: 0.532732\tvalid's binary_logloss: 0.574616\n",
      "[100]\ttrain's binary_logloss: 0.528158\tvalid's binary_logloss: 0.574097\n",
      "[110]\ttrain's binary_logloss: 0.523618\tvalid's binary_logloss: 0.573725\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.520026\tvalid's binary_logloss: 0.573467\n",
      "[130]\ttrain's binary_logloss: 0.516232\tvalid's binary_logloss: 0.573317\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.513272\tvalid's binary_logloss: 0.57304\n",
      "[150]\ttrain's binary_logloss: 0.509762\tvalid's binary_logloss: 0.572957\n",
      "[160]\ttrain's binary_logloss: 0.50636\tvalid's binary_logloss: 0.572827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:   5%|5         | 1/20 [00:07<02:31,  7.96s/it]\u001b[32m[I 2023-01-04 07:07:09,412]\u001b[0m Trial 7 finished with value: 0.5726995641451669 and parameters: {'num_leaves': 233}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:   5%|5         | 1/20 [00:07<02:31,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain's binary_logloss: 0.502458\tvalid's binary_logloss: 0.572813\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.504984\tvalid's binary_logloss: 0.5727\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.603331\tvalid's binary_logloss: 0.605299\n",
      "[20]\ttrain's binary_logloss: 0.590219\tvalid's binary_logloss: 0.594017\n",
      "[30]\ttrain's binary_logloss: 0.582848\tvalid's binary_logloss: 0.588305\n",
      "[40]\ttrain's binary_logloss: 0.576407\tvalid's binary_logloss: 0.583737\n",
      "[50]\ttrain's binary_logloss: 0.572087\tvalid's binary_logloss: 0.581321\n",
      "[60]\ttrain's binary_logloss: 0.569159\tvalid's binary_logloss: 0.580129\n",
      "[70]\ttrain's binary_logloss: 0.566597\tvalid's binary_logloss: 0.57925\n",
      "[80]\ttrain's binary_logloss: 0.564575\tvalid's binary_logloss: 0.578676\n",
      "[90]\ttrain's binary_logloss: 0.562277\tvalid's binary_logloss: 0.578053\n",
      "[100]\ttrain's binary_logloss: 0.559984\tvalid's binary_logloss: 0.577535\n",
      "[110]\ttrain's binary_logloss: 0.557855\tvalid's binary_logloss: 0.577067\n",
      "[120]\ttrain's binary_logloss: 0.556191\tvalid's binary_logloss: 0.576825\n",
      "[130]\ttrain's binary_logloss: 0.554313\tvalid's binary_logloss: 0.576399\n",
      "[140]\ttrain's binary_logloss: 0.552735\tvalid's binary_logloss: 0.576204\n",
      "[150]\ttrain's binary_logloss: 0.550796\tvalid's binary_logloss: 0.57579\n",
      "[160]\ttrain's binary_logloss: 0.549147\tvalid's binary_logloss: 0.57551\n",
      "[170]\ttrain's binary_logloss: 0.547425\tvalid's binary_logloss: 0.575381\n",
      "[180]\ttrain's binary_logloss: 0.546015\tvalid's binary_logloss: 0.57523\n",
      "[190]\ttrain's binary_logloss: 0.544211\tvalid's binary_logloss: 0.574915\n",
      "[200]\ttrain's binary_logloss: 0.542657\tvalid's binary_logloss: 0.574848\n",
      "[210]\ttrain's binary_logloss: 0.541072\tvalid's binary_logloss: 0.574666\n",
      "[220]\ttrain's binary_logloss: 0.539776\tvalid's binary_logloss: 0.574594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  10%|#         | 2/20 [00:16<02:28,  8.25s/it]\u001b[32m[I 2023-01-04 07:07:17,876]\u001b[0m Trial 8 finished with value: 0.574467084372118 and parameters: {'num_leaves': 80}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  10%|#         | 2/20 [00:16<02:28,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230]\ttrain's binary_logloss: 0.538249\tvalid's binary_logloss: 0.574513\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttrain's binary_logloss: 0.538665\tvalid's binary_logloss: 0.574467\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.602628\tvalid's binary_logloss: 0.604761\n",
      "[20]\ttrain's binary_logloss: 0.589302\tvalid's binary_logloss: 0.593434\n",
      "[30]\ttrain's binary_logloss: 0.581615\tvalid's binary_logloss: 0.587706\n",
      "[40]\ttrain's binary_logloss: 0.574919\tvalid's binary_logloss: 0.583111\n",
      "[50]\ttrain's binary_logloss: 0.570339\tvalid's binary_logloss: 0.580627\n",
      "[60]\ttrain's binary_logloss: 0.567277\tvalid's binary_logloss: 0.579461\n",
      "[70]\ttrain's binary_logloss: 0.56454\tvalid's binary_logloss: 0.578581\n",
      "[80]\ttrain's binary_logloss: 0.562314\tvalid's binary_logloss: 0.578033\n",
      "[90]\ttrain's binary_logloss: 0.559884\tvalid's binary_logloss: 0.5776\n",
      "[100]\ttrain's binary_logloss: 0.557361\tvalid's binary_logloss: 0.577097\n",
      "[110]\ttrain's binary_logloss: 0.555068\tvalid's binary_logloss: 0.576684\n",
      "[120]\ttrain's binary_logloss: 0.55328\tvalid's binary_logloss: 0.576442\n",
      "[130]\ttrain's binary_logloss: 0.551191\tvalid's binary_logloss: 0.576151\n",
      "[140]\ttrain's binary_logloss: 0.549493\tvalid's binary_logloss: 0.575957\n",
      "[150]\ttrain's binary_logloss: 0.547481\tvalid's binary_logloss: 0.575633\n",
      "[160]\ttrain's binary_logloss: 0.545644\tvalid's binary_logloss: 0.575443\n",
      "[170]\ttrain's binary_logloss: 0.543768\tvalid's binary_logloss: 0.575331\n",
      "[180]\ttrain's binary_logloss: 0.542181\tvalid's binary_logloss: 0.57522\n",
      "[190]\ttrain's binary_logloss: 0.54044\tvalid's binary_logloss: 0.575033\n",
      "[200]\ttrain's binary_logloss: 0.538649\tvalid's binary_logloss: 0.574814\n",
      "[210]\ttrain's binary_logloss: 0.536966\tvalid's binary_logloss: 0.574704\n",
      "[220]\ttrain's binary_logloss: 0.535565\tvalid's binary_logloss: 0.574537\n",
      "[230]\ttrain's binary_logloss: 0.533754\tvalid's binary_logloss: 0.574317\n",
      "[240]\ttrain's binary_logloss: 0.532353\tvalid's binary_logloss: 0.574214\n",
      "[250]\ttrain's binary_logloss: 0.530773\tvalid's binary_logloss: 0.574034\n",
      "[260]\ttrain's binary_logloss: 0.529417\tvalid's binary_logloss: 0.573969\n",
      "[270]\ttrain's binary_logloss: 0.528146\tvalid's binary_logloss: 0.573934\n",
      "[280]\ttrain's binary_logloss: 0.526526\tvalid's binary_logloss: 0.573874\n",
      "[290]\ttrain's binary_logloss: 0.525088\tvalid's binary_logloss: 0.573723\n",
      "[300]\ttrain's binary_logloss: 0.523876\tvalid's binary_logloss: 0.573714\n",
      "[310]\ttrain's binary_logloss: 0.521985\tvalid's binary_logloss: 0.573484\n",
      "[320]\ttrain's binary_logloss: 0.52067\tvalid's binary_logloss: 0.573468\n",
      "[330]\ttrain's binary_logloss: 0.519234\tvalid's binary_logloss: 0.573364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  15%|#5        | 3/20 [00:23<02:08,  7.57s/it]\u001b[32m[I 2023-01-04 07:07:24,631]\u001b[0m Trial 9 finished with value: 0.5733375297443012 and parameters: {'num_leaves': 90}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  15%|#5        | 3/20 [00:23<02:08,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[328]\ttrain's binary_logloss: 0.519429\tvalid's binary_logloss: 0.573338\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.60183\tvalid's binary_logloss: 0.604347\n",
      "[20]\ttrain's binary_logloss: 0.587925\tvalid's binary_logloss: 0.592787\n",
      "[30]\ttrain's binary_logloss: 0.579869\tvalid's binary_logloss: 0.58698\n",
      "[40]\ttrain's binary_logloss: 0.572769\tvalid's binary_logloss: 0.582436\n",
      "[50]\ttrain's binary_logloss: 0.5677\tvalid's binary_logloss: 0.579841\n",
      "[60]\ttrain's binary_logloss: 0.56432\tvalid's binary_logloss: 0.57869\n",
      "[70]\ttrain's binary_logloss: 0.561314\tvalid's binary_logloss: 0.577941\n",
      "[80]\ttrain's binary_logloss: 0.558788\tvalid's binary_logloss: 0.577207\n",
      "[90]\ttrain's binary_logloss: 0.555967\tvalid's binary_logloss: 0.576486\n",
      "[100]\ttrain's binary_logloss: 0.553284\tvalid's binary_logloss: 0.576087\n",
      "[110]\ttrain's binary_logloss: 0.550722\tvalid's binary_logloss: 0.575702\n",
      "[120]\ttrain's binary_logloss: 0.548667\tvalid's binary_logloss: 0.575497\n",
      "[130]\ttrain's binary_logloss: 0.546407\tvalid's binary_logloss: 0.575274\n",
      "[140]\ttrain's binary_logloss: 0.544478\tvalid's binary_logloss: 0.57511\n",
      "[150]\ttrain's binary_logloss: 0.542256\tvalid's binary_logloss: 0.574851\n",
      "[160]\ttrain's binary_logloss: 0.539959\tvalid's binary_logloss: 0.574638\n",
      "[170]\ttrain's binary_logloss: 0.53775\tvalid's binary_logloss: 0.57443\n",
      "[180]\ttrain's binary_logloss: 0.535886\tvalid's binary_logloss: 0.57423\n",
      "[190]\ttrain's binary_logloss: 0.533857\tvalid's binary_logloss: 0.57398\n",
      "[200]\ttrain's binary_logloss: 0.532024\tvalid's binary_logloss: 0.573739\n",
      "[210]\ttrain's binary_logloss: 0.530035\tvalid's binary_logloss: 0.573558\n",
      "[220]\ttrain's binary_logloss: 0.528557\tvalid's binary_logloss: 0.573512\n",
      "[230]\ttrain's binary_logloss: 0.526856\tvalid's binary_logloss: 0.573397\n",
      "[240]\ttrain's binary_logloss: 0.525324\tvalid's binary_logloss: 0.573273\n",
      "[250]\ttrain's binary_logloss: 0.523558\tvalid's binary_logloss: 0.573198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  20%|##        | 4/20 [00:28<01:44,  6.56s/it]\u001b[32m[I 2023-01-04 07:07:29,635]\u001b[0m Trial 10 finished with value: 0.5730636035511097 and parameters: {'num_leaves': 106}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  20%|##        | 4/20 [00:28<01:44,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\ttrain's binary_logloss: 0.521886\tvalid's binary_logloss: 0.57307\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttrain's binary_logloss: 0.522521\tvalid's binary_logloss: 0.573064\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.596389\tvalid's binary_logloss: 0.601867\n",
      "[20]\ttrain's binary_logloss: 0.579439\tvalid's binary_logloss: 0.590084\n",
      "[30]\ttrain's binary_logloss: 0.568606\tvalid's binary_logloss: 0.583997\n",
      "[40]\ttrain's binary_logloss: 0.558455\tvalid's binary_logloss: 0.579168\n",
      "[50]\ttrain's binary_logloss: 0.550783\tvalid's binary_logloss: 0.576933\n",
      "[60]\ttrain's binary_logloss: 0.545152\tvalid's binary_logloss: 0.576107\n",
      "[70]\ttrain's binary_logloss: 0.540214\tvalid's binary_logloss: 0.575507\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.53609\tvalid's binary_logloss: 0.575012\n",
      "[90]\ttrain's binary_logloss: 0.531348\tvalid's binary_logloss: 0.574581\n",
      "[100]\ttrain's binary_logloss: 0.526485\tvalid's binary_logloss: 0.574173\n",
      "[110]\ttrain's binary_logloss: 0.521878\tvalid's binary_logloss: 0.57378\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.51814\tvalid's binary_logloss: 0.57361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  25%|##5       | 5/20 [00:33<01:32,  6.16s/it]\u001b[32m[I 2023-01-04 07:07:35,083]\u001b[0m Trial 11 finished with value: 0.5733551564247632 and parameters: {'num_leaves': 240}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  25%|##5       | 5/20 [00:33<01:32,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130]\ttrain's binary_logloss: 0.514302\tvalid's binary_logloss: 0.573389\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttrain's binary_logloss: 0.51581\tvalid's binary_logloss: 0.573355\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.607567\tvalid's binary_logloss: 0.608592\n",
      "[20]\ttrain's binary_logloss: 0.595894\tvalid's binary_logloss: 0.59787\n",
      "[30]\ttrain's binary_logloss: 0.589727\tvalid's binary_logloss: 0.592545\n",
      "[40]\ttrain's binary_logloss: 0.584438\tvalid's binary_logloss: 0.588009\n",
      "[50]\ttrain's binary_logloss: 0.5809\tvalid's binary_logloss: 0.585169\n",
      "[60]\ttrain's binary_logloss: 0.5787\tvalid's binary_logloss: 0.583696\n",
      "[70]\ttrain's binary_logloss: 0.57688\tvalid's binary_logloss: 0.582669\n",
      "[80]\ttrain's binary_logloss: 0.575567\tvalid's binary_logloss: 0.582037\n",
      "[90]\ttrain's binary_logloss: 0.57416\tvalid's binary_logloss: 0.581446\n",
      "[100]\ttrain's binary_logloss: 0.572772\tvalid's binary_logloss: 0.580926\n",
      "[110]\ttrain's binary_logloss: 0.571548\tvalid's binary_logloss: 0.580513\n",
      "[120]\ttrain's binary_logloss: 0.57058\tvalid's binary_logloss: 0.580237\n",
      "[130]\ttrain's binary_logloss: 0.569421\tvalid's binary_logloss: 0.579828\n",
      "[140]\ttrain's binary_logloss: 0.568425\tvalid's binary_logloss: 0.579512\n",
      "[150]\ttrain's binary_logloss: 0.567257\tvalid's binary_logloss: 0.579124\n",
      "[160]\ttrain's binary_logloss: 0.566156\tvalid's binary_logloss: 0.578802\n",
      "[170]\ttrain's binary_logloss: 0.565141\tvalid's binary_logloss: 0.578623\n",
      "[180]\ttrain's binary_logloss: 0.564332\tvalid's binary_logloss: 0.578428\n",
      "[190]\ttrain's binary_logloss: 0.563339\tvalid's binary_logloss: 0.578168\n",
      "[200]\ttrain's binary_logloss: 0.562328\tvalid's binary_logloss: 0.577924\n",
      "[210]\ttrain's binary_logloss: 0.561469\tvalid's binary_logloss: 0.577742\n",
      "[220]\ttrain's binary_logloss: 0.56074\tvalid's binary_logloss: 0.577645\n",
      "[230]\ttrain's binary_logloss: 0.559826\tvalid's binary_logloss: 0.577391\n",
      "[240]\ttrain's binary_logloss: 0.55911\tvalid's binary_logloss: 0.57727\n",
      "[250]\ttrain's binary_logloss: 0.558261\tvalid's binary_logloss: 0.577147\n",
      "[260]\ttrain's binary_logloss: 0.557424\tvalid's binary_logloss: 0.57697\n",
      "[270]\ttrain's binary_logloss: 0.55672\tvalid's binary_logloss: 0.576794\n",
      "[280]\ttrain's binary_logloss: 0.555976\tvalid's binary_logloss: 0.576716\n",
      "[290]\ttrain's binary_logloss: 0.555199\tvalid's binary_logloss: 0.576632\n",
      "[300]\ttrain's binary_logloss: 0.554515\tvalid's binary_logloss: 0.576491\n",
      "[310]\ttrain's binary_logloss: 0.553693\tvalid's binary_logloss: 0.576362\n",
      "[320]\ttrain's binary_logloss: 0.55285\tvalid's binary_logloss: 0.576195\n",
      "[330]\ttrain's binary_logloss: 0.552114\tvalid's binary_logloss: 0.576126\n",
      "[340]\ttrain's binary_logloss: 0.551465\tvalid's binary_logloss: 0.576062\n",
      "[350]\ttrain's binary_logloss: 0.550756\tvalid's binary_logloss: 0.575961\n",
      "[360]\ttrain's binary_logloss: 0.550137\tvalid's binary_logloss: 0.575898\n",
      "[370]\ttrain's binary_logloss: 0.549391\tvalid's binary_logloss: 0.575764\n",
      "[380]\ttrain's binary_logloss: 0.548643\tvalid's binary_logloss: 0.57564\n",
      "[390]\ttrain's binary_logloss: 0.547902\tvalid's binary_logloss: 0.575458\n",
      "[400]\ttrain's binary_logloss: 0.547263\tvalid's binary_logloss: 0.575422\n",
      "[410]\ttrain's binary_logloss: 0.546621\tvalid's binary_logloss: 0.575327\n",
      "[420]\ttrain's binary_logloss: 0.545817\tvalid's binary_logloss: 0.575228\n",
      "[430]\ttrain's binary_logloss: 0.545144\tvalid's binary_logloss: 0.575178\n",
      "[440]\ttrain's binary_logloss: 0.544451\tvalid's binary_logloss: 0.575113\n",
      "[450]\ttrain's binary_logloss: 0.543894\tvalid's binary_logloss: 0.575134\n",
      "[460]\ttrain's binary_logloss: 0.543297\tvalid's binary_logloss: 0.575051\n",
      "[470]\ttrain's binary_logloss: 0.542579\tvalid's binary_logloss: 0.574988\n",
      "[480]\ttrain's binary_logloss: 0.5419\tvalid's binary_logloss: 0.574874\n",
      "[490]\ttrain's binary_logloss: 0.541046\tvalid's binary_logloss: 0.574713\n",
      "[500]\ttrain's binary_logloss: 0.540445\tvalid's binary_logloss: 0.574702\n",
      "[510]\ttrain's binary_logloss: 0.539825\tvalid's binary_logloss: 0.574679\n",
      "[520]\ttrain's binary_logloss: 0.539151\tvalid's binary_logloss: 0.574612\n",
      "Early stopping, best iteration is:\n",
      "[515]\ttrain's binary_logloss: 0.539511\tvalid's binary_logloss: 0.574602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  30%|###       | 6/20 [00:42<01:39,  7.08s/it]\u001b[32m[I 2023-01-04 07:07:43,964]\u001b[0m Trial 12 finished with value: 0.5746021830437709 and parameters: {'num_leaves': 36}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  30%|###       | 6/20 [00:42<01:39,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.599678\tvalid's binary_logloss: 0.603171\n",
      "[20]\ttrain's binary_logloss: 0.584798\tvalid's binary_logloss: 0.591734\n",
      "[30]\ttrain's binary_logloss: 0.575657\tvalid's binary_logloss: 0.585707\n",
      "[40]\ttrain's binary_logloss: 0.567456\tvalid's binary_logloss: 0.581038\n",
      "[50]\ttrain's binary_logloss: 0.5615\tvalid's binary_logloss: 0.578773\n",
      "[60]\ttrain's binary_logloss: 0.557287\tvalid's binary_logloss: 0.577663\n",
      "[70]\ttrain's binary_logloss: 0.553632\tvalid's binary_logloss: 0.576899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.550596\tvalid's binary_logloss: 0.576406\n",
      "[90]\ttrain's binary_logloss: 0.547212\tvalid's binary_logloss: 0.57604\n",
      "[100]\ttrain's binary_logloss: 0.543671\tvalid's binary_logloss: 0.575598\n",
      "[110]\ttrain's binary_logloss: 0.540306\tvalid's binary_logloss: 0.575117\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.537726\tvalid's binary_logloss: 0.57492\n",
      "[130]\ttrain's binary_logloss: 0.534996\tvalid's binary_logloss: 0.574687\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.532776\tvalid's binary_logloss: 0.574567\n",
      "[150]\ttrain's binary_logloss: 0.529975\tvalid's binary_logloss: 0.574331\n",
      "[160]\ttrain's binary_logloss: 0.527474\tvalid's binary_logloss: 0.574236\n",
      "[170]\ttrain's binary_logloss: 0.524805\tvalid's binary_logloss: 0.573981\n",
      "[180]\ttrain's binary_logloss: 0.522594\tvalid's binary_logloss: 0.573884\n",
      "[190]\ttrain's binary_logloss: 0.520212\tvalid's binary_logloss: 0.573686\n",
      "[200]\ttrain's binary_logloss: 0.517862\tvalid's binary_logloss: 0.573496\n",
      "[210]\ttrain's binary_logloss: 0.515367\tvalid's binary_logloss: 0.573395\n",
      "[220]\ttrain's binary_logloss: 0.513472\tvalid's binary_logloss: 0.573348\n",
      "[230]\ttrain's binary_logloss: 0.510988\tvalid's binary_logloss: 0.573181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  35%|###5      | 7/20 [00:51<01:38,  7.55s/it]\u001b[32m[I 2023-01-04 07:07:52,471]\u001b[0m Trial 13 finished with value: 0.5731255922880666 and parameters: {'num_leaves': 151}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  35%|###5      | 7/20 [00:51<01:38,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[228]\ttrain's binary_logloss: 0.511377\tvalid's binary_logloss: 0.573126\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.603392\tvalid's binary_logloss: 0.605328\n",
      "[20]\ttrain's binary_logloss: 0.590293\tvalid's binary_logloss: 0.594029\n",
      "[30]\ttrain's binary_logloss: 0.582962\tvalid's binary_logloss: 0.588354\n",
      "[40]\ttrain's binary_logloss: 0.576626\tvalid's binary_logloss: 0.583814\n",
      "[50]\ttrain's binary_logloss: 0.572184\tvalid's binary_logloss: 0.581363\n",
      "[60]\ttrain's binary_logloss: 0.569297\tvalid's binary_logloss: 0.580102\n",
      "[70]\ttrain's binary_logloss: 0.566748\tvalid's binary_logloss: 0.579292\n",
      "[80]\ttrain's binary_logloss: 0.56466\tvalid's binary_logloss: 0.578565\n",
      "[90]\ttrain's binary_logloss: 0.562459\tvalid's binary_logloss: 0.578121\n",
      "[100]\ttrain's binary_logloss: 0.560296\tvalid's binary_logloss: 0.577678\n",
      "[110]\ttrain's binary_logloss: 0.558145\tvalid's binary_logloss: 0.577216\n",
      "[120]\ttrain's binary_logloss: 0.556459\tvalid's binary_logloss: 0.57688\n",
      "[130]\ttrain's binary_logloss: 0.554785\tvalid's binary_logloss: 0.576627\n",
      "[140]\ttrain's binary_logloss: 0.553277\tvalid's binary_logloss: 0.576427\n",
      "[150]\ttrain's binary_logloss: 0.5512\tvalid's binary_logloss: 0.576054\n",
      "[160]\ttrain's binary_logloss: 0.549456\tvalid's binary_logloss: 0.575875\n",
      "[170]\ttrain's binary_logloss: 0.5478\tvalid's binary_logloss: 0.57583\n",
      "[180]\ttrain's binary_logloss: 0.54619\tvalid's binary_logloss: 0.57569\n",
      "[190]\ttrain's binary_logloss: 0.544651\tvalid's binary_logloss: 0.57541\n",
      "[200]\ttrain's binary_logloss: 0.543188\tvalid's binary_logloss: 0.575286\n",
      "[210]\ttrain's binary_logloss: 0.541652\tvalid's binary_logloss: 0.575035\n",
      "[220]\ttrain's binary_logloss: 0.540322\tvalid's binary_logloss: 0.574866\n",
      "[230]\ttrain's binary_logloss: 0.538912\tvalid's binary_logloss: 0.574803\n",
      "[240]\ttrain's binary_logloss: 0.537631\tvalid's binary_logloss: 0.574642\n",
      "[250]\ttrain's binary_logloss: 0.536197\tvalid's binary_logloss: 0.574526\n",
      "[260]\ttrain's binary_logloss: 0.534785\tvalid's binary_logloss: 0.574375\n",
      "[270]\ttrain's binary_logloss: 0.533614\tvalid's binary_logloss: 0.574283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  40%|####      | 8/20 [01:00<01:38,  8.22s/it]\u001b[32m[I 2023-01-04 07:08:02,130]\u001b[0m Trial 14 finished with value: 0.5741682826581656 and parameters: {'num_leaves': 79}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  40%|####      | 8/20 [01:00<01:38,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280]\ttrain's binary_logloss: 0.53215\tvalid's binary_logloss: 0.574247\n",
      "Early stopping, best iteration is:\n",
      "[276]\ttrain's binary_logloss: 0.532675\tvalid's binary_logloss: 0.574168\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.604455\tvalid's binary_logloss: 0.606089\n",
      "[20]\ttrain's binary_logloss: 0.591793\tvalid's binary_logloss: 0.594945\n",
      "[30]\ttrain's binary_logloss: 0.584823\tvalid's binary_logloss: 0.589394\n",
      "[40]\ttrain's binary_logloss: 0.578748\tvalid's binary_logloss: 0.584825\n",
      "[50]\ttrain's binary_logloss: 0.574708\tvalid's binary_logloss: 0.582317\n",
      "[60]\ttrain's binary_logloss: 0.572122\tvalid's binary_logloss: 0.581073\n",
      "[70]\ttrain's binary_logloss: 0.569847\tvalid's binary_logloss: 0.580294\n",
      "[80]\ttrain's binary_logloss: 0.568017\tvalid's binary_logloss: 0.5796\n",
      "[90]\ttrain's binary_logloss: 0.566077\tvalid's binary_logloss: 0.579169\n",
      "[100]\ttrain's binary_logloss: 0.56404\tvalid's binary_logloss: 0.5786\n",
      "[110]\ttrain's binary_logloss: 0.562029\tvalid's binary_logloss: 0.578078\n",
      "[120]\ttrain's binary_logloss: 0.560451\tvalid's binary_logloss: 0.577678\n",
      "[130]\ttrain's binary_logloss: 0.558919\tvalid's binary_logloss: 0.577538\n",
      "[140]\ttrain's binary_logloss: 0.55757\tvalid's binary_logloss: 0.577291\n",
      "[150]\ttrain's binary_logloss: 0.555878\tvalid's binary_logloss: 0.576979\n",
      "[160]\ttrain's binary_logloss: 0.554339\tvalid's binary_logloss: 0.576737\n",
      "[170]\ttrain's binary_logloss: 0.552773\tvalid's binary_logloss: 0.576532\n",
      "[180]\ttrain's binary_logloss: 0.551419\tvalid's binary_logloss: 0.576371\n",
      "[190]\ttrain's binary_logloss: 0.54992\tvalid's binary_logloss: 0.576138\n",
      "[200]\ttrain's binary_logloss: 0.54852\tvalid's binary_logloss: 0.575866\n",
      "[210]\ttrain's binary_logloss: 0.546906\tvalid's binary_logloss: 0.575554\n",
      "[220]\ttrain's binary_logloss: 0.545744\tvalid's binary_logloss: 0.575431\n",
      "[230]\ttrain's binary_logloss: 0.544451\tvalid's binary_logloss: 0.575416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  45%|####5     | 9/20 [01:07<01:25,  7.73s/it]\u001b[32m[I 2023-01-04 07:08:08,786]\u001b[0m Trial 15 finished with value: 0.5753501256004061 and parameters: {'num_leaves': 65}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  45%|####5     | 9/20 [01:07<01:25,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[227]\ttrain's binary_logloss: 0.544806\tvalid's binary_logloss: 0.57535\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.599278\tvalid's binary_logloss: 0.60302\n",
      "[20]\ttrain's binary_logloss: 0.584108\tvalid's binary_logloss: 0.591488\n",
      "[30]\ttrain's binary_logloss: 0.574803\tvalid's binary_logloss: 0.585537\n",
      "[40]\ttrain's binary_logloss: 0.566303\tvalid's binary_logloss: 0.580669\n",
      "[50]\ttrain's binary_logloss: 0.560244\tvalid's binary_logloss: 0.578513\n",
      "[60]\ttrain's binary_logloss: 0.555863\tvalid's binary_logloss: 0.577448\n",
      "[70]\ttrain's binary_logloss: 0.552009\tvalid's binary_logloss: 0.576674\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.548897\tvalid's binary_logloss: 0.576182\n",
      "[90]\ttrain's binary_logloss: 0.545451\tvalid's binary_logloss: 0.575799\n",
      "[100]\ttrain's binary_logloss: 0.541865\tvalid's binary_logloss: 0.575294\n",
      "[110]\ttrain's binary_logloss: 0.538379\tvalid's binary_logloss: 0.574674\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.535712\tvalid's binary_logloss: 0.574563\n",
      "[130]\ttrain's binary_logloss: 0.532844\tvalid's binary_logloss: 0.574398\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.53037\tvalid's binary_logloss: 0.574187\n",
      "[150]\ttrain's binary_logloss: 0.527664\tvalid's binary_logloss: 0.573926\n",
      "[160]\ttrain's binary_logloss: 0.525093\tvalid's binary_logloss: 0.573797\n",
      "[170]\ttrain's binary_logloss: 0.521901\tvalid's binary_logloss: 0.573664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572700:  50%|#####     | 10/20 [01:12<01:09,  6.96s/it]\u001b[32m[I 2023-01-04 07:08:14,020]\u001b[0m Trial 16 finished with value: 0.5735902489878958 and parameters: {'num_leaves': 161}. Best is trial 7 with value: 0.5726995641451669.\u001b[0m\n",
      "num_leaves, val_score: 0.572700:  50%|#####     | 10/20 [01:12<01:09,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.523792\tvalid's binary_logloss: 0.57359\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.59589\tvalid's binary_logloss: 0.601774\n",
      "[20]\ttrain's binary_logloss: 0.57865\tvalid's binary_logloss: 0.590193\n",
      "[30]\ttrain's binary_logloss: 0.567486\tvalid's binary_logloss: 0.584106\n",
      "[40]\ttrain's binary_logloss: 0.556975\tvalid's binary_logloss: 0.579246\n",
      "[50]\ttrain's binary_logloss: 0.54901\tvalid's binary_logloss: 0.576993\n",
      "[60]\ttrain's binary_logloss: 0.54313\tvalid's binary_logloss: 0.576218\n",
      "[70]\ttrain's binary_logloss: 0.537835\tvalid's binary_logloss: 0.575481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.533634\tvalid's binary_logloss: 0.575128\n",
      "[90]\ttrain's binary_logloss: 0.528971\tvalid's binary_logloss: 0.574807\n",
      "[100]\ttrain's binary_logloss: 0.52395\tvalid's binary_logloss: 0.574347\n",
      "[110]\ttrain's binary_logloss: 0.519123\tvalid's binary_logloss: 0.573845\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.515409\tvalid's binary_logloss: 0.573755\n",
      "[130]\ttrain's binary_logloss: 0.51154\tvalid's binary_logloss: 0.573694\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.508127\tvalid's binary_logloss: 0.573552\n",
      "[150]\ttrain's binary_logloss: 0.504083\tvalid's binary_logloss: 0.573103\n",
      "[160]\ttrain's binary_logloss: 0.50036\tvalid's binary_logloss: 0.572882\n",
      "[170]\ttrain's binary_logloss: 0.496351\tvalid's binary_logloss: 0.57273\n",
      "[180]\ttrain's binary_logloss: 0.492823\tvalid's binary_logloss: 0.572495\n",
      "[190]\ttrain's binary_logloss: 0.489382\tvalid's binary_logloss: 0.572303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572264:  55%|#####5    | 11/20 [01:20<01:04,  7.15s/it]\u001b[32m[I 2023-01-04 07:08:21,585]\u001b[0m Trial 17 finished with value: 0.5722636633047575 and parameters: {'num_leaves': 255}. Best is trial 17 with value: 0.5722636633047575.\u001b[0m\n",
      "num_leaves, val_score: 0.572264:  55%|#####5    | 11/20 [01:20<01:04,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[188]\ttrain's binary_logloss: 0.489821\tvalid's binary_logloss: 0.572264\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.595991\tvalid's binary_logloss: 0.601749\n",
      "[20]\ttrain's binary_logloss: 0.578771\tvalid's binary_logloss: 0.590055\n",
      "[30]\ttrain's binary_logloss: 0.567695\tvalid's binary_logloss: 0.584073\n",
      "[40]\ttrain's binary_logloss: 0.557322\tvalid's binary_logloss: 0.579284\n",
      "[50]\ttrain's binary_logloss: 0.549422\tvalid's binary_logloss: 0.577069\n",
      "[60]\ttrain's binary_logloss: 0.543657\tvalid's binary_logloss: 0.576247\n",
      "[70]\ttrain's binary_logloss: 0.538359\tvalid's binary_logloss: 0.575701\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.534179\tvalid's binary_logloss: 0.575275\n",
      "[90]\ttrain's binary_logloss: 0.529536\tvalid's binary_logloss: 0.57502\n",
      "[100]\ttrain's binary_logloss: 0.524502\tvalid's binary_logloss: 0.574725\n",
      "[110]\ttrain's binary_logloss: 0.519654\tvalid's binary_logloss: 0.574252\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.515986\tvalid's binary_logloss: 0.574178\n",
      "[130]\ttrain's binary_logloss: 0.512131\tvalid's binary_logloss: 0.573957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.508942\tvalid's binary_logloss: 0.573731\n",
      "[150]\ttrain's binary_logloss: 0.505089\tvalid's binary_logloss: 0.573615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.572264:  60%|######    | 12/20 [01:29<01:03,  7.90s/it]\u001b[32m[I 2023-01-04 07:08:31,198]\u001b[0m Trial 18 finished with value: 0.5735611487019401 and parameters: {'num_leaves': 252}. Best is trial 17 with value: 0.5722636633047575.\u001b[0m\n",
      "num_leaves, val_score: 0.572264:  60%|######    | 12/20 [01:29<01:03,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[147]\ttrain's binary_logloss: 0.506054\tvalid's binary_logloss: 0.573561\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597703\tvalid's binary_logloss: 0.602264\n",
      "[20]\ttrain's binary_logloss: 0.581663\tvalid's binary_logloss: 0.590748\n",
      "[30]\ttrain's binary_logloss: 0.57159\tvalid's binary_logloss: 0.584757\n",
      "[40]\ttrain's binary_logloss: 0.56225\tvalid's binary_logloss: 0.579975\n",
      "[50]\ttrain's binary_logloss: 0.555348\tvalid's binary_logloss: 0.577764\n",
      "[60]\ttrain's binary_logloss: 0.550271\tvalid's binary_logloss: 0.576692\n",
      "[70]\ttrain's binary_logloss: 0.545769\tvalid's binary_logloss: 0.575965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542085\tvalid's binary_logloss: 0.575412\n",
      "[90]\ttrain's binary_logloss: 0.538103\tvalid's binary_logloss: 0.574986\n",
      "[100]\ttrain's binary_logloss: 0.533801\tvalid's binary_logloss: 0.574397\n",
      "[110]\ttrain's binary_logloss: 0.529675\tvalid's binary_logloss: 0.574001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526408\tvalid's binary_logloss: 0.573773\n",
      "[130]\ttrain's binary_logloss: 0.523036\tvalid's binary_logloss: 0.573535\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520254\tvalid's binary_logloss: 0.573299\n",
      "[150]\ttrain's binary_logloss: 0.516815\tvalid's binary_logloss: 0.573098\n",
      "[160]\ttrain's binary_logloss: 0.513811\tvalid's binary_logloss: 0.573036\n",
      "[170]\ttrain's binary_logloss: 0.510599\tvalid's binary_logloss: 0.572902\n",
      "[180]\ttrain's binary_logloss: 0.507795\tvalid's binary_logloss: 0.57273\n",
      "[190]\ttrain's binary_logloss: 0.50488\tvalid's binary_logloss: 0.572488\n",
      "[200]\ttrain's binary_logloss: 0.501862\tvalid's binary_logloss: 0.572201\n",
      "[210]\ttrain's binary_logloss: 0.499069\tvalid's binary_logloss: 0.572015\n",
      "[220]\ttrain's binary_logloss: 0.496863\tvalid's binary_logloss: 0.572006\n",
      "[230]\ttrain's binary_logloss: 0.494163\tvalid's binary_logloss: 0.571986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  65%|######5   | 13/20 [01:37<00:55,  7.86s/it]\u001b[32m[I 2023-01-04 07:08:38,967]\u001b[0m Trial 19 finished with value: 0.5719040217408571 and parameters: {'num_leaves': 201}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  65%|######5   | 13/20 [01:37<00:55,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[228]\ttrain's binary_logloss: 0.494764\tvalid's binary_logloss: 0.571904\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597783\tvalid's binary_logloss: 0.602332\n",
      "[20]\ttrain's binary_logloss: 0.581765\tvalid's binary_logloss: 0.590781\n",
      "[30]\ttrain's binary_logloss: 0.571782\tvalid's binary_logloss: 0.584865\n",
      "[40]\ttrain's binary_logloss: 0.562471\tvalid's binary_logloss: 0.579955\n",
      "[50]\ttrain's binary_logloss: 0.555641\tvalid's binary_logloss: 0.577798\n",
      "[60]\ttrain's binary_logloss: 0.550703\tvalid's binary_logloss: 0.576776\n",
      "[70]\ttrain's binary_logloss: 0.546338\tvalid's binary_logloss: 0.576051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542649\tvalid's binary_logloss: 0.575521\n",
      "[90]\ttrain's binary_logloss: 0.538612\tvalid's binary_logloss: 0.575078\n",
      "[100]\ttrain's binary_logloss: 0.534429\tvalid's binary_logloss: 0.574614\n",
      "[110]\ttrain's binary_logloss: 0.530345\tvalid's binary_logloss: 0.574087\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.52723\tvalid's binary_logloss: 0.574043\n",
      "[130]\ttrain's binary_logloss: 0.523943\tvalid's binary_logloss: 0.573893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.521078\tvalid's binary_logloss: 0.573667\n",
      "[150]\ttrain's binary_logloss: 0.517713\tvalid's binary_logloss: 0.573428\n",
      "[160]\ttrain's binary_logloss: 0.514381\tvalid's binary_logloss: 0.573284\n",
      "[170]\ttrain's binary_logloss: 0.511152\tvalid's binary_logloss: 0.573189\n",
      "[180]\ttrain's binary_logloss: 0.508114\tvalid's binary_logloss: 0.573024\n",
      "[190]\ttrain's binary_logloss: 0.505028\tvalid's binary_logloss: 0.57282\n",
      "[200]\ttrain's binary_logloss: 0.502316\tvalid's binary_logloss: 0.572648\n",
      "[210]\ttrain's binary_logloss: 0.499238\tvalid's binary_logloss: 0.57242\n",
      "[220]\ttrain's binary_logloss: 0.496991\tvalid's binary_logloss: 0.572338\n",
      "[230]\ttrain's binary_logloss: 0.494188\tvalid's binary_logloss: 0.572229\n",
      "[240]\ttrain's binary_logloss: 0.491768\tvalid's binary_logloss: 0.572141\n",
      "[250]\ttrain's binary_logloss: 0.489136\tvalid's binary_logloss: 0.57204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  70%|#######   | 14/20 [01:44<00:45,  7.66s/it]\u001b[32m[I 2023-01-04 07:08:46,167]\u001b[0m Trial 20 finished with value: 0.5720399478531802 and parameters: {'num_leaves': 199}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  70%|#######   | 14/20 [01:44<00:45,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\ttrain's binary_logloss: 0.486625\tvalid's binary_logloss: 0.572084\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttrain's binary_logloss: 0.489136\tvalid's binary_logloss: 0.57204\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597843\tvalid's binary_logloss: 0.602327\n",
      "[20]\ttrain's binary_logloss: 0.581824\tvalid's binary_logloss: 0.590774\n",
      "[30]\ttrain's binary_logloss: 0.57185\tvalid's binary_logloss: 0.584655\n",
      "[40]\ttrain's binary_logloss: 0.56253\tvalid's binary_logloss: 0.57973\n",
      "[50]\ttrain's binary_logloss: 0.555773\tvalid's binary_logloss: 0.577578\n",
      "[60]\ttrain's binary_logloss: 0.550862\tvalid's binary_logloss: 0.576682\n",
      "[70]\ttrain's binary_logloss: 0.546477\tvalid's binary_logloss: 0.576051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542866\tvalid's binary_logloss: 0.575615\n",
      "[90]\ttrain's binary_logloss: 0.538718\tvalid's binary_logloss: 0.57521\n",
      "[100]\ttrain's binary_logloss: 0.53457\tvalid's binary_logloss: 0.574654\n",
      "[110]\ttrain's binary_logloss: 0.530461\tvalid's binary_logloss: 0.574312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527252\tvalid's binary_logloss: 0.573976\n",
      "[130]\ttrain's binary_logloss: 0.523884\tvalid's binary_logloss: 0.573844\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.521163\tvalid's binary_logloss: 0.573593\n",
      "[150]\ttrain's binary_logloss: 0.517858\tvalid's binary_logloss: 0.573435\n",
      "[160]\ttrain's binary_logloss: 0.514662\tvalid's binary_logloss: 0.573312\n",
      "[170]\ttrain's binary_logloss: 0.511493\tvalid's binary_logloss: 0.573221\n",
      "[180]\ttrain's binary_logloss: 0.508944\tvalid's binary_logloss: 0.573243\n",
      "[190]\ttrain's binary_logloss: 0.505832\tvalid's binary_logloss: 0.572923\n",
      "[200]\ttrain's binary_logloss: 0.503173\tvalid's binary_logloss: 0.572837\n",
      "[210]\ttrain's binary_logloss: 0.500141\tvalid's binary_logloss: 0.572624\n",
      "[220]\ttrain's binary_logloss: 0.497814\tvalid's binary_logloss: 0.572687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  75%|#######5  | 15/20 [01:52<00:37,  7.57s/it]\u001b[32m[I 2023-01-04 07:08:53,516]\u001b[0m Trial 21 finished with value: 0.5725852546826862 and parameters: {'num_leaves': 197}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  75%|#######5  | 15/20 [01:52<00:37,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[215]\ttrain's binary_logloss: 0.4988\tvalid's binary_logloss: 0.572585\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598242\tvalid's binary_logloss: 0.60256\n",
      "[20]\ttrain's binary_logloss: 0.582532\tvalid's binary_logloss: 0.591042\n",
      "[30]\ttrain's binary_logloss: 0.57275\tvalid's binary_logloss: 0.585074\n",
      "[40]\ttrain's binary_logloss: 0.563679\tvalid's binary_logloss: 0.580323\n",
      "[50]\ttrain's binary_logloss: 0.557014\tvalid's binary_logloss: 0.578054\n",
      "[60]\ttrain's binary_logloss: 0.552211\tvalid's binary_logloss: 0.576948\n",
      "[70]\ttrain's binary_logloss: 0.547989\tvalid's binary_logloss: 0.57619\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.544394\tvalid's binary_logloss: 0.575652\n",
      "[90]\ttrain's binary_logloss: 0.540514\tvalid's binary_logloss: 0.575218\n",
      "[100]\ttrain's binary_logloss: 0.536413\tvalid's binary_logloss: 0.574787\n",
      "[110]\ttrain's binary_logloss: 0.532491\tvalid's binary_logloss: 0.574275\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.52944\tvalid's binary_logloss: 0.573998\n",
      "[130]\ttrain's binary_logloss: 0.52613\tvalid's binary_logloss: 0.573837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.52352\tvalid's binary_logloss: 0.573724\n",
      "[150]\ttrain's binary_logloss: 0.520205\tvalid's binary_logloss: 0.573654\n",
      "[160]\ttrain's binary_logloss: 0.517086\tvalid's binary_logloss: 0.573508\n",
      "[170]\ttrain's binary_logloss: 0.5138\tvalid's binary_logloss: 0.573356\n",
      "[180]\ttrain's binary_logloss: 0.510905\tvalid's binary_logloss: 0.573131\n",
      "[190]\ttrain's binary_logloss: 0.507805\tvalid's binary_logloss: 0.572898\n",
      "[200]\ttrain's binary_logloss: 0.505073\tvalid's binary_logloss: 0.572762\n",
      "[210]\ttrain's binary_logloss: 0.502088\tvalid's binary_logloss: 0.572542\n",
      "[220]\ttrain's binary_logloss: 0.499893\tvalid's binary_logloss: 0.572531\n",
      "[230]\ttrain's binary_logloss: 0.497231\tvalid's binary_logloss: 0.572442\n",
      "[240]\ttrain's binary_logloss: 0.49499\tvalid's binary_logloss: 0.572361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  80%|########  | 16/20 [02:04<00:36,  9.17s/it]\u001b[32m[I 2023-01-04 07:09:06,413]\u001b[0m Trial 22 finished with value: 0.5722932268497778 and parameters: {'num_leaves': 187}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  80%|########  | 16/20 [02:04<00:36,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttrain's binary_logloss: 0.492289\tvalid's binary_logloss: 0.572337\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttrain's binary_logloss: 0.493209\tvalid's binary_logloss: 0.572293\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597818\tvalid's binary_logloss: 0.602323\n",
      "[20]\ttrain's binary_logloss: 0.58184\tvalid's binary_logloss: 0.590769\n",
      "[30]\ttrain's binary_logloss: 0.571838\tvalid's binary_logloss: 0.58478\n",
      "[40]\ttrain's binary_logloss: 0.562551\tvalid's binary_logloss: 0.580046\n",
      "[50]\ttrain's binary_logloss: 0.555629\tvalid's binary_logloss: 0.577731\n",
      "[60]\ttrain's binary_logloss: 0.550648\tvalid's binary_logloss: 0.576657\n",
      "[70]\ttrain's binary_logloss: 0.546343\tvalid's binary_logloss: 0.576028\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.54272\tvalid's binary_logloss: 0.575413\n",
      "[90]\ttrain's binary_logloss: 0.538718\tvalid's binary_logloss: 0.574987\n",
      "[100]\ttrain's binary_logloss: 0.534636\tvalid's binary_logloss: 0.574558\n",
      "[110]\ttrain's binary_logloss: 0.530584\tvalid's binary_logloss: 0.574059\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527417\tvalid's binary_logloss: 0.573752\n",
      "[130]\ttrain's binary_logloss: 0.524249\tvalid's binary_logloss: 0.573622\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.521369\tvalid's binary_logloss: 0.573419\n",
      "[150]\ttrain's binary_logloss: 0.518038\tvalid's binary_logloss: 0.573314\n",
      "[160]\ttrain's binary_logloss: 0.514848\tvalid's binary_logloss: 0.573152\n",
      "[170]\ttrain's binary_logloss: 0.511324\tvalid's binary_logloss: 0.573004\n",
      "[180]\ttrain's binary_logloss: 0.508324\tvalid's binary_logloss: 0.572936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  85%|########5 | 17/20 [02:10<00:24,  8.09s/it]\u001b[32m[I 2023-01-04 07:09:11,998]\u001b[0m Trial 23 finished with value: 0.5728617006501422 and parameters: {'num_leaves': 198}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  85%|########5 | 17/20 [02:10<00:24,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[173]\ttrain's binary_logloss: 0.510262\tvalid's binary_logloss: 0.572862\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.600575\tvalid's binary_logloss: 0.603654\n",
      "[20]\ttrain's binary_logloss: 0.586087\tvalid's binary_logloss: 0.592186\n",
      "[30]\ttrain's binary_logloss: 0.577437\tvalid's binary_logloss: 0.586291\n",
      "[40]\ttrain's binary_logloss: 0.569727\tvalid's binary_logloss: 0.581622\n",
      "[50]\ttrain's binary_logloss: 0.564038\tvalid's binary_logloss: 0.579182\n",
      "[60]\ttrain's binary_logloss: 0.560181\tvalid's binary_logloss: 0.577938\n",
      "[70]\ttrain's binary_logloss: 0.556704\tvalid's binary_logloss: 0.577268\n",
      "[80]\ttrain's binary_logloss: 0.553891\tvalid's binary_logloss: 0.576693\n",
      "[90]\ttrain's binary_logloss: 0.550799\tvalid's binary_logloss: 0.57633\n",
      "[100]\ttrain's binary_logloss: 0.547674\tvalid's binary_logloss: 0.575987\n",
      "[110]\ttrain's binary_logloss: 0.544663\tvalid's binary_logloss: 0.57566\n",
      "[120]\ttrain's binary_logloss: 0.542269\tvalid's binary_logloss: 0.575327\n",
      "[130]\ttrain's binary_logloss: 0.539712\tvalid's binary_logloss: 0.575193\n",
      "[140]\ttrain's binary_logloss: 0.537567\tvalid's binary_logloss: 0.574873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  90%|######### | 18/20 [02:15<00:14,  7.22s/it]\u001b[32m[I 2023-01-04 07:09:17,203]\u001b[0m Trial 24 finished with value: 0.5746705084791502 and parameters: {'num_leaves': 132}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  90%|######### | 18/20 [02:15<00:14,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain's binary_logloss: 0.535022\tvalid's binary_logloss: 0.574693\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttrain's binary_logloss: 0.536185\tvalid's binary_logloss: 0.574671\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597276\tvalid's binary_logloss: 0.602159\n",
      "[20]\ttrain's binary_logloss: 0.580935\tvalid's binary_logloss: 0.590497\n",
      "[30]\ttrain's binary_logloss: 0.570564\tvalid's binary_logloss: 0.584453\n",
      "[40]\ttrain's binary_logloss: 0.560858\tvalid's binary_logloss: 0.57954\n",
      "[50]\ttrain's binary_logloss: 0.553611\tvalid's binary_logloss: 0.577413\n",
      "[60]\ttrain's binary_logloss: 0.548429\tvalid's binary_logloss: 0.576441\n",
      "[70]\ttrain's binary_logloss: 0.543697\tvalid's binary_logloss: 0.575811\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.53994\tvalid's binary_logloss: 0.575334\n",
      "[90]\ttrain's binary_logloss: 0.535727\tvalid's binary_logloss: 0.575116\n",
      "[100]\ttrain's binary_logloss: 0.531238\tvalid's binary_logloss: 0.574684\n",
      "[110]\ttrain's binary_logloss: 0.526784\tvalid's binary_logloss: 0.574162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.523486\tvalid's binary_logloss: 0.573948\n",
      "[130]\ttrain's binary_logloss: 0.519853\tvalid's binary_logloss: 0.573754\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.516869\tvalid's binary_logloss: 0.573485\n",
      "[150]\ttrain's binary_logloss: 0.513311\tvalid's binary_logloss: 0.573255\n",
      "[160]\ttrain's binary_logloss: 0.509882\tvalid's binary_logloss: 0.573173\n",
      "[170]\ttrain's binary_logloss: 0.506033\tvalid's binary_logloss: 0.572927\n",
      "[180]\ttrain's binary_logloss: 0.503046\tvalid's binary_logloss: 0.57279\n",
      "[190]\ttrain's binary_logloss: 0.499693\tvalid's binary_logloss: 0.572427\n",
      "[200]\ttrain's binary_logloss: 0.496583\tvalid's binary_logloss: 0.572269\n",
      "[210]\ttrain's binary_logloss: 0.493549\tvalid's binary_logloss: 0.572168\n",
      "[220]\ttrain's binary_logloss: 0.491026\tvalid's binary_logloss: 0.572117\n",
      "[230]\ttrain's binary_logloss: 0.487909\tvalid's binary_logloss: 0.572089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904:  95%|#########5| 19/20 [02:28<00:08,  8.74s/it]\u001b[32m[I 2023-01-04 07:09:29,470]\u001b[0m Trial 25 finished with value: 0.57204268306727 and parameters: {'num_leaves': 215}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904:  95%|#########5| 19/20 [02:28<00:08,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\ttrain's binary_logloss: 0.485556\tvalid's binary_logloss: 0.572089\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttrain's binary_logloss: 0.486266\tvalid's binary_logloss: 0.572043\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.599465\tvalid's binary_logloss: 0.603053\n",
      "[20]\ttrain's binary_logloss: 0.584431\tvalid's binary_logloss: 0.591644\n",
      "[30]\ttrain's binary_logloss: 0.575228\tvalid's binary_logloss: 0.58571\n",
      "[40]\ttrain's binary_logloss: 0.566707\tvalid's binary_logloss: 0.580876\n",
      "[50]\ttrain's binary_logloss: 0.560651\tvalid's binary_logloss: 0.578727\n",
      "[60]\ttrain's binary_logloss: 0.556325\tvalid's binary_logloss: 0.577599\n",
      "[70]\ttrain's binary_logloss: 0.552613\tvalid's binary_logloss: 0.577001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.549483\tvalid's binary_logloss: 0.576475\n",
      "[90]\ttrain's binary_logloss: 0.545946\tvalid's binary_logloss: 0.575969\n",
      "[100]\ttrain's binary_logloss: 0.542289\tvalid's binary_logloss: 0.575371\n",
      "[110]\ttrain's binary_logloss: 0.538849\tvalid's binary_logloss: 0.574865\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.536103\tvalid's binary_logloss: 0.574599\n",
      "[130]\ttrain's binary_logloss: 0.533224\tvalid's binary_logloss: 0.574407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.530818\tvalid's binary_logloss: 0.574221\n",
      "[150]\ttrain's binary_logloss: 0.527922\tvalid's binary_logloss: 0.573991\n",
      "[160]\ttrain's binary_logloss: 0.525308\tvalid's binary_logloss: 0.573908\n",
      "[170]\ttrain's binary_logloss: 0.522261\tvalid's binary_logloss: 0.573655\n",
      "[180]\ttrain's binary_logloss: 0.520071\tvalid's binary_logloss: 0.573528\n",
      "[190]\ttrain's binary_logloss: 0.51719\tvalid's binary_logloss: 0.573337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.571904: 100%|##########| 20/20 [02:36<00:00,  8.73s/it]\u001b[32m[I 2023-01-04 07:09:38,166]\u001b[0m Trial 26 finished with value: 0.5731677466716848 and parameters: {'num_leaves': 157}. Best is trial 19 with value: 0.5719040217408571.\u001b[0m\n",
      "num_leaves, val_score: 0.571904: 100%|##########| 20/20 [02:36<00:00,  7.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's binary_logloss: 0.514666\tvalid's binary_logloss: 0.573193\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttrain's binary_logloss: 0.515666\tvalid's binary_logloss: 0.573168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.59768\tvalid's binary_logloss: 0.602344\n",
      "[20]\ttrain's binary_logloss: 0.581683\tvalid's binary_logloss: 0.590696\n",
      "[30]\ttrain's binary_logloss: 0.571607\tvalid's binary_logloss: 0.584707\n",
      "[40]\ttrain's binary_logloss: 0.562359\tvalid's binary_logloss: 0.580148\n",
      "[50]\ttrain's binary_logloss: 0.555259\tvalid's binary_logloss: 0.577568\n",
      "[60]\ttrain's binary_logloss: 0.550379\tvalid's binary_logloss: 0.576678\n",
      "[70]\ttrain's binary_logloss: 0.545849\tvalid's binary_logloss: 0.575883\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542242\tvalid's binary_logloss: 0.575523\n",
      "[90]\ttrain's binary_logloss: 0.538232\tvalid's binary_logloss: 0.575276\n",
      "[100]\ttrain's binary_logloss: 0.534012\tvalid's binary_logloss: 0.574918\n",
      "[110]\ttrain's binary_logloss: 0.529573\tvalid's binary_logloss: 0.574246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526217\tvalid's binary_logloss: 0.573887\n",
      "[130]\ttrain's binary_logloss: 0.522692\tvalid's binary_logloss: 0.573604\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.519846\tvalid's binary_logloss: 0.573469\n",
      "[150]\ttrain's binary_logloss: 0.516226\tvalid's binary_logloss: 0.573123\n",
      "[160]\ttrain's binary_logloss: 0.512896\tvalid's binary_logloss: 0.573024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  10%|#         | 1/10 [00:09<01:25,  9.46s/it]\u001b[32m[I 2023-01-04 07:09:47,633]\u001b[0m Trial 27 finished with value: 0.5728319545241207 and parameters: {'bagging_fraction': 0.9661168629063649, 'bagging_freq': 6}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  10%|#         | 1/10 [00:09<01:25,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain's binary_logloss: 0.509428\tvalid's binary_logloss: 0.572932\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's binary_logloss: 0.510771\tvalid's binary_logloss: 0.572832\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598023\tvalid's binary_logloss: 0.602938\n",
      "[20]\ttrain's binary_logloss: 0.582243\tvalid's binary_logloss: 0.591556\n",
      "[30]\ttrain's binary_logloss: 0.572168\tvalid's binary_logloss: 0.585514\n",
      "[40]\ttrain's binary_logloss: 0.562974\tvalid's binary_logloss: 0.580846\n",
      "[50]\ttrain's binary_logloss: 0.556084\tvalid's binary_logloss: 0.578578\n",
      "[60]\ttrain's binary_logloss: 0.551119\tvalid's binary_logloss: 0.577437\n",
      "[70]\ttrain's binary_logloss: 0.546648\tvalid's binary_logloss: 0.576865\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542853\tvalid's binary_logloss: 0.57626\n",
      "[90]\ttrain's binary_logloss: 0.538811\tvalid's binary_logloss: 0.575908\n",
      "[100]\ttrain's binary_logloss: 0.534584\tvalid's binary_logloss: 0.575395\n",
      "[110]\ttrain's binary_logloss: 0.530479\tvalid's binary_logloss: 0.575084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527139\tvalid's binary_logloss: 0.574911\n",
      "[130]\ttrain's binary_logloss: 0.523538\tvalid's binary_logloss: 0.574545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  20%|##        | 2/10 [00:15<00:59,  7.38s/it]\u001b[32m[I 2023-01-04 07:09:53,558]\u001b[0m Trial 28 finished with value: 0.5745261136794215 and parameters: {'bagging_fraction': 0.7197691852715512, 'bagging_freq': 6}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  20%|##        | 2/10 [00:15<00:59,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttrain's binary_logloss: 0.524577\tvalid's binary_logloss: 0.574526\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597972\tvalid's binary_logloss: 0.602813\n",
      "[20]\ttrain's binary_logloss: 0.582092\tvalid's binary_logloss: 0.591337\n",
      "[30]\ttrain's binary_logloss: 0.571943\tvalid's binary_logloss: 0.585356\n",
      "[40]\ttrain's binary_logloss: 0.562653\tvalid's binary_logloss: 0.580829\n",
      "[50]\ttrain's binary_logloss: 0.555715\tvalid's binary_logloss: 0.578277\n",
      "[60]\ttrain's binary_logloss: 0.550857\tvalid's binary_logloss: 0.577304\n",
      "[70]\ttrain's binary_logloss: 0.54632\tvalid's binary_logloss: 0.576717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542708\tvalid's binary_logloss: 0.576022\n",
      "[90]\ttrain's binary_logloss: 0.538415\tvalid's binary_logloss: 0.57562\n",
      "[100]\ttrain's binary_logloss: 0.534354\tvalid's binary_logloss: 0.575225\n",
      "[110]\ttrain's binary_logloss: 0.530482\tvalid's binary_logloss: 0.574898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.52724\tvalid's binary_logloss: 0.57467\n",
      "[130]\ttrain's binary_logloss: 0.523661\tvalid's binary_logloss: 0.574522\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520628\tvalid's binary_logloss: 0.574262\n",
      "[150]\ttrain's binary_logloss: 0.517238\tvalid's binary_logloss: 0.573997\n",
      "[160]\ttrain's binary_logloss: 0.513804\tvalid's binary_logloss: 0.573872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  30%|###       | 3/10 [00:22<00:52,  7.48s/it]\u001b[32m[I 2023-01-04 07:10:01,147]\u001b[0m Trial 29 finished with value: 0.5736503784552908 and parameters: {'bagging_fraction': 0.8210993924415293, 'bagging_freq': 7}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  30%|###       | 3/10 [00:22<00:52,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain's binary_logloss: 0.510025\tvalid's binary_logloss: 0.573707\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.512327\tvalid's binary_logloss: 0.57365\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597875\tvalid's binary_logloss: 0.60252\n",
      "[20]\ttrain's binary_logloss: 0.582247\tvalid's binary_logloss: 0.591379\n",
      "[30]\ttrain's binary_logloss: 0.572172\tvalid's binary_logloss: 0.585551\n",
      "[40]\ttrain's binary_logloss: 0.56298\tvalid's binary_logloss: 0.580902\n",
      "[50]\ttrain's binary_logloss: 0.556226\tvalid's binary_logloss: 0.578745\n",
      "[60]\ttrain's binary_logloss: 0.551323\tvalid's binary_logloss: 0.577732\n",
      "[70]\ttrain's binary_logloss: 0.546927\tvalid's binary_logloss: 0.577015\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.543202\tvalid's binary_logloss: 0.576233\n",
      "[90]\ttrain's binary_logloss: 0.539092\tvalid's binary_logloss: 0.575832\n",
      "[100]\ttrain's binary_logloss: 0.534788\tvalid's binary_logloss: 0.575569\n",
      "[110]\ttrain's binary_logloss: 0.530521\tvalid's binary_logloss: 0.575019\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527155\tvalid's binary_logloss: 0.574984\n",
      "[130]\ttrain's binary_logloss: 0.523668\tvalid's binary_logloss: 0.575019\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520917\tvalid's binary_logloss: 0.574784\n",
      "[150]\ttrain's binary_logloss: 0.517154\tvalid's binary_logloss: 0.574506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  40%|####      | 4/10 [00:29<00:42,  7.03s/it]\u001b[32m[I 2023-01-04 07:10:07,503]\u001b[0m Trial 30 finished with value: 0.5744557171342575 and parameters: {'bagging_fraction': 0.6757675424647384, 'bagging_freq': 7}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  40%|####      | 4/10 [00:29<00:42,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[148]\ttrain's binary_logloss: 0.517697\tvalid's binary_logloss: 0.574456\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598024\tvalid's binary_logloss: 0.602869\n",
      "[20]\ttrain's binary_logloss: 0.582333\tvalid's binary_logloss: 0.591504\n",
      "[30]\ttrain's binary_logloss: 0.572257\tvalid's binary_logloss: 0.585741\n",
      "[40]\ttrain's binary_logloss: 0.562885\tvalid's binary_logloss: 0.581064\n",
      "[50]\ttrain's binary_logloss: 0.555797\tvalid's binary_logloss: 0.578632\n",
      "[60]\ttrain's binary_logloss: 0.550886\tvalid's binary_logloss: 0.577758\n",
      "[70]\ttrain's binary_logloss: 0.546412\tvalid's binary_logloss: 0.57703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542625\tvalid's binary_logloss: 0.576666\n",
      "[90]\ttrain's binary_logloss: 0.538273\tvalid's binary_logloss: 0.576218\n",
      "[100]\ttrain's binary_logloss: 0.534172\tvalid's binary_logloss: 0.576011\n",
      "[110]\ttrain's binary_logloss: 0.530041\tvalid's binary_logloss: 0.575603\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526815\tvalid's binary_logloss: 0.575602\n",
      "[130]\ttrain's binary_logloss: 0.523238\tvalid's binary_logloss: 0.57547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520203\tvalid's binary_logloss: 0.575356\n",
      "[150]\ttrain's binary_logloss: 0.51662\tvalid's binary_logloss: 0.575121\n",
      "[160]\ttrain's binary_logloss: 0.513352\tvalid's binary_logloss: 0.574945\n",
      "[170]\ttrain's binary_logloss: 0.509735\tvalid's binary_logloss: 0.57489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  50%|#####     | 5/10 [00:37<00:37,  7.41s/it]\u001b[32m[I 2023-01-04 07:10:15,572]\u001b[0m Trial 31 finished with value: 0.5747889720998551 and parameters: {'bagging_fraction': 0.6697370483407328, 'bagging_freq': 3}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  50%|#####     | 5/10 [00:37<00:37,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.512062\tvalid's binary_logloss: 0.574789\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597942\tvalid's binary_logloss: 0.60251\n",
      "[20]\ttrain's binary_logloss: 0.582014\tvalid's binary_logloss: 0.591029\n",
      "[30]\ttrain's binary_logloss: 0.571898\tvalid's binary_logloss: 0.58506\n",
      "[40]\ttrain's binary_logloss: 0.56262\tvalid's binary_logloss: 0.580603\n",
      "[50]\ttrain's binary_logloss: 0.555589\tvalid's binary_logloss: 0.578081\n",
      "[60]\ttrain's binary_logloss: 0.550608\tvalid's binary_logloss: 0.577399\n",
      "[70]\ttrain's binary_logloss: 0.546092\tvalid's binary_logloss: 0.57672\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542424\tvalid's binary_logloss: 0.576206\n",
      "[90]\ttrain's binary_logloss: 0.538053\tvalid's binary_logloss: 0.575599\n",
      "[100]\ttrain's binary_logloss: 0.534146\tvalid's binary_logloss: 0.57527\n",
      "[110]\ttrain's binary_logloss: 0.530163\tvalid's binary_logloss: 0.574869\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526993\tvalid's binary_logloss: 0.574711\n",
      "[130]\ttrain's binary_logloss: 0.523372\tvalid's binary_logloss: 0.574339\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520408\tvalid's binary_logloss: 0.574109\n",
      "[150]\ttrain's binary_logloss: 0.517186\tvalid's binary_logloss: 0.573872\n",
      "[160]\ttrain's binary_logloss: 0.513818\tvalid's binary_logloss: 0.573904\n",
      "[170]\ttrain's binary_logloss: 0.510338\tvalid's binary_logloss: 0.573692\n",
      "[180]\ttrain's binary_logloss: 0.507449\tvalid's binary_logloss: 0.573579\n",
      "[190]\ttrain's binary_logloss: 0.504235\tvalid's binary_logloss: 0.573384\n",
      "[200]\ttrain's binary_logloss: 0.501105\tvalid's binary_logloss: 0.573273\n",
      "[210]\ttrain's binary_logloss: 0.497703\tvalid's binary_logloss: 0.573111\n",
      "[220]\ttrain's binary_logloss: 0.495243\tvalid's binary_logloss: 0.573037\n",
      "[230]\ttrain's binary_logloss: 0.492276\tvalid's binary_logloss: 0.572887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  60%|######    | 6/10 [00:52<00:40, 10.18s/it]\u001b[32m[I 2023-01-04 07:10:31,146]\u001b[0m Trial 32 finished with value: 0.5728734095725126 and parameters: {'bagging_fraction': 0.8414251416535368, 'bagging_freq': 7}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  60%|######    | 6/10 [00:52<00:40, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[229]\ttrain's binary_logloss: 0.492541\tvalid's binary_logloss: 0.572873\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598448\tvalid's binary_logloss: 0.603261\n",
      "[20]\ttrain's binary_logloss: 0.582795\tvalid's binary_logloss: 0.592045\n",
      "[30]\ttrain's binary_logloss: 0.572679\tvalid's binary_logloss: 0.586054\n",
      "[40]\ttrain's binary_logloss: 0.563647\tvalid's binary_logloss: 0.5814\n",
      "[50]\ttrain's binary_logloss: 0.556926\tvalid's binary_logloss: 0.579267\n",
      "[60]\ttrain's binary_logloss: 0.552277\tvalid's binary_logloss: 0.57844\n",
      "[70]\ttrain's binary_logloss: 0.547872\tvalid's binary_logloss: 0.577954\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.544322\tvalid's binary_logloss: 0.577495\n",
      "[90]\ttrain's binary_logloss: 0.540198\tvalid's binary_logloss: 0.577104\n",
      "[100]\ttrain's binary_logloss: 0.535793\tvalid's binary_logloss: 0.576828\n",
      "[110]\ttrain's binary_logloss: 0.531487\tvalid's binary_logloss: 0.57643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.528102\tvalid's binary_logloss: 0.576406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571904:  70%|#######   | 7/10 [01:03<00:31, 10.45s/it]\u001b[32m[I 2023-01-04 07:10:42,149]\u001b[0m Trial 33 finished with value: 0.5762708816557365 and parameters: {'bagging_fraction': 0.48842851210980465, 'bagging_freq': 1}. Best is trial 27 with value: 0.5728319545241207.\u001b[0m\n",
      "bagging, val_score: 0.571904:  70%|#######   | 7/10 [01:03<00:31, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130]\ttrain's binary_logloss: 0.524457\tvalid's binary_logloss: 0.576299\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttrain's binary_logloss: 0.527604\tvalid's binary_logloss: 0.576271\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597604\tvalid's binary_logloss: 0.602218\n",
      "[20]\ttrain's binary_logloss: 0.581595\tvalid's binary_logloss: 0.590487\n",
      "[30]\ttrain's binary_logloss: 0.571539\tvalid's binary_logloss: 0.584554\n",
      "[40]\ttrain's binary_logloss: 0.562213\tvalid's binary_logloss: 0.579784\n",
      "[50]\ttrain's binary_logloss: 0.555358\tvalid's binary_logloss: 0.577574\n",
      "[60]\ttrain's binary_logloss: 0.550354\tvalid's binary_logloss: 0.576576\n",
      "[70]\ttrain's binary_logloss: 0.545871\tvalid's binary_logloss: 0.575836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542195\tvalid's binary_logloss: 0.575317\n",
      "[90]\ttrain's binary_logloss: 0.537966\tvalid's binary_logloss: 0.574946\n",
      "[100]\ttrain's binary_logloss: 0.533882\tvalid's binary_logloss: 0.574604\n",
      "[110]\ttrain's binary_logloss: 0.529768\tvalid's binary_logloss: 0.574247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526513\tvalid's binary_logloss: 0.574012\n",
      "[130]\ttrain's binary_logloss: 0.523152\tvalid's binary_logloss: 0.57384\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520056\tvalid's binary_logloss: 0.573576\n",
      "[150]\ttrain's binary_logloss: 0.516783\tvalid's binary_logloss: 0.573447\n",
      "[160]\ttrain's binary_logloss: 0.513698\tvalid's binary_logloss: 0.573391\n",
      "[170]\ttrain's binary_logloss: 0.510095\tvalid's binary_logloss: 0.573245\n",
      "[180]\ttrain's binary_logloss: 0.507217\tvalid's binary_logloss: 0.573038\n",
      "[190]\ttrain's binary_logloss: 0.504195\tvalid's binary_logloss: 0.572793\n",
      "[200]\ttrain's binary_logloss: 0.501378\tvalid's binary_logloss: 0.572547\n",
      "[210]\ttrain's binary_logloss: 0.497905\tvalid's binary_logloss: 0.572277\n",
      "[220]\ttrain's binary_logloss: 0.495466\tvalid's binary_logloss: 0.572138\n",
      "[230]\ttrain's binary_logloss: 0.492616\tvalid's binary_logloss: 0.571976\n",
      "[240]\ttrain's binary_logloss: 0.490264\tvalid's binary_logloss: 0.571869\n",
      "[250]\ttrain's binary_logloss: 0.487567\tvalid's binary_logloss: 0.571754\n",
      "[260]\ttrain's binary_logloss: 0.484964\tvalid's binary_logloss: 0.571584\n",
      "[270]\ttrain's binary_logloss: 0.482608\tvalid's binary_logloss: 0.571524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571497:  80%|########  | 8/10 [01:24<00:27, 13.63s/it]\u001b[32m[I 2023-01-04 07:11:02,594]\u001b[0m Trial 34 finished with value: 0.5714972026674063 and parameters: {'bagging_fraction': 0.9796447169070526, 'bagging_freq': 7}. Best is trial 34 with value: 0.5714972026674063.\u001b[0m\n",
      "bagging, val_score: 0.571497:  80%|########  | 8/10 [01:24<00:27, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[267]\ttrain's binary_logloss: 0.483262\tvalid's binary_logloss: 0.571497\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597932\tvalid's binary_logloss: 0.602727\n",
      "[20]\ttrain's binary_logloss: 0.582167\tvalid's binary_logloss: 0.591576\n",
      "[30]\ttrain's binary_logloss: 0.572149\tvalid's binary_logloss: 0.585629\n",
      "[40]\ttrain's binary_logloss: 0.563001\tvalid's binary_logloss: 0.581136\n",
      "[50]\ttrain's binary_logloss: 0.555952\tvalid's binary_logloss: 0.578333\n",
      "[60]\ttrain's binary_logloss: 0.551142\tvalid's binary_logloss: 0.577668\n",
      "[70]\ttrain's binary_logloss: 0.546585\tvalid's binary_logloss: 0.577062\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.543016\tvalid's binary_logloss: 0.576498\n",
      "[90]\ttrain's binary_logloss: 0.539051\tvalid's binary_logloss: 0.576126\n",
      "[100]\ttrain's binary_logloss: 0.535087\tvalid's binary_logloss: 0.575857\n",
      "[110]\ttrain's binary_logloss: 0.530768\tvalid's binary_logloss: 0.57549\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527371\tvalid's binary_logloss: 0.57518\n",
      "[130]\ttrain's binary_logloss: 0.523847\tvalid's binary_logloss: 0.575164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571497:  90%|######### | 9/10 [01:34<00:12, 12.47s/it]\u001b[32m[I 2023-01-04 07:11:12,502]\u001b[0m Trial 35 finished with value: 0.5750624137943177 and parameters: {'bagging_fraction': 0.6730009290270507, 'bagging_freq': 5}. Best is trial 34 with value: 0.5714972026674063.\u001b[0m\n",
      "bagging, val_score: 0.571497:  90%|######### | 9/10 [01:34<00:12, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[122]\ttrain's binary_logloss: 0.526507\tvalid's binary_logloss: 0.575062\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597944\tvalid's binary_logloss: 0.602626\n",
      "[20]\ttrain's binary_logloss: 0.582164\tvalid's binary_logloss: 0.59144\n",
      "[30]\ttrain's binary_logloss: 0.572139\tvalid's binary_logloss: 0.585488\n",
      "[40]\ttrain's binary_logloss: 0.562747\tvalid's binary_logloss: 0.580684\n",
      "[50]\ttrain's binary_logloss: 0.555664\tvalid's binary_logloss: 0.578325\n",
      "[60]\ttrain's binary_logloss: 0.550716\tvalid's binary_logloss: 0.577374\n",
      "[70]\ttrain's binary_logloss: 0.546359\tvalid's binary_logloss: 0.576723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542776\tvalid's binary_logloss: 0.576259\n",
      "[90]\ttrain's binary_logloss: 0.538613\tvalid's binary_logloss: 0.575724\n",
      "[100]\ttrain's binary_logloss: 0.534415\tvalid's binary_logloss: 0.575363\n",
      "[110]\ttrain's binary_logloss: 0.52999\tvalid's binary_logloss: 0.574949\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526621\tvalid's binary_logloss: 0.574781\n",
      "[130]\ttrain's binary_logloss: 0.52314\tvalid's binary_logloss: 0.574583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520202\tvalid's binary_logloss: 0.574363\n",
      "[150]\ttrain's binary_logloss: 0.516395\tvalid's binary_logloss: 0.574166\n",
      "[160]\ttrain's binary_logloss: 0.512807\tvalid's binary_logloss: 0.57392\n",
      "[170]\ttrain's binary_logloss: 0.509125\tvalid's binary_logloss: 0.573859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.571497: 100%|##########| 10/10 [01:46<00:00, 12.26s/it]\u001b[32m[I 2023-01-04 07:11:24,304]\u001b[0m Trial 36 finished with value: 0.5737415249167559 and parameters: {'bagging_fraction': 0.7583105058857147, 'bagging_freq': 5}. Best is trial 34 with value: 0.5714972026674063.\u001b[0m\n",
      "bagging, val_score: 0.571497: 100%|##########| 10/10 [01:46<00:00, 10.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180]\ttrain's binary_logloss: 0.506114\tvalid's binary_logloss: 0.573873\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttrain's binary_logloss: 0.507659\tvalid's binary_logloss: 0.573742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.571497:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597369\tvalid's binary_logloss: 0.602209\n",
      "[20]\ttrain's binary_logloss: 0.579993\tvalid's binary_logloss: 0.589631\n",
      "[30]\ttrain's binary_logloss: 0.569817\tvalid's binary_logloss: 0.583837\n",
      "[40]\ttrain's binary_logloss: 0.560612\tvalid's binary_logloss: 0.579587\n",
      "[50]\ttrain's binary_logloss: 0.553755\tvalid's binary_logloss: 0.577538\n",
      "[60]\ttrain's binary_logloss: 0.548779\tvalid's binary_logloss: 0.576659\n",
      "[70]\ttrain's binary_logloss: 0.543953\tvalid's binary_logloss: 0.575945\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.540092\tvalid's binary_logloss: 0.575698\n",
      "[90]\ttrain's binary_logloss: 0.535714\tvalid's binary_logloss: 0.575163\n",
      "[100]\ttrain's binary_logloss: 0.53136\tvalid's binary_logloss: 0.574876\n",
      "[110]\ttrain's binary_logloss: 0.526952\tvalid's binary_logloss: 0.574426\n",
      "[120]\ttrain's binary_logloss: 0.523333\tvalid's binary_logloss: 0.574125\n",
      "[130]\ttrain's binary_logloss: 0.519555\tvalid's binary_logloss: 0.573977\n",
      "[140]\ttrain's binary_logloss: 0.516286\tvalid's binary_logloss: 0.573696\n",
      "[150]\ttrain's binary_logloss: 0.512819\tvalid's binary_logloss: 0.573487\n",
      "[160]\ttrain's binary_logloss: 0.509332\tvalid's binary_logloss: 0.573162\n",
      "[170]\ttrain's binary_logloss: 0.505722\tvalid's binary_logloss: 0.572951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.571497:  33%|###3      | 1/3 [00:15<00:30, 15.23s/it]\u001b[32m[I 2023-01-04 07:11:39,542]\u001b[0m Trial 37 finished with value: 0.5728490654175039 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.5728490654175039.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.571497:  33%|###3      | 1/3 [00:15<00:30, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180]\ttrain's binary_logloss: 0.502903\tvalid's binary_logloss: 0.57297\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttrain's binary_logloss: 0.504417\tvalid's binary_logloss: 0.572849\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597369\tvalid's binary_logloss: 0.602209\n",
      "[20]\ttrain's binary_logloss: 0.579993\tvalid's binary_logloss: 0.589631\n",
      "[30]\ttrain's binary_logloss: 0.569817\tvalid's binary_logloss: 0.583837\n",
      "[40]\ttrain's binary_logloss: 0.560612\tvalid's binary_logloss: 0.579587\n",
      "[50]\ttrain's binary_logloss: 0.553755\tvalid's binary_logloss: 0.577538\n",
      "[60]\ttrain's binary_logloss: 0.548779\tvalid's binary_logloss: 0.576659\n",
      "[70]\ttrain's binary_logloss: 0.543953\tvalid's binary_logloss: 0.575945\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.540092\tvalid's binary_logloss: 0.575698\n",
      "[90]\ttrain's binary_logloss: 0.535714\tvalid's binary_logloss: 0.575163\n",
      "[100]\ttrain's binary_logloss: 0.53136\tvalid's binary_logloss: 0.574876\n",
      "[110]\ttrain's binary_logloss: 0.526952\tvalid's binary_logloss: 0.574426\n",
      "[120]\ttrain's binary_logloss: 0.523333\tvalid's binary_logloss: 0.574125\n",
      "[130]\ttrain's binary_logloss: 0.519555\tvalid's binary_logloss: 0.573977\n",
      "[140]\ttrain's binary_logloss: 0.516286\tvalid's binary_logloss: 0.573696\n",
      "[150]\ttrain's binary_logloss: 0.512819\tvalid's binary_logloss: 0.573487\n",
      "[160]\ttrain's binary_logloss: 0.509332\tvalid's binary_logloss: 0.573162\n",
      "[170]\ttrain's binary_logloss: 0.505722\tvalid's binary_logloss: 0.572951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.571497:  67%|######6   | 2/3 [00:27<00:13, 13.72s/it]\u001b[32m[I 2023-01-04 07:11:52,203]\u001b[0m Trial 38 finished with value: 0.5728490654175038 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 0.5728490654175038.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.571497:  67%|######6   | 2/3 [00:27<00:13, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180]\ttrain's binary_logloss: 0.502903\tvalid's binary_logloss: 0.57297\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttrain's binary_logloss: 0.504417\tvalid's binary_logloss: 0.572849\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597604\tvalid's binary_logloss: 0.602218\n",
      "[20]\ttrain's binary_logloss: 0.581595\tvalid's binary_logloss: 0.590487\n",
      "[30]\ttrain's binary_logloss: 0.571539\tvalid's binary_logloss: 0.584554\n",
      "[40]\ttrain's binary_logloss: 0.562213\tvalid's binary_logloss: 0.579784\n",
      "[50]\ttrain's binary_logloss: 0.555358\tvalid's binary_logloss: 0.577574\n",
      "[60]\ttrain's binary_logloss: 0.550354\tvalid's binary_logloss: 0.576576\n",
      "[70]\ttrain's binary_logloss: 0.545871\tvalid's binary_logloss: 0.575836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542195\tvalid's binary_logloss: 0.575317\n",
      "[90]\ttrain's binary_logloss: 0.537966\tvalid's binary_logloss: 0.574946\n",
      "[100]\ttrain's binary_logloss: 0.533882\tvalid's binary_logloss: 0.574604\n",
      "[110]\ttrain's binary_logloss: 0.529768\tvalid's binary_logloss: 0.574247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526513\tvalid's binary_logloss: 0.574012\n",
      "[130]\ttrain's binary_logloss: 0.523152\tvalid's binary_logloss: 0.57384\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520056\tvalid's binary_logloss: 0.573576\n",
      "[150]\ttrain's binary_logloss: 0.516783\tvalid's binary_logloss: 0.573447\n",
      "[160]\ttrain's binary_logloss: 0.513698\tvalid's binary_logloss: 0.573391\n",
      "[170]\ttrain's binary_logloss: 0.510095\tvalid's binary_logloss: 0.573245\n",
      "[180]\ttrain's binary_logloss: 0.507217\tvalid's binary_logloss: 0.573038\n",
      "[190]\ttrain's binary_logloss: 0.504195\tvalid's binary_logloss: 0.572793\n",
      "[200]\ttrain's binary_logloss: 0.501378\tvalid's binary_logloss: 0.572547\n",
      "[210]\ttrain's binary_logloss: 0.497905\tvalid's binary_logloss: 0.572277\n",
      "[220]\ttrain's binary_logloss: 0.495466\tvalid's binary_logloss: 0.572138\n",
      "[230]\ttrain's binary_logloss: 0.492616\tvalid's binary_logloss: 0.571976\n",
      "[240]\ttrain's binary_logloss: 0.490264\tvalid's binary_logloss: 0.571869\n",
      "[250]\ttrain's binary_logloss: 0.487567\tvalid's binary_logloss: 0.571754\n",
      "[260]\ttrain's binary_logloss: 0.484964\tvalid's binary_logloss: 0.571584\n",
      "[270]\ttrain's binary_logloss: 0.482608\tvalid's binary_logloss: 0.571524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.571497: 100%|##########| 3/3 [00:42<00:00, 14.26s/it]\u001b[32m[I 2023-01-04 07:12:07,113]\u001b[0m Trial 39 finished with value: 0.5714972026674064 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.5714972026674064.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.571497: 100%|##########| 3/3 [00:42<00:00, 14.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[267]\ttrain's binary_logloss: 0.483262\tvalid's binary_logloss: 0.571497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571497:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.59821\tvalid's binary_logloss: 0.602425\n",
      "[20]\ttrain's binary_logloss: 0.582579\tvalid's binary_logloss: 0.590885\n",
      "[30]\ttrain's binary_logloss: 0.572871\tvalid's binary_logloss: 0.584885\n",
      "[40]\ttrain's binary_logloss: 0.563931\tvalid's binary_logloss: 0.580087\n",
      "[50]\ttrain's binary_logloss: 0.557364\tvalid's binary_logloss: 0.577707\n",
      "[60]\ttrain's binary_logloss: 0.552633\tvalid's binary_logloss: 0.576589\n",
      "[70]\ttrain's binary_logloss: 0.548543\tvalid's binary_logloss: 0.575794\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.545135\tvalid's binary_logloss: 0.575356\n",
      "[90]\ttrain's binary_logloss: 0.54132\tvalid's binary_logloss: 0.574782\n",
      "[100]\ttrain's binary_logloss: 0.537541\tvalid's binary_logloss: 0.574324\n",
      "[110]\ttrain's binary_logloss: 0.533811\tvalid's binary_logloss: 0.574006\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.530774\tvalid's binary_logloss: 0.573767\n",
      "[130]\ttrain's binary_logloss: 0.527737\tvalid's binary_logloss: 0.573474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.525074\tvalid's binary_logloss: 0.573302\n",
      "[150]\ttrain's binary_logloss: 0.521919\tvalid's binary_logloss: 0.573095\n",
      "[160]\ttrain's binary_logloss: 0.519192\tvalid's binary_logloss: 0.572966\n",
      "[170]\ttrain's binary_logloss: 0.516232\tvalid's binary_logloss: 0.572868\n",
      "[180]\ttrain's binary_logloss: 0.513768\tvalid's binary_logloss: 0.572784\n",
      "[190]\ttrain's binary_logloss: 0.511121\tvalid's binary_logloss: 0.572425\n",
      "[200]\ttrain's binary_logloss: 0.50869\tvalid's binary_logloss: 0.572278\n",
      "[210]\ttrain's binary_logloss: 0.505633\tvalid's binary_logloss: 0.571991\n",
      "[220]\ttrain's binary_logloss: 0.503507\tvalid's binary_logloss: 0.57179\n",
      "[230]\ttrain's binary_logloss: 0.500675\tvalid's binary_logloss: 0.571683\n",
      "[240]\ttrain's binary_logloss: 0.498749\tvalid's binary_logloss: 0.571631\n",
      "[250]\ttrain's binary_logloss: 0.496375\tvalid's binary_logloss: 0.57161\n",
      "[260]\ttrain's binary_logloss: 0.493751\tvalid's binary_logloss: 0.571487\n",
      "[270]\ttrain's binary_logloss: 0.49172\tvalid's binary_logloss: 0.571463\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[280]\ttrain's binary_logloss: 0.489312\tvalid's binary_logloss: 0.571398\n",
      "[290]\ttrain's binary_logloss: 0.487055\tvalid's binary_logloss: 0.571392\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttrain's binary_logloss: 0.487346\tvalid's binary_logloss: 0.571385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:   5%|5         | 1/20 [00:17<05:24, 17.08s/it]\u001b[32m[I 2023-01-04 07:12:24,203]\u001b[0m Trial 40 finished with value: 0.5713854776011388 and parameters: {'lambda_l1': 0.1698617694136903, 'lambda_l2': 2.0470139543874986}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:   5%|5         | 1/20 [00:17<05:24, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597604\tvalid's binary_logloss: 0.602218\n",
      "[20]\ttrain's binary_logloss: 0.581595\tvalid's binary_logloss: 0.590487\n",
      "[30]\ttrain's binary_logloss: 0.57154\tvalid's binary_logloss: 0.584556\n",
      "[40]\ttrain's binary_logloss: 0.562222\tvalid's binary_logloss: 0.579875\n",
      "[50]\ttrain's binary_logloss: 0.555309\tvalid's binary_logloss: 0.577698\n",
      "[60]\ttrain's binary_logloss: 0.550226\tvalid's binary_logloss: 0.576724\n",
      "[70]\ttrain's binary_logloss: 0.545898\tvalid's binary_logloss: 0.57614\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542076\tvalid's binary_logloss: 0.575654\n",
      "[90]\ttrain's binary_logloss: 0.537927\tvalid's binary_logloss: 0.575019\n",
      "[100]\ttrain's binary_logloss: 0.533732\tvalid's binary_logloss: 0.574738\n",
      "[110]\ttrain's binary_logloss: 0.52968\tvalid's binary_logloss: 0.574397\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526426\tvalid's binary_logloss: 0.574221\n",
      "[130]\ttrain's binary_logloss: 0.523008\tvalid's binary_logloss: 0.574001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520161\tvalid's binary_logloss: 0.573725\n",
      "[150]\ttrain's binary_logloss: 0.516822\tvalid's binary_logloss: 0.573422\n",
      "[160]\ttrain's binary_logloss: 0.51354\tvalid's binary_logloss: 0.573084\n",
      "[170]\ttrain's binary_logloss: 0.509715\tvalid's binary_logloss: 0.572807\n",
      "[180]\ttrain's binary_logloss: 0.507015\tvalid's binary_logloss: 0.572809\n",
      "[190]\ttrain's binary_logloss: 0.503912\tvalid's binary_logloss: 0.57254\n",
      "[200]\ttrain's binary_logloss: 0.500859\tvalid's binary_logloss: 0.57241\n",
      "[210]\ttrain's binary_logloss: 0.497505\tvalid's binary_logloss: 0.572243\n",
      "[220]\ttrain's binary_logloss: 0.494873\tvalid's binary_logloss: 0.572205\n",
      "[230]\ttrain's binary_logloss: 0.492038\tvalid's binary_logloss: 0.572112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  10%|#         | 2/20 [00:31<04:37, 15.41s/it]\u001b[32m[I 2023-01-04 07:12:38,445]\u001b[0m Trial 41 finished with value: 0.5720941067718954 and parameters: {'lambda_l1': 1.2206355222762104e-07, 'lambda_l2': 4.79355973246669e-06}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  10%|#         | 2/20 [00:31<04:37, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[228]\ttrain's binary_logloss: 0.492517\tvalid's binary_logloss: 0.572094\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597604\tvalid's binary_logloss: 0.602218\n",
      "[20]\ttrain's binary_logloss: 0.581591\tvalid's binary_logloss: 0.590492\n",
      "[30]\ttrain's binary_logloss: 0.571538\tvalid's binary_logloss: 0.584525\n",
      "[40]\ttrain's binary_logloss: 0.562248\tvalid's binary_logloss: 0.579751\n",
      "[50]\ttrain's binary_logloss: 0.555367\tvalid's binary_logloss: 0.577583\n",
      "[60]\ttrain's binary_logloss: 0.550428\tvalid's binary_logloss: 0.576614\n",
      "[70]\ttrain's binary_logloss: 0.54594\tvalid's binary_logloss: 0.575915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542194\tvalid's binary_logloss: 0.575362\n",
      "[90]\ttrain's binary_logloss: 0.537966\tvalid's binary_logloss: 0.574841\n",
      "[100]\ttrain's binary_logloss: 0.533834\tvalid's binary_logloss: 0.574443\n",
      "[110]\ttrain's binary_logloss: 0.529721\tvalid's binary_logloss: 0.574\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.52648\tvalid's binary_logloss: 0.573866\n",
      "[130]\ttrain's binary_logloss: 0.523109\tvalid's binary_logloss: 0.573559\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520245\tvalid's binary_logloss: 0.573302\n",
      "[150]\ttrain's binary_logloss: 0.516731\tvalid's binary_logloss: 0.573139\n",
      "[160]\ttrain's binary_logloss: 0.513607\tvalid's binary_logloss: 0.572857\n",
      "[170]\ttrain's binary_logloss: 0.510191\tvalid's binary_logloss: 0.572757\n",
      "[180]\ttrain's binary_logloss: 0.50765\tvalid's binary_logloss: 0.572685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  15%|#5        | 3/20 [00:45<04:11, 14.81s/it]\u001b[32m[I 2023-01-04 07:12:52,533]\u001b[0m Trial 42 finished with value: 0.5725549825147769 and parameters: {'lambda_l1': 0.0004298322711254279, 'lambda_l2': 3.705663982659978e-06}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  15%|#5        | 3/20 [00:45<04:11, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\ttrain's binary_logloss: 0.509009\tvalid's binary_logloss: 0.572555\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's binary_logloss: 0.60088\tvalid's binary_logloss: 0.603989\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttrain's binary_logloss: 0.587359\tvalid's binary_logloss: 0.592973\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttrain's binary_logloss: 0.579488\tvalid's binary_logloss: 0.587317\n",
      "[40]\ttrain's binary_logloss: 0.571863\tvalid's binary_logloss: 0.582287\n",
      "[50]\ttrain's binary_logloss: 0.566716\tvalid's binary_logloss: 0.579804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttrain's binary_logloss: 0.563525\tvalid's binary_logloss: 0.578673\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.560666\tvalid's binary_logloss: 0.57779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.558424\tvalid's binary_logloss: 0.577215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttrain's binary_logloss: 0.555918\tvalid's binary_logloss: 0.576759\n",
      "[100]\ttrain's binary_logloss: 0.553105\tvalid's binary_logloss: 0.576287\n",
      "[110]\ttrain's binary_logloss: 0.550211\tvalid's binary_logloss: 0.575782\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.547961\tvalid's binary_logloss: 0.575384\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttrain's binary_logloss: 0.545787\tvalid's binary_logloss: 0.575095\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.544137\tvalid's binary_logloss: 0.574895\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttrain's binary_logloss: 0.541861\tvalid's binary_logloss: 0.574694\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[160]\ttrain's binary_logloss: 0.53971\tvalid's binary_logloss: 0.574436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[170]\ttrain's binary_logloss: 0.537612\tvalid's binary_logloss: 0.574361\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[180]\ttrain's binary_logloss: 0.536079\tvalid's binary_logloss: 0.574218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[190]\ttrain's binary_logloss: 0.53419\tvalid's binary_logloss: 0.574001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttrain's binary_logloss: 0.532357\tvalid's binary_logloss: 0.573794\n",
      "[210]\ttrain's binary_logloss: 0.530345\tvalid's binary_logloss: 0.573645\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[220]\ttrain's binary_logloss: 0.529044\tvalid's binary_logloss: 0.573582\n",
      "[230]\ttrain's binary_logloss: 0.52727\tvalid's binary_logloss: 0.573436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[240]\ttrain's binary_logloss: 0.525855\tvalid's binary_logloss: 0.573394\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\ttrain's binary_logloss: 0.52428\tvalid's binary_logloss: 0.573369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[260]\ttrain's binary_logloss: 0.52286\tvalid's binary_logloss: 0.573246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[270]\ttrain's binary_logloss: 0.521706\tvalid's binary_logloss: 0.573207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  20%|##        | 4/20 [01:11<05:07, 19.21s/it]\u001b[32m[I 2023-01-04 07:13:18,501]\u001b[0m Trial 43 finished with value: 0.5731911292540811 and parameters: {'lambda_l1': 9.18961198593515, 'lambda_l2': 0.0031791139824252817}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  20%|##        | 4/20 [01:11<05:07, 19.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280]\ttrain's binary_logloss: 0.520352\tvalid's binary_logloss: 0.573248\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttrain's binary_logloss: 0.521531\tvalid's binary_logloss: 0.573191\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597637\tvalid's binary_logloss: 0.602226\n",
      "[20]\ttrain's binary_logloss: 0.581627\tvalid's binary_logloss: 0.590516\n",
      "[30]\ttrain's binary_logloss: 0.571499\tvalid's binary_logloss: 0.584472\n",
      "[40]\ttrain's binary_logloss: 0.562269\tvalid's binary_logloss: 0.579824\n",
      "[50]\ttrain's binary_logloss: 0.55545\tvalid's binary_logloss: 0.577549\n",
      "[60]\ttrain's binary_logloss: 0.550468\tvalid's binary_logloss: 0.576485\n",
      "[70]\ttrain's binary_logloss: 0.545937\tvalid's binary_logloss: 0.575778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542286\tvalid's binary_logloss: 0.575235\n",
      "[90]\ttrain's binary_logloss: 0.538006\tvalid's binary_logloss: 0.574686\n",
      "[100]\ttrain's binary_logloss: 0.53393\tvalid's binary_logloss: 0.574238\n",
      "[110]\ttrain's binary_logloss: 0.529837\tvalid's binary_logloss: 0.573915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526598\tvalid's binary_logloss: 0.573649\n",
      "[130]\ttrain's binary_logloss: 0.52314\tvalid's binary_logloss: 0.573427\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520356\tvalid's binary_logloss: 0.573207\n",
      "[150]\ttrain's binary_logloss: 0.516792\tvalid's binary_logloss: 0.573063\n",
      "[160]\ttrain's binary_logloss: 0.513282\tvalid's binary_logloss: 0.572866\n",
      "[170]\ttrain's binary_logloss: 0.509969\tvalid's binary_logloss: 0.572779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  25%|##5       | 5/20 [01:28<04:36, 18.46s/it]\u001b[32m[I 2023-01-04 07:13:35,635]\u001b[0m Trial 44 finished with value: 0.5727035004809647 and parameters: {'lambda_l1': 5.078130707122152e-08, 'lambda_l2': 0.049592376374763034}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  25%|##5       | 5/20 [01:28<04:36, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.512074\tvalid's binary_logloss: 0.572704\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597604\tvalid's binary_logloss: 0.602218\n",
      "[20]\ttrain's binary_logloss: 0.581598\tvalid's binary_logloss: 0.590502\n",
      "[30]\ttrain's binary_logloss: 0.571535\tvalid's binary_logloss: 0.584529\n",
      "[40]\ttrain's binary_logloss: 0.562246\tvalid's binary_logloss: 0.579704\n",
      "[50]\ttrain's binary_logloss: 0.555361\tvalid's binary_logloss: 0.5774\n",
      "[60]\ttrain's binary_logloss: 0.55038\tvalid's binary_logloss: 0.576507\n",
      "[70]\ttrain's binary_logloss: 0.546023\tvalid's binary_logloss: 0.57582\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542408\tvalid's binary_logloss: 0.575415\n",
      "[90]\ttrain's binary_logloss: 0.538216\tvalid's binary_logloss: 0.574767\n",
      "[100]\ttrain's binary_logloss: 0.533994\tvalid's binary_logloss: 0.574502\n",
      "[110]\ttrain's binary_logloss: 0.529908\tvalid's binary_logloss: 0.5741\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526595\tvalid's binary_logloss: 0.573891\n",
      "[130]\ttrain's binary_logloss: 0.523242\tvalid's binary_logloss: 0.573705\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520314\tvalid's binary_logloss: 0.573333\n",
      "[150]\ttrain's binary_logloss: 0.516982\tvalid's binary_logloss: 0.573262\n",
      "[160]\ttrain's binary_logloss: 0.513585\tvalid's binary_logloss: 0.573159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  30%|###       | 6/20 [01:42<03:55, 16.80s/it]\u001b[32m[I 2023-01-04 07:13:49,219]\u001b[0m Trial 45 finished with value: 0.5729727601113798 and parameters: {'lambda_l1': 0.0001734074844504017, 'lambda_l2': 0.0007404389957295124}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  30%|###       | 6/20 [01:42<03:55, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain's binary_logloss: 0.509962\tvalid's binary_logloss: 0.573046\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.512224\tvalid's binary_logloss: 0.572973\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597604\tvalid's binary_logloss: 0.602218\n",
      "[20]\ttrain's binary_logloss: 0.581595\tvalid's binary_logloss: 0.590513\n",
      "[30]\ttrain's binary_logloss: 0.57153\tvalid's binary_logloss: 0.584548\n",
      "[40]\ttrain's binary_logloss: 0.562253\tvalid's binary_logloss: 0.579736\n",
      "[50]\ttrain's binary_logloss: 0.555348\tvalid's binary_logloss: 0.577506\n",
      "[60]\ttrain's binary_logloss: 0.550354\tvalid's binary_logloss: 0.57657\n",
      "[70]\ttrain's binary_logloss: 0.545868\tvalid's binary_logloss: 0.575847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542161\tvalid's binary_logloss: 0.575346\n",
      "[90]\ttrain's binary_logloss: 0.538004\tvalid's binary_logloss: 0.574679\n",
      "[100]\ttrain's binary_logloss: 0.53394\tvalid's binary_logloss: 0.574363\n",
      "[110]\ttrain's binary_logloss: 0.529846\tvalid's binary_logloss: 0.573991\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526506\tvalid's binary_logloss: 0.573864\n",
      "[130]\ttrain's binary_logloss: 0.52299\tvalid's binary_logloss: 0.573564\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520106\tvalid's binary_logloss: 0.573265\n",
      "[150]\ttrain's binary_logloss: 0.51657\tvalid's binary_logloss: 0.573\n",
      "[160]\ttrain's binary_logloss: 0.513345\tvalid's binary_logloss: 0.572734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  35%|###5      | 7/20 [01:52<03:10, 14.64s/it]\u001b[32m[I 2023-01-04 07:13:59,408]\u001b[0m Trial 46 finished with value: 0.5725006959362997 and parameters: {'lambda_l1': 1.554880890768819e-08, 'lambda_l2': 0.0017104492752132918}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  35%|###5      | 7/20 [01:52<03:10, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain's binary_logloss: 0.509676\tvalid's binary_logloss: 0.572563\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttrain's binary_logloss: 0.51241\tvalid's binary_logloss: 0.572501\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597692\tvalid's binary_logloss: 0.602235\n",
      "[20]\ttrain's binary_logloss: 0.581664\tvalid's binary_logloss: 0.590499\n",
      "[30]\ttrain's binary_logloss: 0.571636\tvalid's binary_logloss: 0.584444\n",
      "[40]\ttrain's binary_logloss: 0.562485\tvalid's binary_logloss: 0.579773\n",
      "[50]\ttrain's binary_logloss: 0.55566\tvalid's binary_logloss: 0.577475\n",
      "[60]\ttrain's binary_logloss: 0.550699\tvalid's binary_logloss: 0.576434\n",
      "[70]\ttrain's binary_logloss: 0.546171\tvalid's binary_logloss: 0.575643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542577\tvalid's binary_logloss: 0.575203\n",
      "[90]\ttrain's binary_logloss: 0.53852\tvalid's binary_logloss: 0.574679\n",
      "[100]\ttrain's binary_logloss: 0.534494\tvalid's binary_logloss: 0.574425\n",
      "[110]\ttrain's binary_logloss: 0.530553\tvalid's binary_logloss: 0.57402\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527428\tvalid's binary_logloss: 0.573838\n",
      "[130]\ttrain's binary_logloss: 0.524071\tvalid's binary_logloss: 0.573617\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.52123\tvalid's binary_logloss: 0.573352\n",
      "[150]\ttrain's binary_logloss: 0.518041\tvalid's binary_logloss: 0.573175\n",
      "[160]\ttrain's binary_logloss: 0.514863\tvalid's binary_logloss: 0.572931\n",
      "[170]\ttrain's binary_logloss: 0.511331\tvalid's binary_logloss: 0.572739\n",
      "[180]\ttrain's binary_logloss: 0.508731\tvalid's binary_logloss: 0.572699\n",
      "[190]\ttrain's binary_logloss: 0.505666\tvalid's binary_logloss: 0.572335\n",
      "[200]\ttrain's binary_logloss: 0.50272\tvalid's binary_logloss: 0.572111\n",
      "[210]\ttrain's binary_logloss: 0.49945\tvalid's binary_logloss: 0.571938\n",
      "[220]\ttrain's binary_logloss: 0.497119\tvalid's binary_logloss: 0.571806\n",
      "[230]\ttrain's binary_logloss: 0.494549\tvalid's binary_logloss: 0.571782\n",
      "[240]\ttrain's binary_logloss: 0.492179\tvalid's binary_logloss: 0.571693\n",
      "[250]\ttrain's binary_logloss: 0.48968\tvalid's binary_logloss: 0.571632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  40%|####      | 8/20 [02:11<03:11, 15.97s/it]\u001b[32m[I 2023-01-04 07:14:18,228]\u001b[0m Trial 47 finished with value: 0.5715138665046849 and parameters: {'lambda_l1': 5.549726951282371e-07, 'lambda_l2': 0.19877774097965248}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  40%|####      | 8/20 [02:11<03:11, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\ttrain's binary_logloss: 0.487148\tvalid's binary_logloss: 0.571527\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttrain's binary_logloss: 0.488083\tvalid's binary_logloss: 0.571514\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597714\tvalid's binary_logloss: 0.60225\n",
      "[20]\ttrain's binary_logloss: 0.581642\tvalid's binary_logloss: 0.590477\n",
      "[30]\ttrain's binary_logloss: 0.571629\tvalid's binary_logloss: 0.584469\n",
      "[40]\ttrain's binary_logloss: 0.562469\tvalid's binary_logloss: 0.57978\n",
      "[50]\ttrain's binary_logloss: 0.555654\tvalid's binary_logloss: 0.577427\n",
      "[60]\ttrain's binary_logloss: 0.550741\tvalid's binary_logloss: 0.576462\n",
      "[70]\ttrain's binary_logloss: 0.546231\tvalid's binary_logloss: 0.57572\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542681\tvalid's binary_logloss: 0.575357\n",
      "[90]\ttrain's binary_logloss: 0.538614\tvalid's binary_logloss: 0.575012\n",
      "[100]\ttrain's binary_logloss: 0.534612\tvalid's binary_logloss: 0.574583\n",
      "[110]\ttrain's binary_logloss: 0.5306\tvalid's binary_logloss: 0.574269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527295\tvalid's binary_logloss: 0.573952\n",
      "[130]\ttrain's binary_logloss: 0.52401\tvalid's binary_logloss: 0.573812\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.521114\tvalid's binary_logloss: 0.573549\n",
      "[150]\ttrain's binary_logloss: 0.517584\tvalid's binary_logloss: 0.57333\n",
      "[160]\ttrain's binary_logloss: 0.514477\tvalid's binary_logloss: 0.573302\n",
      "[170]\ttrain's binary_logloss: 0.511296\tvalid's binary_logloss: 0.573261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  45%|####5     | 9/20 [02:22<02:39, 14.53s/it]\u001b[32m[I 2023-01-04 07:14:29,576]\u001b[0m Trial 48 finished with value: 0.5732087339244017 and parameters: {'lambda_l1': 6.2974926748260746e-06, 'lambda_l2': 0.2626844548413751}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  45%|####5     | 9/20 [02:22<02:39, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.513373\tvalid's binary_logloss: 0.573209\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597673\tvalid's binary_logloss: 0.602225\n",
      "[20]\ttrain's binary_logloss: 0.581625\tvalid's binary_logloss: 0.590475\n",
      "[30]\ttrain's binary_logloss: 0.571656\tvalid's binary_logloss: 0.584651\n",
      "[40]\ttrain's binary_logloss: 0.56237\tvalid's binary_logloss: 0.579876\n",
      "[50]\ttrain's binary_logloss: 0.555526\tvalid's binary_logloss: 0.577745\n",
      "[60]\ttrain's binary_logloss: 0.550501\tvalid's binary_logloss: 0.576861\n",
      "[70]\ttrain's binary_logloss: 0.546024\tvalid's binary_logloss: 0.576141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542351\tvalid's binary_logloss: 0.575444\n",
      "[90]\ttrain's binary_logloss: 0.53829\tvalid's binary_logloss: 0.575053\n",
      "[100]\ttrain's binary_logloss: 0.534068\tvalid's binary_logloss: 0.574676\n",
      "[110]\ttrain's binary_logloss: 0.529914\tvalid's binary_logloss: 0.574235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526904\tvalid's binary_logloss: 0.574011\n",
      "[130]\ttrain's binary_logloss: 0.523536\tvalid's binary_logloss: 0.573876\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520721\tvalid's binary_logloss: 0.573632\n",
      "[150]\ttrain's binary_logloss: 0.517114\tvalid's binary_logloss: 0.573335\n",
      "[160]\ttrain's binary_logloss: 0.514144\tvalid's binary_logloss: 0.573182\n",
      "[170]\ttrain's binary_logloss: 0.510536\tvalid's binary_logloss: 0.573127\n",
      "[180]\ttrain's binary_logloss: 0.507715\tvalid's binary_logloss: 0.572929\n",
      "[190]\ttrain's binary_logloss: 0.504523\tvalid's binary_logloss: 0.572716\n",
      "[200]\ttrain's binary_logloss: 0.501758\tvalid's binary_logloss: 0.57262\n",
      "[210]\ttrain's binary_logloss: 0.498439\tvalid's binary_logloss: 0.572408\n",
      "[220]\ttrain's binary_logloss: 0.49588\tvalid's binary_logloss: 0.572313\n",
      "[230]\ttrain's binary_logloss: 0.492981\tvalid's binary_logloss: 0.57217\n",
      "[240]\ttrain's binary_logloss: 0.4906\tvalid's binary_logloss: 0.572137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  50%|#####     | 10/20 [02:48<03:00, 18.00s/it]\u001b[32m[I 2023-01-04 07:14:55,360]\u001b[0m Trial 49 finished with value: 0.5720776680029899 and parameters: {'lambda_l1': 0.035310011863970286, 'lambda_l2': 1.925812511416134e-06}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  50%|#####     | 10/20 [02:48<03:00, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[233]\ttrain's binary_logloss: 0.492155\tvalid's binary_logloss: 0.572078\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.59983\tvalid's binary_logloss: 0.603357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttrain's binary_logloss: 0.585585\tvalid's binary_logloss: 0.592182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttrain's binary_logloss: 0.57709\tvalid's binary_logloss: 0.586316\n",
      "[40]\ttrain's binary_logloss: 0.569056\tvalid's binary_logloss: 0.581504\n",
      "[50]\ttrain's binary_logloss: 0.563378\tvalid's binary_logloss: 0.578986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttrain's binary_logloss: 0.55972\tvalid's binary_logloss: 0.577914\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.556462\tvalid's binary_logloss: 0.576946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.553879\tvalid's binary_logloss: 0.576379\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttrain's binary_logloss: 0.550791\tvalid's binary_logloss: 0.575795\n",
      "[100]\ttrain's binary_logloss: 0.547613\tvalid's binary_logloss: 0.575274\n",
      "[110]\ttrain's binary_logloss: 0.544483\tvalid's binary_logloss: 0.574864\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.541974\tvalid's binary_logloss: 0.574529\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttrain's binary_logloss: 0.539511\tvalid's binary_logloss: 0.574304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.537567\tvalid's binary_logloss: 0.574024\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttrain's binary_logloss: 0.535021\tvalid's binary_logloss: 0.573723\n",
      "[160]\ttrain's binary_logloss: 0.532665\tvalid's binary_logloss: 0.573477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[170]\ttrain's binary_logloss: 0.530199\tvalid's binary_logloss: 0.573302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[180]\ttrain's binary_logloss: 0.52826\tvalid's binary_logloss: 0.573138\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[190]\ttrain's binary_logloss: 0.526206\tvalid's binary_logloss: 0.572935\n",
      "[200]\ttrain's binary_logloss: 0.524175\tvalid's binary_logloss: 0.572753\n",
      "[210]\ttrain's binary_logloss: 0.521872\tvalid's binary_logloss: 0.572523\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[220]\ttrain's binary_logloss: 0.520189\tvalid's binary_logloss: 0.572452\n",
      "[230]\ttrain's binary_logloss: 0.518278\tvalid's binary_logloss: 0.572425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttrain's binary_logloss: 0.518799\tvalid's binary_logloss: 0.572383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  55%|#####5    | 11/20 [03:07<02:45, 18.41s/it]\u001b[32m[I 2023-01-04 07:15:14,707]\u001b[0m Trial 50 finished with value: 0.5723827049170371 and parameters: {'lambda_l1': 5.036583977093645, 'lambda_l2': 3.5181309558102174}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  55%|#####5    | 11/20 [03:07<02:45, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598645\tvalid's binary_logloss: 0.602676\n",
      "[20]\ttrain's binary_logloss: 0.583321\tvalid's binary_logloss: 0.591047\n",
      "[30]\ttrain's binary_logloss: 0.573858\tvalid's binary_logloss: 0.585088\n",
      "[40]\ttrain's binary_logloss: 0.56518\tvalid's binary_logloss: 0.580319\n",
      "[50]\ttrain's binary_logloss: 0.558795\tvalid's binary_logloss: 0.577821\n",
      "[60]\ttrain's binary_logloss: 0.554251\tvalid's binary_logloss: 0.576774\n",
      "[70]\ttrain's binary_logloss: 0.550301\tvalid's binary_logloss: 0.575993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.547097\tvalid's binary_logloss: 0.575544\n",
      "[90]\ttrain's binary_logloss: 0.5436\tvalid's binary_logloss: 0.575056\n",
      "[100]\ttrain's binary_logloss: 0.539954\tvalid's binary_logloss: 0.574581\n",
      "[110]\ttrain's binary_logloss: 0.536717\tvalid's binary_logloss: 0.574308\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.533846\tvalid's binary_logloss: 0.573992\n",
      "[130]\ttrain's binary_logloss: 0.530993\tvalid's binary_logloss: 0.573731\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.528564\tvalid's binary_logloss: 0.573445\n",
      "[150]\ttrain's binary_logloss: 0.52575\tvalid's binary_logloss: 0.573265\n",
      "[160]\ttrain's binary_logloss: 0.523132\tvalid's binary_logloss: 0.573056\n",
      "[170]\ttrain's binary_logloss: 0.520828\tvalid's binary_logloss: 0.572857\n",
      "[180]\ttrain's binary_logloss: 0.518676\tvalid's binary_logloss: 0.572823\n",
      "[190]\ttrain's binary_logloss: 0.515962\tvalid's binary_logloss: 0.572631\n",
      "[200]\ttrain's binary_logloss: 0.513644\tvalid's binary_logloss: 0.572532\n",
      "[210]\ttrain's binary_logloss: 0.510962\tvalid's binary_logloss: 0.572266\n",
      "[220]\ttrain's binary_logloss: 0.508839\tvalid's binary_logloss: 0.572084\n",
      "[230]\ttrain's binary_logloss: 0.506503\tvalid's binary_logloss: 0.572033\n",
      "[240]\ttrain's binary_logloss: 0.504665\tvalid's binary_logloss: 0.571944\n",
      "[250]\ttrain's binary_logloss: 0.502741\tvalid's binary_logloss: 0.571945\n",
      "[260]\ttrain's binary_logloss: 0.500447\tvalid's binary_logloss: 0.571827\n",
      "[270]\ttrain's binary_logloss: 0.498529\tvalid's binary_logloss: 0.571702\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[280]\ttrain's binary_logloss: 0.496428\tvalid's binary_logloss: 0.571643\n",
      "[290]\ttrain's binary_logloss: 0.494277\tvalid's binary_logloss: 0.571642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  60%|######    | 12/20 [03:25<02:25, 18.22s/it]\u001b[32m[I 2023-01-04 07:15:32,489]\u001b[0m Trial 51 finished with value: 0.5716149151870258 and parameters: {'lambda_l1': 0.03222358827110318, 'lambda_l2': 5.878883507562609}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  60%|######    | 12/20 [03:25<02:25, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[284]\ttrain's binary_logloss: 0.495621\tvalid's binary_logloss: 0.571615\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.59766\tvalid's binary_logloss: 0.602224\n",
      "[20]\ttrain's binary_logloss: 0.581599\tvalid's binary_logloss: 0.59046\n",
      "[30]\ttrain's binary_logloss: 0.571607\tvalid's binary_logloss: 0.58446\n",
      "[40]\ttrain's binary_logloss: 0.562443\tvalid's binary_logloss: 0.579912\n",
      "[50]\ttrain's binary_logloss: 0.555677\tvalid's binary_logloss: 0.577712\n",
      "[60]\ttrain's binary_logloss: 0.550774\tvalid's binary_logloss: 0.576839\n",
      "[70]\ttrain's binary_logloss: 0.546352\tvalid's binary_logloss: 0.576116\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542612\tvalid's binary_logloss: 0.575598\n",
      "[90]\ttrain's binary_logloss: 0.538555\tvalid's binary_logloss: 0.575084\n",
      "[100]\ttrain's binary_logloss: 0.534398\tvalid's binary_logloss: 0.574738\n",
      "[110]\ttrain's binary_logloss: 0.530283\tvalid's binary_logloss: 0.57424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527063\tvalid's binary_logloss: 0.574017\n",
      "[130]\ttrain's binary_logloss: 0.523752\tvalid's binary_logloss: 0.573873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520685\tvalid's binary_logloss: 0.573676\n",
      "[150]\ttrain's binary_logloss: 0.517285\tvalid's binary_logloss: 0.573418\n",
      "[160]\ttrain's binary_logloss: 0.513881\tvalid's binary_logloss: 0.573225\n",
      "[170]\ttrain's binary_logloss: 0.510577\tvalid's binary_logloss: 0.573099\n",
      "[180]\ttrain's binary_logloss: 0.50809\tvalid's binary_logloss: 0.573117\n",
      "[190]\ttrain's binary_logloss: 0.505244\tvalid's binary_logloss: 0.572884\n",
      "[200]\ttrain's binary_logloss: 0.502136\tvalid's binary_logloss: 0.572693\n",
      "[210]\ttrain's binary_logloss: 0.498727\tvalid's binary_logloss: 0.572488\n",
      "[220]\ttrain's binary_logloss: 0.496297\tvalid's binary_logloss: 0.572529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  65%|######5   | 13/20 [03:37<01:55, 16.52s/it]\u001b[32m[I 2023-01-04 07:15:45,085]\u001b[0m Trial 52 finished with value: 0.5724648754376436 and parameters: {'lambda_l1': 5.301319336292448e-06, 'lambda_l2': 0.09490907414656227}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  65%|######5   | 13/20 [03:37<01:55, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[215]\ttrain's binary_logloss: 0.49739\tvalid's binary_logloss: 0.572465\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597765\tvalid's binary_logloss: 0.602312\n",
      "[20]\ttrain's binary_logloss: 0.581751\tvalid's binary_logloss: 0.590569\n",
      "[30]\ttrain's binary_logloss: 0.571716\tvalid's binary_logloss: 0.584569\n",
      "[40]\ttrain's binary_logloss: 0.562521\tvalid's binary_logloss: 0.57984\n",
      "[50]\ttrain's binary_logloss: 0.555626\tvalid's binary_logloss: 0.577491\n",
      "[60]\ttrain's binary_logloss: 0.550709\tvalid's binary_logloss: 0.576516\n",
      "[70]\ttrain's binary_logloss: 0.54638\tvalid's binary_logloss: 0.575938\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542708\tvalid's binary_logloss: 0.575389\n",
      "[90]\ttrain's binary_logloss: 0.538591\tvalid's binary_logloss: 0.575012\n",
      "[100]\ttrain's binary_logloss: 0.534607\tvalid's binary_logloss: 0.574652\n",
      "[110]\ttrain's binary_logloss: 0.53062\tvalid's binary_logloss: 0.574258\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.527492\tvalid's binary_logloss: 0.574103\n",
      "[130]\ttrain's binary_logloss: 0.524146\tvalid's binary_logloss: 0.573803\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.52131\tvalid's binary_logloss: 0.573401\n",
      "[150]\ttrain's binary_logloss: 0.517876\tvalid's binary_logloss: 0.573213\n",
      "[160]\ttrain's binary_logloss: 0.514564\tvalid's binary_logloss: 0.572943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  70%|#######   | 14/20 [03:59<01:47, 17.89s/it]\u001b[32m[I 2023-01-04 07:16:06,133]\u001b[0m Trial 53 finished with value: 0.5727877098571634 and parameters: {'lambda_l1': 0.09472225658413162, 'lambda_l2': 2.0112198272261653e-08}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  70%|#######   | 14/20 [03:59<01:47, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain's binary_logloss: 0.510971\tvalid's binary_logloss: 0.572842\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's binary_logloss: 0.513244\tvalid's binary_logloss: 0.572788\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598004\tvalid's binary_logloss: 0.602369\n",
      "[20]\ttrain's binary_logloss: 0.58212\tvalid's binary_logloss: 0.590681\n",
      "[30]\ttrain's binary_logloss: 0.572203\tvalid's binary_logloss: 0.584645\n",
      "[40]\ttrain's binary_logloss: 0.563107\tvalid's binary_logloss: 0.579803\n",
      "[50]\ttrain's binary_logloss: 0.556367\tvalid's binary_logloss: 0.577409\n",
      "[60]\ttrain's binary_logloss: 0.551515\tvalid's binary_logloss: 0.576369\n",
      "[70]\ttrain's binary_logloss: 0.547284\tvalid's binary_logloss: 0.575648\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.543927\tvalid's binary_logloss: 0.575195\n",
      "[90]\ttrain's binary_logloss: 0.539906\tvalid's binary_logloss: 0.574792\n",
      "[100]\ttrain's binary_logloss: 0.535972\tvalid's binary_logloss: 0.574329\n",
      "[110]\ttrain's binary_logloss: 0.532053\tvalid's binary_logloss: 0.574009\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.529136\tvalid's binary_logloss: 0.573816\n",
      "[130]\ttrain's binary_logloss: 0.526074\tvalid's binary_logloss: 0.57372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.523323\tvalid's binary_logloss: 0.573436\n",
      "[150]\ttrain's binary_logloss: 0.519794\tvalid's binary_logloss: 0.573228\n",
      "[160]\ttrain's binary_logloss: 0.516597\tvalid's binary_logloss: 0.57301\n",
      "[170]\ttrain's binary_logloss: 0.513171\tvalid's binary_logloss: 0.572824\n",
      "[180]\ttrain's binary_logloss: 0.510618\tvalid's binary_logloss: 0.572809\n",
      "[190]\ttrain's binary_logloss: 0.507773\tvalid's binary_logloss: 0.572419\n",
      "[200]\ttrain's binary_logloss: 0.505249\tvalid's binary_logloss: 0.572255\n",
      "[210]\ttrain's binary_logloss: 0.502099\tvalid's binary_logloss: 0.571987\n",
      "[220]\ttrain's binary_logloss: 0.499817\tvalid's binary_logloss: 0.571947\n",
      "[230]\ttrain's binary_logloss: 0.496937\tvalid's binary_logloss: 0.571863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  75%|#######5  | 15/20 [04:14<01:25, 17.09s/it]\u001b[32m[I 2023-01-04 07:16:21,374]\u001b[0m Trial 54 finished with value: 0.5718576595478138 and parameters: {'lambda_l1': 0.0010985139222346155, 'lambda_l2': 1.1657943530679395}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  75%|#######5  | 15/20 [04:14<01:25, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[229]\ttrain's binary_logloss: 0.497153\tvalid's binary_logloss: 0.571858\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597608\tvalid's binary_logloss: 0.602215\n",
      "[20]\ttrain's binary_logloss: 0.581601\tvalid's binary_logloss: 0.590519\n",
      "[30]\ttrain's binary_logloss: 0.571544\tvalid's binary_logloss: 0.584552\n",
      "[40]\ttrain's binary_logloss: 0.562254\tvalid's binary_logloss: 0.579716\n",
      "[50]\ttrain's binary_logloss: 0.555428\tvalid's binary_logloss: 0.577416\n",
      "[60]\ttrain's binary_logloss: 0.550371\tvalid's binary_logloss: 0.576434\n",
      "[70]\ttrain's binary_logloss: 0.546021\tvalid's binary_logloss: 0.575832\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.542268\tvalid's binary_logloss: 0.575386\n",
      "[90]\ttrain's binary_logloss: 0.538044\tvalid's binary_logloss: 0.574781\n",
      "[100]\ttrain's binary_logloss: 0.533965\tvalid's binary_logloss: 0.574413\n",
      "[110]\ttrain's binary_logloss: 0.530017\tvalid's binary_logloss: 0.574115\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.526782\tvalid's binary_logloss: 0.573968\n",
      "[130]\ttrain's binary_logloss: 0.523272\tvalid's binary_logloss: 0.573659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.520291\tvalid's binary_logloss: 0.573361\n",
      "[150]\ttrain's binary_logloss: 0.516905\tvalid's binary_logloss: 0.573174\n",
      "[160]\ttrain's binary_logloss: 0.513701\tvalid's binary_logloss: 0.572942\n",
      "[170]\ttrain's binary_logloss: 0.510116\tvalid's binary_logloss: 0.572801\n",
      "[180]\ttrain's binary_logloss: 0.507394\tvalid's binary_logloss: 0.572635\n",
      "[190]\ttrain's binary_logloss: 0.5044\tvalid's binary_logloss: 0.572459\n",
      "[200]\ttrain's binary_logloss: 0.501436\tvalid's binary_logloss: 0.572271\n",
      "[210]\ttrain's binary_logloss: 0.498155\tvalid's binary_logloss: 0.572086\n",
      "[220]\ttrain's binary_logloss: 0.495857\tvalid's binary_logloss: 0.572049\n",
      "[230]\ttrain's binary_logloss: 0.493242\tvalid's binary_logloss: 0.571988\n",
      "[240]\ttrain's binary_logloss: 0.491109\tvalid's binary_logloss: 0.571975\n",
      "[250]\ttrain's binary_logloss: 0.488538\tvalid's binary_logloss: 0.571929\n",
      "[260]\ttrain's binary_logloss: 0.485936\tvalid's binary_logloss: 0.57184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  80%|########  | 16/20 [04:37<01:15, 18.86s/it]\u001b[32m[I 2023-01-04 07:16:44,344]\u001b[0m Trial 55 finished with value: 0.5718397551191132 and parameters: {'lambda_l1': 2.9125439058515493e-06, 'lambda_l2': 0.016559766805968042}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  80%|########  | 16/20 [04:37<01:15, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270]\ttrain's binary_logloss: 0.483586\tvalid's binary_logloss: 0.571844\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttrain's binary_logloss: 0.485936\tvalid's binary_logloss: 0.57184\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597931\tvalid's binary_logloss: 0.602283\n",
      "[20]\ttrain's binary_logloss: 0.582114\tvalid's binary_logloss: 0.590713\n",
      "[30]\ttrain's binary_logloss: 0.572331\tvalid's binary_logloss: 0.584803\n",
      "[40]\ttrain's binary_logloss: 0.563242\tvalid's binary_logloss: 0.580122\n",
      "[50]\ttrain's binary_logloss: 0.556563\tvalid's binary_logloss: 0.577817\n",
      "[60]\ttrain's binary_logloss: 0.55173\tvalid's binary_logloss: 0.576762\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.54753\tvalid's binary_logloss: 0.575988\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.544059\tvalid's binary_logloss: 0.575548\n",
      "[90]\ttrain's binary_logloss: 0.540045\tvalid's binary_logloss: 0.574981\n",
      "[100]\ttrain's binary_logloss: 0.536032\tvalid's binary_logloss: 0.574667\n",
      "[110]\ttrain's binary_logloss: 0.532097\tvalid's binary_logloss: 0.574202\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.528915\tvalid's binary_logloss: 0.573855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttrain's binary_logloss: 0.525664\tvalid's binary_logloss: 0.573702\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.522965\tvalid's binary_logloss: 0.573436\n",
      "[150]\ttrain's binary_logloss: 0.519453\tvalid's binary_logloss: 0.573267\n",
      "[160]\ttrain's binary_logloss: 0.516263\tvalid's binary_logloss: 0.573104\n",
      "[170]\ttrain's binary_logloss: 0.51289\tvalid's binary_logloss: 0.573014\n",
      "[180]\ttrain's binary_logloss: 0.510258\tvalid's binary_logloss: 0.572917\n",
      "[190]\ttrain's binary_logloss: 0.507387\tvalid's binary_logloss: 0.572562\n",
      "[200]\ttrain's binary_logloss: 0.504601\tvalid's binary_logloss: 0.57233\n",
      "[210]\ttrain's binary_logloss: 0.50124\tvalid's binary_logloss: 0.572002\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[220]\ttrain's binary_logloss: 0.499057\tvalid's binary_logloss: 0.5719\n",
      "[230]\ttrain's binary_logloss: 0.496262\tvalid's binary_logloss: 0.57178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  85%|########5 | 17/20 [04:51<00:52, 17.36s/it]\u001b[32m[I 2023-01-04 07:16:58,230]\u001b[0m Trial 56 finished with value: 0.5716817961963345 and parameters: {'lambda_l1': 0.6477892257040199, 'lambda_l2': 7.444120616430285e-05}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  85%|########5 | 17/20 [04:51<00:52, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\ttrain's binary_logloss: 0.494237\tvalid's binary_logloss: 0.571753\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttrain's binary_logloss: 0.495442\tvalid's binary_logloss: 0.571682\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.175111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.597935\tvalid's binary_logloss: 0.602345\n",
      "[20]\ttrain's binary_logloss: 0.581978\tvalid's binary_logloss: 0.590594\n",
      "[30]\ttrain's binary_logloss: 0.572097\tvalid's binary_logloss: 0.584605\n",
      "[40]\ttrain's binary_logloss: 0.56294\tvalid's binary_logloss: 0.579885\n",
      "[50]\ttrain's binary_logloss: 0.556198\tvalid's binary_logloss: 0.577584\n",
      "[60]\ttrain's binary_logloss: 0.551387\tvalid's binary_logloss: 0.576496\n",
      "[70]\ttrain's binary_logloss: 0.54705\tvalid's binary_logloss: 0.575723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.543504\tvalid's binary_logloss: 0.575214\n",
      "[90]\ttrain's binary_logloss: 0.539383\tvalid's binary_logloss: 0.574713\n",
      "[100]\ttrain's binary_logloss: 0.535395\tvalid's binary_logloss: 0.574437\n",
      "[110]\ttrain's binary_logloss: 0.531553\tvalid's binary_logloss: 0.574173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.528476\tvalid's binary_logloss: 0.57384\n",
      "[130]\ttrain's binary_logloss: 0.525048\tvalid's binary_logloss: 0.573628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.52221\tvalid's binary_logloss: 0.573372\n",
      "[150]\ttrain's binary_logloss: 0.518807\tvalid's binary_logloss: 0.573233\n",
      "[160]\ttrain's binary_logloss: 0.515752\tvalid's binary_logloss: 0.573064\n",
      "[170]\ttrain's binary_logloss: 0.512539\tvalid's binary_logloss: 0.572935\n",
      "[180]\ttrain's binary_logloss: 0.509765\tvalid's binary_logloss: 0.572898\n",
      "[190]\ttrain's binary_logloss: 0.50666\tvalid's binary_logloss: 0.5726\n",
      "[200]\ttrain's binary_logloss: 0.503943\tvalid's binary_logloss: 0.572373\n",
      "[210]\ttrain's binary_logloss: 0.500685\tvalid's binary_logloss: 0.572207\n",
      "[220]\ttrain's binary_logloss: 0.498548\tvalid's binary_logloss: 0.572159\n",
      "[230]\ttrain's binary_logloss: 0.495873\tvalid's binary_logloss: 0.572114\n",
      "[240]\ttrain's binary_logloss: 0.49351\tvalid's binary_logloss: 0.57203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  90%|######### | 18/20 [05:46<00:57, 28.65s/it]\u001b[32m[I 2023-01-04 07:17:53,154]\u001b[0m Trial 57 finished with value: 0.57200140400297 and parameters: {'lambda_l1': 0.002858206795995805, 'lambda_l2': 0.749705707430116}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  90%|######### | 18/20 [05:46<00:57, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttrain's binary_logloss: 0.491179\tvalid's binary_logloss: 0.572106\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttrain's binary_logloss: 0.493226\tvalid's binary_logloss: 0.572001\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.599021\tvalid's binary_logloss: 0.602978\n",
      "[20]\ttrain's binary_logloss: 0.583869\tvalid's binary_logloss: 0.591443\n",
      "[30]\ttrain's binary_logloss: 0.574579\tvalid's binary_logloss: 0.585457\n",
      "[40]\ttrain's binary_logloss: 0.56597\tvalid's binary_logloss: 0.580625\n",
      "[50]\ttrain's binary_logloss: 0.559637\tvalid's binary_logloss: 0.578005\n",
      "[60]\ttrain's binary_logloss: 0.555305\tvalid's binary_logloss: 0.577002\n",
      "[70]\ttrain's binary_logloss: 0.551397\tvalid's binary_logloss: 0.576118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.548254\tvalid's binary_logloss: 0.57551\n",
      "[90]\ttrain's binary_logloss: 0.544779\tvalid's binary_logloss: 0.575052\n",
      "[100]\ttrain's binary_logloss: 0.541273\tvalid's binary_logloss: 0.574617\n",
      "[110]\ttrain's binary_logloss: 0.537895\tvalid's binary_logloss: 0.574093\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.53503\tvalid's binary_logloss: 0.573776\n",
      "[130]\ttrain's binary_logloss: 0.53241\tvalid's binary_logloss: 0.573532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.530043\tvalid's binary_logloss: 0.573281\n",
      "[150]\ttrain's binary_logloss: 0.527356\tvalid's binary_logloss: 0.57298\n",
      "[160]\ttrain's binary_logloss: 0.524726\tvalid's binary_logloss: 0.572822\n",
      "[170]\ttrain's binary_logloss: 0.521976\tvalid's binary_logloss: 0.572586\n",
      "[180]\ttrain's binary_logloss: 0.519998\tvalid's binary_logloss: 0.572415\n",
      "[190]\ttrain's binary_logloss: 0.517829\tvalid's binary_logloss: 0.572122\n",
      "[200]\ttrain's binary_logloss: 0.515532\tvalid's binary_logloss: 0.571957\n",
      "[210]\ttrain's binary_logloss: 0.51308\tvalid's binary_logloss: 0.57171\n",
      "[220]\ttrain's binary_logloss: 0.511229\tvalid's binary_logloss: 0.571596\n",
      "[230]\ttrain's binary_logloss: 0.509079\tvalid's binary_logloss: 0.571548\n",
      "[240]\ttrain's binary_logloss: 0.507326\tvalid's binary_logloss: 0.571487\n",
      "[250]\ttrain's binary_logloss: 0.505203\tvalid's binary_logloss: 0.571459\n",
      "[260]\ttrain's binary_logloss: 0.503132\tvalid's binary_logloss: 0.57143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385:  95%|#########5| 19/20 [06:16<00:29, 29.12s/it]\u001b[32m[I 2023-01-04 07:18:23,383]\u001b[0m Trial 58 finished with value: 0.5714098315346908 and parameters: {'lambda_l1': 4.123984775676981e-07, 'lambda_l2': 9.220201634200624}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385:  95%|#########5| 19/20 [06:16<00:29, 29.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[255]\ttrain's binary_logloss: 0.504256\tvalid's binary_logloss: 0.57141\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.599016\tvalid's binary_logloss: 0.602977\n",
      "[20]\ttrain's binary_logloss: 0.583862\tvalid's binary_logloss: 0.591443\n",
      "[30]\ttrain's binary_logloss: 0.574572\tvalid's binary_logloss: 0.585452\n",
      "[40]\ttrain's binary_logloss: 0.565991\tvalid's binary_logloss: 0.580523\n",
      "[50]\ttrain's binary_logloss: 0.559723\tvalid's binary_logloss: 0.578006\n",
      "[60]\ttrain's binary_logloss: 0.555353\tvalid's binary_logloss: 0.576943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.551471\tvalid's binary_logloss: 0.576166\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.548374\tvalid's binary_logloss: 0.575535\n",
      "[90]\ttrain's binary_logloss: 0.544839\tvalid's binary_logloss: 0.575005\n",
      "[100]\ttrain's binary_logloss: 0.541367\tvalid's binary_logloss: 0.574641\n",
      "[110]\ttrain's binary_logloss: 0.53805\tvalid's binary_logloss: 0.574164\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.535439\tvalid's binary_logloss: 0.573927\n",
      "[130]\ttrain's binary_logloss: 0.532854\tvalid's binary_logloss: 0.573682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.530647\tvalid's binary_logloss: 0.57341\n",
      "[150]\ttrain's binary_logloss: 0.527984\tvalid's binary_logloss: 0.573241\n",
      "[160]\ttrain's binary_logloss: 0.525442\tvalid's binary_logloss: 0.57309\n",
      "[170]\ttrain's binary_logloss: 0.522987\tvalid's binary_logloss: 0.573006\n",
      "[180]\ttrain's binary_logloss: 0.520951\tvalid's binary_logloss: 0.572847\n",
      "[190]\ttrain's binary_logloss: 0.518777\tvalid's binary_logloss: 0.57263\n",
      "[200]\ttrain's binary_logloss: 0.516509\tvalid's binary_logloss: 0.572448\n",
      "[210]\ttrain's binary_logloss: 0.513963\tvalid's binary_logloss: 0.572187\n",
      "[220]\ttrain's binary_logloss: 0.511997\tvalid's binary_logloss: 0.572122\n",
      "[230]\ttrain's binary_logloss: 0.509637\tvalid's binary_logloss: 0.571963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.571385: 100%|##########| 20/20 [06:25<00:00, 23.03s/it]\u001b[32m[I 2023-01-04 07:18:32,222]\u001b[0m Trial 59 finished with value: 0.5719343483902424 and parameters: {'lambda_l1': 5.951075880978881e-05, 'lambda_l2': 9.174165951387668}. Best is trial 40 with value: 0.5713854776011388.\u001b[0m\n",
      "regularization_factors, val_score: 0.571385: 100%|##########| 20/20 [06:25<00:00, 19.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\ttrain's binary_logloss: 0.507705\tvalid's binary_logloss: 0.571947\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttrain's binary_logloss: 0.509277\tvalid's binary_logloss: 0.571934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.571385:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598342\tvalid's binary_logloss: 0.602443\n",
      "[20]\ttrain's binary_logloss: 0.582969\tvalid's binary_logloss: 0.590903\n",
      "[30]\ttrain's binary_logloss: 0.57352\tvalid's binary_logloss: 0.584906\n",
      "[40]\ttrain's binary_logloss: 0.564804\tvalid's binary_logloss: 0.580139\n",
      "[50]\ttrain's binary_logloss: 0.558354\tvalid's binary_logloss: 0.577628\n",
      "[60]\ttrain's binary_logloss: 0.553845\tvalid's binary_logloss: 0.576691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.549934\tvalid's binary_logloss: 0.57603\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.546638\tvalid's binary_logloss: 0.575501\n",
      "[90]\ttrain's binary_logloss: 0.543027\tvalid's binary_logloss: 0.574992\n",
      "[100]\ttrain's binary_logloss: 0.539386\tvalid's binary_logloss: 0.574625\n",
      "[110]\ttrain's binary_logloss: 0.53582\tvalid's binary_logloss: 0.57426\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.533158\tvalid's binary_logloss: 0.574099\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttrain's binary_logloss: 0.530324\tvalid's binary_logloss: 0.573842\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.527859\tvalid's binary_logloss: 0.573589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttrain's binary_logloss: 0.524929\tvalid's binary_logloss: 0.573404\n",
      "[160]\ttrain's binary_logloss: 0.522042\tvalid's binary_logloss: 0.573195\n",
      "[170]\ttrain's binary_logloss: 0.519072\tvalid's binary_logloss: 0.573039\n",
      "[180]\ttrain's binary_logloss: 0.516695\tvalid's binary_logloss: 0.572983\n",
      "[190]\ttrain's binary_logloss: 0.514119\tvalid's binary_logloss: 0.572696\n",
      "[200]\ttrain's binary_logloss: 0.511561\tvalid's binary_logloss: 0.572541\n",
      "[210]\ttrain's binary_logloss: 0.50873\tvalid's binary_logloss: 0.572336\n",
      "[220]\ttrain's binary_logloss: 0.506675\tvalid's binary_logloss: 0.572359\n",
      "[230]\ttrain's binary_logloss: 0.504139\tvalid's binary_logloss: 0.57225\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[240]\ttrain's binary_logloss: 0.50214\tvalid's binary_logloss: 0.5723\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttrain's binary_logloss: 0.503861\tvalid's binary_logloss: 0.572193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.571385:  20%|##        | 1/5 [00:09<00:36,  9.16s/it]\u001b[32m[I 2023-01-04 07:18:41,390]\u001b[0m Trial 60 finished with value: 0.5721931086504163 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.5721931086504163.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.571385:  20%|##        | 1/5 [00:09<00:36,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598308\tvalid's binary_logloss: 0.602506\n",
      "[20]\ttrain's binary_logloss: 0.582653\tvalid's binary_logloss: 0.590906\n",
      "[30]\ttrain's binary_logloss: 0.572969\tvalid's binary_logloss: 0.584885\n",
      "[40]\ttrain's binary_logloss: 0.564017\tvalid's binary_logloss: 0.580088\n",
      "[50]\ttrain's binary_logloss: 0.557584\tvalid's binary_logloss: 0.577807\n",
      "[60]\ttrain's binary_logloss: 0.552918\tvalid's binary_logloss: 0.576841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.548888\tvalid's binary_logloss: 0.576074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.545545\tvalid's binary_logloss: 0.57555\n",
      "[90]\ttrain's binary_logloss: 0.541829\tvalid's binary_logloss: 0.575004\n",
      "[100]\ttrain's binary_logloss: 0.538177\tvalid's binary_logloss: 0.57458\n",
      "[110]\ttrain's binary_logloss: 0.534557\tvalid's binary_logloss: 0.574289\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.531452\tvalid's binary_logloss: 0.573954\n",
      "[130]\ttrain's binary_logloss: 0.528448\tvalid's binary_logloss: 0.573807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.525963\tvalid's binary_logloss: 0.57357\n",
      "[150]\ttrain's binary_logloss: 0.522913\tvalid's binary_logloss: 0.573366\n",
      "[160]\ttrain's binary_logloss: 0.520047\tvalid's binary_logloss: 0.573255\n",
      "[170]\ttrain's binary_logloss: 0.516742\tvalid's binary_logloss: 0.573054\n",
      "[180]\ttrain's binary_logloss: 0.514128\tvalid's binary_logloss: 0.572882\n",
      "[190]\ttrain's binary_logloss: 0.511502\tvalid's binary_logloss: 0.57268\n",
      "[200]\ttrain's binary_logloss: 0.508864\tvalid's binary_logloss: 0.572515\n",
      "[210]\ttrain's binary_logloss: 0.506034\tvalid's binary_logloss: 0.572249\n",
      "[220]\ttrain's binary_logloss: 0.503945\tvalid's binary_logloss: 0.572252\n",
      "[230]\ttrain's binary_logloss: 0.50144\tvalid's binary_logloss: 0.572108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.571385:  40%|####      | 2/5 [00:18<00:27,  9.07s/it]\u001b[32m[I 2023-01-04 07:18:50,398]\u001b[0m Trial 61 finished with value: 0.5721054484980506 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.5721054484980506.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.571385:  40%|####      | 2/5 [00:18<00:27,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[229]\ttrain's binary_logloss: 0.501612\tvalid's binary_logloss: 0.572105\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598199\tvalid's binary_logloss: 0.602414\n",
      "[20]\ttrain's binary_logloss: 0.582513\tvalid's binary_logloss: 0.590808\n",
      "[30]\ttrain's binary_logloss: 0.572894\tvalid's binary_logloss: 0.584804\n",
      "[40]\ttrain's binary_logloss: 0.563801\tvalid's binary_logloss: 0.579907\n",
      "[50]\ttrain's binary_logloss: 0.557312\tvalid's binary_logloss: 0.577709\n",
      "[60]\ttrain's binary_logloss: 0.552612\tvalid's binary_logloss: 0.576561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.548525\tvalid's binary_logloss: 0.575716\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.545203\tvalid's binary_logloss: 0.575213\n",
      "[90]\ttrain's binary_logloss: 0.541295\tvalid's binary_logloss: 0.574717\n",
      "[100]\ttrain's binary_logloss: 0.537414\tvalid's binary_logloss: 0.574346\n",
      "[110]\ttrain's binary_logloss: 0.533706\tvalid's binary_logloss: 0.574018\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.530637\tvalid's binary_logloss: 0.573783\n",
      "[130]\ttrain's binary_logloss: 0.527636\tvalid's binary_logloss: 0.573518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.525148\tvalid's binary_logloss: 0.57334\n",
      "[150]\ttrain's binary_logloss: 0.522194\tvalid's binary_logloss: 0.573147\n",
      "[160]\ttrain's binary_logloss: 0.519261\tvalid's binary_logloss: 0.573008\n",
      "[170]\ttrain's binary_logloss: 0.516467\tvalid's binary_logloss: 0.572984\n",
      "[180]\ttrain's binary_logloss: 0.51383\tvalid's binary_logloss: 0.572826\n",
      "[190]\ttrain's binary_logloss: 0.511238\tvalid's binary_logloss: 0.572599\n",
      "[200]\ttrain's binary_logloss: 0.508576\tvalid's binary_logloss: 0.572398\n",
      "[210]\ttrain's binary_logloss: 0.505623\tvalid's binary_logloss: 0.572121\n",
      "[220]\ttrain's binary_logloss: 0.503586\tvalid's binary_logloss: 0.572\n",
      "[230]\ttrain's binary_logloss: 0.501003\tvalid's binary_logloss: 0.57186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.571385:  60%|######    | 3/5 [00:30<00:21, 10.51s/it]\u001b[32m[I 2023-01-04 07:19:02,615]\u001b[0m Trial 62 finished with value: 0.5717838739263542 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.5717838739263542.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.571385:  60%|######    | 3/5 [00:30<00:21, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\ttrain's binary_logloss: 0.498916\tvalid's binary_logloss: 0.57179\n",
      "[250]\ttrain's binary_logloss: 0.496765\tvalid's binary_logloss: 0.571814\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttrain's binary_logloss: 0.498753\tvalid's binary_logloss: 0.571784\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598193\tvalid's binary_logloss: 0.602422\n",
      "[20]\ttrain's binary_logloss: 0.5825\tvalid's binary_logloss: 0.590831\n",
      "[30]\ttrain's binary_logloss: 0.572839\tvalid's binary_logloss: 0.584883\n",
      "[40]\ttrain's binary_logloss: 0.563865\tvalid's binary_logloss: 0.580143\n",
      "[50]\ttrain's binary_logloss: 0.557229\tvalid's binary_logloss: 0.577773\n",
      "[60]\ttrain's binary_logloss: 0.552529\tvalid's binary_logloss: 0.576783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.548418\tvalid's binary_logloss: 0.575956\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.545098\tvalid's binary_logloss: 0.57543\n",
      "[90]\ttrain's binary_logloss: 0.541236\tvalid's binary_logloss: 0.574989\n",
      "[100]\ttrain's binary_logloss: 0.537421\tvalid's binary_logloss: 0.574521\n",
      "[110]\ttrain's binary_logloss: 0.53388\tvalid's binary_logloss: 0.574113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.53095\tvalid's binary_logloss: 0.574027\n",
      "[130]\ttrain's binary_logloss: 0.527965\tvalid's binary_logloss: 0.573813\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.525458\tvalid's binary_logloss: 0.573551\n",
      "[150]\ttrain's binary_logloss: 0.521966\tvalid's binary_logloss: 0.573239\n",
      "[160]\ttrain's binary_logloss: 0.519111\tvalid's binary_logloss: 0.573106\n",
      "[170]\ttrain's binary_logloss: 0.516356\tvalid's binary_logloss: 0.572956\n",
      "[180]\ttrain's binary_logloss: 0.51391\tvalid's binary_logloss: 0.572828\n",
      "[190]\ttrain's binary_logloss: 0.511114\tvalid's binary_logloss: 0.572424\n",
      "[200]\ttrain's binary_logloss: 0.508349\tvalid's binary_logloss: 0.572195\n",
      "[210]\ttrain's binary_logloss: 0.505474\tvalid's binary_logloss: 0.572037\n",
      "[220]\ttrain's binary_logloss: 0.503513\tvalid's binary_logloss: 0.571968\n",
      "[230]\ttrain's binary_logloss: 0.501148\tvalid's binary_logloss: 0.571798\n",
      "[240]\ttrain's binary_logloss: 0.49926\tvalid's binary_logloss: 0.571741\n",
      "[250]\ttrain's binary_logloss: 0.497205\tvalid's binary_logloss: 0.571748\n",
      "[260]\ttrain's binary_logloss: 0.49471\tvalid's binary_logloss: 0.571584\n",
      "[270]\ttrain's binary_logloss: 0.492637\tvalid's binary_logloss: 0.571547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.571385:  80%|########  | 4/5 [00:40<00:10, 10.52s/it]\u001b[32m[I 2023-01-04 07:19:13,159]\u001b[0m Trial 63 finished with value: 0.5714505254238909 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.5714505254238909.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.571385:  80%|########  | 4/5 [00:40<00:10, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280]\ttrain's binary_logloss: 0.490307\tvalid's binary_logloss: 0.571488\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttrain's binary_logloss: 0.490826\tvalid's binary_logloss: 0.571451\n",
      "[LightGBM] [Info] Number of positive: 122013, number of negative: 61035\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 183048, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.666563 -> initscore=0.692680\n",
      "[LightGBM] [Info] Start training from score 0.692680\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.598227\tvalid's binary_logloss: 0.602458\n",
      "[20]\ttrain's binary_logloss: 0.582529\tvalid's binary_logloss: 0.59084\n",
      "[30]\ttrain's binary_logloss: 0.572842\tvalid's binary_logloss: 0.584802\n",
      "[40]\ttrain's binary_logloss: 0.563981\tvalid's binary_logloss: 0.580043\n",
      "[50]\ttrain's binary_logloss: 0.557329\tvalid's binary_logloss: 0.577511\n",
      "[60]\ttrain's binary_logloss: 0.552676\tvalid's binary_logloss: 0.576414\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's binary_logloss: 0.548528\tvalid's binary_logloss: 0.575671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's binary_logloss: 0.545222\tvalid's binary_logloss: 0.575148\n",
      "[90]\ttrain's binary_logloss: 0.541344\tvalid's binary_logloss: 0.574577\n",
      "[100]\ttrain's binary_logloss: 0.537626\tvalid's binary_logloss: 0.574173\n",
      "[110]\ttrain's binary_logloss: 0.5339\tvalid's binary_logloss: 0.573724\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's binary_logloss: 0.530927\tvalid's binary_logloss: 0.573578\n",
      "[130]\ttrain's binary_logloss: 0.528017\tvalid's binary_logloss: 0.57337\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's binary_logloss: 0.525515\tvalid's binary_logloss: 0.573138\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttrain's binary_logloss: 0.522401\tvalid's binary_logloss: 0.572947\n",
      "[160]\ttrain's binary_logloss: 0.519584\tvalid's binary_logloss: 0.572739\n",
      "[170]\ttrain's binary_logloss: 0.51634\tvalid's binary_logloss: 0.572471\n",
      "[180]\ttrain's binary_logloss: 0.513964\tvalid's binary_logloss: 0.572264\n",
      "[190]\ttrain's binary_logloss: 0.511256\tvalid's binary_logloss: 0.571963\n",
      "[200]\ttrain's binary_logloss: 0.508739\tvalid's binary_logloss: 0.571766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.571385: 100%|##########| 5/5 [00:49<00:00,  9.73s/it]\u001b[32m[I 2023-01-04 07:19:21,473]\u001b[0m Trial 64 finished with value: 0.571504885120768 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.5714505254238909.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.571385: 100%|##########| 5/5 [00:49<00:00,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttrain's binary_logloss: 0.505774\tvalid's binary_logloss: 0.571534\n",
      "[220]\ttrain's binary_logloss: 0.50364\tvalid's binary_logloss: 0.571549\n",
      "Early stopping, best iteration is:\n",
      "[212]\ttrain's binary_logloss: 0.505287\tvalid's binary_logloss: 0.571505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.train_lgb()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3. モデルのパラメータを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータをロード\n",
    "data_train.load_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータを確認\n",
    "data_train.show_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合配列を確認\n",
    "data_train.show_mixed_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類レポートを確認\n",
    "data_train.show_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-4. 学習推移を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 頻度とゲインを表示\n",
    "# 引数\n",
    "#  頻度：'split'\n",
    "#  ゲイン：'gain'\n",
    "data_train.show_feature_importance('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 頻度とゲインを表示\n",
    "# 引数\n",
    "#  頻度：'split'\n",
    "#  ゲイン：'gain'\n",
    "data_train.show_feature_importance('gain')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 予測"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1. 予測クラスのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データのパスクラスをインスタンス化\n",
    "#   モデルのタイプ\n",
    "#     multiclass_3\n",
    "#     multiclass_5\n",
    "#     binaryclass\n",
    "#   カテゴリ変数の処理方法を決める\n",
    "#     ラベルエンコーディング　：pred_label\n",
    "#     ダミー変数化　　　　　　：pred_dummies\n",
    "#     カウントエンコーディング：pred_count\n",
    "pred_tdp = TrainDataPaths('multiclass_5','pred_label')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2. 予測するレースurlをセット\n",
    "既に着順が出ているレースはエラーになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_url = 'https://race.netkeiba.com/race/shutuba.html?race_id=202206050811&rf=race_list'\n",
    "\n",
    "pred_url = 'https://race.netkeiba.com/race/result.html?race_id=202209060711&rf=race_list'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3. 予測レースのスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy_proc.coll_pred_grades(pred_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy_proc.coll_eval_grades(pred_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-4. 前処理に必要なクラスのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース結果マスタを読み込み\n",
    "pred_keiba = pd.read_pickle(lps.DATA_TMP_PRED)\n",
    "# データフレームの処理クラスのインスタンス化\n",
    "predict = dataframe_grades(pred_keiba, lps, pred_tdp, df_cols, race_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-5. レース情報を分割し、下記列を追加\n",
    "- 距離\n",
    "- 回り\n",
    "- タイプ\n",
    "- 馬場状態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.pred_split_raceinfo()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G1・G2・G3レース列を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.add_G_race()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-6. 予測レース結果を整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 競馬場名を指定\n",
    "# 例：中山\n",
    "place_name = None\n",
    "\n",
    "# 体重増減の記号(+)を削除\n",
    "predict.pred_conversion_values()\n",
    "# 性齢を性と齢で分割\n",
    "predict.split_sexual_age()\n",
    "# 競馬場指定(デフォルト指定なし)\n",
    "predict.select_place_name(place_name)\n",
    "# レースタイプを指定(デフォルト指定なし)\n",
    "# 芝・ダート・障\n",
    "# 引数はリスト\n",
    "race_type_list = ['芝','ダート']\n",
    "predict.select_race_type(race_type_list)\n",
    "# 空白列を0で埋める\n",
    "predict.blank_conversion()\n",
    "#grades.tmp_del_shougai()\n",
    "# 整数型に型変換\n",
    "predict.pred_conversion_int()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-7. カテゴリ変数(馬名・騎手・調教師)の処理\n",
    "共通で処理するカテゴリ変数  \n",
    "- 回り\n",
    "- タイプ\n",
    "- 性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.category_process()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-8. 学習データのダミー変数化した列をマージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.pred_merge_dummies()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-9. 予測データに空白列が含まれることがあるので削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.blank_conversion()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-10. 予測データを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = predict.grades_master"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【確認用】予測データのデータ型を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.show_grades_master()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【確認用】予測データをcsv出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.grades_master.to_csv('/home/keiba/src/data/tmp/pred_race_grades.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-11. モデル用クラスをインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_training(lps, pred_tdp, df_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-12. 予測結果を表示・json出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred.model_predict_detail(pred_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
